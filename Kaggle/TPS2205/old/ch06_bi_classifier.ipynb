{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMJ-p2-QPsqR"
      },
      "source": [
        "# 6章　2値分類"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hkEhF-rHPsqc"
      },
      "outputs": [],
      "source": [
        "# 必要ライブラリのインポート\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fa0xuJKVPsqd"
      },
      "outputs": [],
      "source": [
        "# torch関連ライブラリのインポート\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "from torchviz import make_dot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OLGjeQzHPsqd"
      },
      "outputs": [],
      "source": [
        "# デフォルトフォントサイズ変更\n",
        "plt.rcParams['font.size'] = 14\n",
        "\n",
        "# デフォルトグラフサイズ変更\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "\n",
        "# デフォルトで方眼表示ON\n",
        "plt.rcParams['axes.grid'] = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqWB_9tDPsqe"
      },
      "source": [
        "## 6.3 シグモイド関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DcYYjzNJPsqe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 12471 (\\N{KATAKANA LETTER SI}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 12464 (\\N{KATAKANA LETTER GU}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 12514 (\\N{KATAKANA LETTER MO}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 12452 (\\N{KATAKANA LETTER I}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 12489 (\\N{KATAKANA LETTER DO}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 38306 (\\N{CJK UNIFIED IDEOGRAPH-95A2}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 12398 (\\N{HIRAGANA LETTER NO}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 12521 (\\N{KATAKANA LETTER RA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 12501 (\\N{KATAKANA LETTER HU}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# NumPy配列でxデータを定義\n",
        "x_np = np.arange(-4, 4.1, 0.25)\n",
        "\n",
        "# データをTensor形式に変換\n",
        "x = torch.tensor(x_np).float()\n",
        "\n",
        "# yの値を計算\n",
        "y = torch.sigmoid(x)\n",
        "\n",
        "# グラフ描画\n",
        "plt.title('シグモイド関数のグラフ')\n",
        "plt.plot(x.data, y.data)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDG_cwuNPsqf"
      },
      "source": [
        "## 6.7 データ準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vhcBelEXPsqf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "元データ (150, 4) (150,)\n"
          ]
        }
      ],
      "source": [
        "# 学習用データ準備\n",
        "\n",
        "# ライブラリのインポート\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# データ読み込み\n",
        "iris = load_iris()\n",
        "\n",
        "# 入力データと正解データ取得\n",
        "x_org, y_org = iris.data, iris.target\n",
        "\n",
        "# 結果確認\n",
        "print('元データ', x_org.shape, y_org.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Uo1YPkPEPsqf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "対象データ (100, 2) (100,)\n"
          ]
        }
      ],
      "source": [
        "# データ絞り込み\n",
        "#   クラス0, 1のみ\n",
        "#   項目sepal_lengthとsepal_widthのみ\n",
        "\n",
        "x_data = iris.data[:100,:2]\n",
        "y_data = iris.target[:100]\n",
        "\n",
        "# 結果確認\n",
        "print('対象データ', x_data.shape, y_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uRG9oXGPsqg"
      },
      "source": [
        "### 訓練データ・検証データの分割"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YUS4x_tmPsqg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 2) (100,)\n",
            "(70, 2) (30, 2) (70,) (30,)\n"
          ]
        }
      ],
      "source": [
        "# 　元データのサイズ\n",
        "print(x_data.shape, y_data.shape)\n",
        "\n",
        "# 訓練データ、検証データに分割 (シャフルも同時に実施)\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_data, y_data, train_size=70, test_size=30, \n",
        "    random_state=123)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRiAjjbePsqh"
      },
      "source": [
        "### 訓練データの散布図表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zu-SEFS2Psqh"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 散布図の表示\n",
        "\n",
        "x_t0 = x_train[y_train == 0]\n",
        "x_t1 = x_train[y_train == 1]\n",
        "plt.scatter(x_t0[:,0], x_t0[:,1], marker='x', c='b', label='0 (setosa)')\n",
        "plt.scatter(x_t1[:,0], x_t1[:,1], marker='o', c='k', label='1 (versicolor)')\n",
        "plt.xlabel('sepal_length')\n",
        "plt.ylabel('sepal_width')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ3NxWrlPsqh"
      },
      "source": [
        "## 6.8 モデル定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8Je8itWpPsqh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_input: 2  n_output:1\n"
          ]
        }
      ],
      "source": [
        "# 入力次元数　(今の場合2)\n",
        "n_input= x_train.shape[1]\n",
        "\n",
        "# 出力次元数\n",
        "n_output = 1\n",
        "\n",
        "# 結果確認\n",
        "print(f'n_input: {n_input}  n_output:{n_output}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DdDi6zsnPsqi"
      },
      "outputs": [],
      "source": [
        "# モデルの定義\n",
        "# 2入力1出力のロジスティック回帰モデル\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_input, n_output):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(n_input, n_output)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "                \n",
        "        # 初期値を全部1にする\n",
        "        # 「ディープラーニングの数学」と条件を合わせる目的        \n",
        "        self.l1.weight.data.fill_(1.0)\n",
        "        self.l1.bias.data.fill_(1.0)        \n",
        "        \n",
        "    # 予測関数の定義\n",
        "    def forward(self, x):\n",
        "        # 最初に入力値を線形関数にかけたを計算する\n",
        "        x1 = self.l1(x)\n",
        "        # 計算結果にシグモイド関数をかける\n",
        "        x2 = self.sigmoid(x1)\n",
        "        return x2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SgP8JkLBPsqi"
      },
      "outputs": [],
      "source": [
        "# インスタンスの生成\n",
        "\n",
        "net = Net(n_input, n_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcmbWo3xPsqj"
      },
      "source": [
        "### モデル確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aWzmDIs_Psqj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('l1.weight', Parameter containing:\n",
            "tensor([[1., 1.]], requires_grad=True))\n",
            "('l1.bias', Parameter containing:\n",
            "tensor([1.], requires_grad=True))\n"
          ]
        }
      ],
      "source": [
        "# モデル内のパラメータの確認\n",
        "# l1.weightとl1.biasがあることがわかる\n",
        "\n",
        "for parameter in net.named_parameters():\n",
        "    print(parameter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "99WSyEiQPsqj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (l1): Linear(in_features=2, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# モデルの概要表示\n",
        "\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SJ34VvxLPsqk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Net                                      --                        --\n",
              "├─Linear: 1-1                            [1]                       3\n",
              "├─Sigmoid: 1-2                           [1]                       --\n",
              "==========================================================================================\n",
              "Total params: 3\n",
              "Trainable params: 3\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# モデルのサマリー表示\n",
        "\n",
        "summary(net, (2,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KHOYmE6Psqk"
      },
      "source": [
        "### 最適化アルゴリズムと損失関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Zfv1SnjRPsqk"
      },
      "outputs": [],
      "source": [
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# 最適化関数: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIEA8RBFPsqk"
      },
      "source": [
        "## 6.9 勾配降下法"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bPBqrftvPsql"
      },
      "outputs": [],
      "source": [
        "# 入力データ x_train と正解データ y_train のテンソル化\n",
        "\n",
        "inputs = torch.tensor(x_train).float()\n",
        "labels = torch.tensor(y_train).float()\n",
        "\n",
        "# 正解データはN行1列の行列に変換する\n",
        "labels1 = labels.view((-1,1))\n",
        "\n",
        "# 検証データのテンソル化\n",
        "inputs_test = torch.tensor(x_test).float()\n",
        "labels_test = torch.tensor(y_test).float()\n",
        "\n",
        "# 検証用の正解データもN行1列の行列に変換する\n",
        "labels1_test = labels_test.view((-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (l1): Linear(in_features=2, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net.to(torch.device('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "e3TvdQuOPsql"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n -->\n<!-- Pages: 1 -->\n<svg width=\"216pt\" height=\"391pt\"\n viewBox=\"0.00 0.00 216.00 391.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 387)\">\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-387 212,-387 212,4 -4,4\"/>\n<!-- 1638342988000 -->\n<g id=\"node1\" class=\"node\">\n<title>1638342988000</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"130.5,-31 76.5,-31 76.5,0 130.5,0 130.5,-31\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 1637400052160 -->\n<g id=\"node2\" class=\"node\">\n<title>1637400052160</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"193,-86 14,-86 14,-67 193,-67 193,-86\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">BinaryCrossEntropyBackward0</text>\n</g>\n<!-- 1637400052160&#45;&gt;1638342988000 -->\n<g id=\"edge8\" class=\"edge\">\n<title>1637400052160&#45;&gt;1638342988000</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-66.79C103.5,-60.07 103.5,-50.4 103.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-41.19 103.5,-31.19 100,-41.19 107,-41.19\"/>\n</g>\n<!-- 1637400054800 -->\n<g id=\"node3\" class=\"node\">\n<title>1637400054800</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"160,-141 47,-141 47,-122 160,-122 160,-141\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">SigmoidBackward0</text>\n</g>\n<!-- 1637400054800&#45;&gt;1637400052160 -->\n<g id=\"edge1\" class=\"edge\">\n<title>1637400054800&#45;&gt;1637400052160</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-121.75C103.5,-114.8 103.5,-104.85 103.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-96.09 103.5,-86.09 100,-96.09 107,-96.09\"/>\n</g>\n<!-- 1637400054992 -->\n<g id=\"node4\" class=\"node\">\n<title>1637400054992</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"154,-196 53,-196 53,-177 154,-177 154,-196\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 1637400054992&#45;&gt;1637400054800 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1637400054992&#45;&gt;1637400054800</title>\n<path fill=\"none\" stroke=\"black\" d=\"M103.5,-176.75C103.5,-169.8 103.5,-159.85 103.5,-151.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"107,-151.09 103.5,-141.09 100,-151.09 107,-151.09\"/>\n</g>\n<!-- 1637400051824 -->\n<g id=\"node5\" class=\"node\">\n<title>1637400051824</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-251 0,-251 0,-232 101,-232 101,-251\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 1637400051824&#45;&gt;1637400054992 -->\n<g id=\"edge3\" class=\"edge\">\n<title>1637400051824&#45;&gt;1637400054992</title>\n<path fill=\"none\" stroke=\"black\" d=\"M59.25,-231.75C66.97,-224.03 78.4,-212.6 87.72,-203.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"90.31,-205.64 94.91,-196.09 85.36,-200.69 90.31,-205.64\"/>\n</g>\n<!-- 1638341652208 -->\n<g id=\"node6\" class=\"node\">\n<title>1638341652208</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"80,-317 21,-317 21,-287 80,-287 80,-317\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\">l1.bias</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n</g>\n<!-- 1638341652208&#45;&gt;1637400051824 -->\n<g id=\"edge4\" class=\"edge\">\n<title>1638341652208&#45;&gt;1637400051824</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-286.84C50.5,-279.21 50.5,-269.7 50.5,-261.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-261.27 50.5,-251.27 47,-261.27 54,-261.27\"/>\n</g>\n<!-- 1637400052688 -->\n<g id=\"node7\" class=\"node\">\n<title>1637400052688</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"196,-251 119,-251 119,-232 196,-232 196,-251\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 1637400052688&#45;&gt;1637400054992 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1637400052688&#45;&gt;1637400054992</title>\n<path fill=\"none\" stroke=\"black\" d=\"M148.58,-231.75C140.72,-224.03 129.07,-212.6 119.58,-203.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"121.84,-200.6 112.25,-196.09 116.94,-205.59 121.84,-200.6\"/>\n</g>\n<!-- 1637400053504 -->\n<g id=\"node8\" class=\"node\">\n<title>1637400053504</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-311.5 107,-311.5 107,-292.5 208,-292.5 208,-311.5\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-299.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 1637400053504&#45;&gt;1637400052688 -->\n<g id=\"edge6\" class=\"edge\">\n<title>1637400053504&#45;&gt;1637400052688</title>\n<path fill=\"none\" stroke=\"black\" d=\"M157.5,-292.37C157.5,-284.25 157.5,-271.81 157.5,-261.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161,-261.17 157.5,-251.17 154,-261.17 161,-261.17\"/>\n</g>\n<!-- 1638341652368 -->\n<g id=\"node9\" class=\"node\">\n<title>1638341652368</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"193,-383 122,-383 122,-353 193,-353 193,-383\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">l1.weight</text>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-360\" font-family=\"monospace\" font-size=\"10.00\"> (1, 2)</text>\n</g>\n<!-- 1638341652368&#45;&gt;1637400053504 -->\n<g id=\"edge7\" class=\"edge\">\n<title>1638341652368&#45;&gt;1637400053504</title>\n<path fill=\"none\" stroke=\"black\" d=\"M157.5,-352.8C157.5,-343.7 157.5,-331.79 157.5,-321.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161,-321.84 157.5,-311.84 154,-321.84 161,-321.84\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x17d3c9a0490>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 予測計算\n",
        "outputs = net(inputs)\n",
        "\n",
        "# 損失計算\n",
        "loss = criterion(outputs, labels1)\n",
        "\n",
        "# 損失の計算グラフ可視化\n",
        "g = make_dot(loss, params=dict(net.named_parameters()))\n",
        "display(g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.772893905639648"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ciIvpF8Psql"
      },
      "source": [
        "### 繰り返し計算"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "syR4VfrZPsql"
      },
      "outputs": [],
      "source": [
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# 初期化\n",
        "net = Net(n_input, n_output)\n",
        "\n",
        "# 損失関数： 交差エントロピー関数\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# 最適化関数: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 10000\n",
        "\n",
        "# 記録用リストの初期化\n",
        "history = np.zeros((0,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "50gln2ooPsqm",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [0/10000], loss: 4.77289 acc: 0.50000 val_loss: 4.49384, val_acc: 0.50000\n",
            "Epoch [10/10000], loss: 3.80546 acc: 0.50000 val_loss: 3.56537, val_acc: 0.50000\n",
            "Epoch [20/10000], loss: 2.84328 acc: 0.50000 val_loss: 2.64328, val_acc: 0.50000\n",
            "Epoch [30/10000], loss: 1.91613 acc: 0.50000 val_loss: 1.76244, val_acc: 0.50000\n",
            "Epoch [40/10000], loss: 1.17137 acc: 0.50000 val_loss: 1.08537, val_acc: 0.50000\n",
            "Epoch [50/10000], loss: 0.84140 acc: 0.50000 val_loss: 0.81872, val_acc: 0.50000\n",
            "Epoch [60/10000], loss: 0.77087 acc: 0.50000 val_loss: 0.77093, val_acc: 0.50000\n",
            "Epoch [70/10000], loss: 0.75450 acc: 0.34286 val_loss: 0.76105, val_acc: 0.33333\n",
            "Epoch [80/10000], loss: 0.74542 acc: 0.25714 val_loss: 0.75447, val_acc: 0.20000\n",
            "Epoch [90/10000], loss: 0.73734 acc: 0.24286 val_loss: 0.74778, val_acc: 0.16667\n",
            "Epoch [100/10000], loss: 0.72949 acc: 0.24286 val_loss: 0.74098, val_acc: 0.13333\n",
            "Epoch [110/10000], loss: 0.72180 acc: 0.27143 val_loss: 0.73419, val_acc: 0.16667\n",
            "Epoch [120/10000], loss: 0.71423 acc: 0.31429 val_loss: 0.72748, val_acc: 0.20000\n",
            "Epoch [130/10000], loss: 0.70680 acc: 0.41429 val_loss: 0.72087, val_acc: 0.20000\n",
            "Epoch [140/10000], loss: 0.69949 acc: 0.47143 val_loss: 0.71437, val_acc: 0.26667\n",
            "Epoch [150/10000], loss: 0.69230 acc: 0.52857 val_loss: 0.70797, val_acc: 0.30000\n",
            "Epoch [160/10000], loss: 0.68524 acc: 0.60000 val_loss: 0.70167, val_acc: 0.36667\n",
            "Epoch [170/10000], loss: 0.67829 acc: 0.62857 val_loss: 0.69548, val_acc: 0.43333\n",
            "Epoch [180/10000], loss: 0.67147 acc: 0.68571 val_loss: 0.68938, val_acc: 0.50000\n",
            "Epoch [190/10000], loss: 0.66476 acc: 0.75714 val_loss: 0.68339, val_acc: 0.56667\n",
            "Epoch [200/10000], loss: 0.65816 acc: 0.81429 val_loss: 0.67749, val_acc: 0.70000\n",
            "Epoch [210/10000], loss: 0.65168 acc: 0.84286 val_loss: 0.67169, val_acc: 0.70000\n",
            "Epoch [220/10000], loss: 0.64531 acc: 0.85714 val_loss: 0.66599, val_acc: 0.73333\n",
            "Epoch [230/10000], loss: 0.63904 acc: 0.85714 val_loss: 0.66037, val_acc: 0.76667\n",
            "Epoch [240/10000], loss: 0.63288 acc: 0.88571 val_loss: 0.65485, val_acc: 0.80000\n",
            "Epoch [250/10000], loss: 0.62682 acc: 0.88571 val_loss: 0.64942, val_acc: 0.83333\n",
            "Epoch [260/10000], loss: 0.62087 acc: 0.90000 val_loss: 0.64408, val_acc: 0.83333\n",
            "Epoch [270/10000], loss: 0.61501 acc: 0.91429 val_loss: 0.63882, val_acc: 0.83333\n",
            "Epoch [280/10000], loss: 0.60925 acc: 0.92857 val_loss: 0.63364, val_acc: 0.86667\n",
            "Epoch [290/10000], loss: 0.60359 acc: 0.94286 val_loss: 0.62855, val_acc: 0.90000\n",
            "Epoch [300/10000], loss: 0.59803 acc: 0.94286 val_loss: 0.62354, val_acc: 0.90000\n",
            "Epoch [310/10000], loss: 0.59255 acc: 0.94286 val_loss: 0.61861, val_acc: 0.90000\n",
            "Epoch [320/10000], loss: 0.58717 acc: 0.94286 val_loss: 0.61376, val_acc: 0.93333\n",
            "Epoch [330/10000], loss: 0.58187 acc: 0.94286 val_loss: 0.60899, val_acc: 0.93333\n",
            "Epoch [340/10000], loss: 0.57667 acc: 0.97143 val_loss: 0.60429, val_acc: 0.93333\n",
            "Epoch [350/10000], loss: 0.57154 acc: 0.97143 val_loss: 0.59967, val_acc: 0.93333\n",
            "Epoch [360/10000], loss: 0.56650 acc: 0.97143 val_loss: 0.59512, val_acc: 0.93333\n",
            "Epoch [370/10000], loss: 0.56155 acc: 0.98571 val_loss: 0.59064, val_acc: 0.93333\n",
            "Epoch [380/10000], loss: 0.55667 acc: 0.98571 val_loss: 0.58623, val_acc: 0.93333\n",
            "Epoch [390/10000], loss: 0.55188 acc: 0.98571 val_loss: 0.58189, val_acc: 0.93333\n",
            "Epoch [400/10000], loss: 0.54716 acc: 0.98571 val_loss: 0.57762, val_acc: 0.93333\n",
            "Epoch [410/10000], loss: 0.54251 acc: 0.98571 val_loss: 0.57341, val_acc: 0.93333\n",
            "Epoch [420/10000], loss: 0.53795 acc: 0.98571 val_loss: 0.56927, val_acc: 0.93333\n",
            "Epoch [430/10000], loss: 0.53345 acc: 1.00000 val_loss: 0.56519, val_acc: 0.93333\n",
            "Epoch [440/10000], loss: 0.52902 acc: 1.00000 val_loss: 0.56117, val_acc: 0.93333\n",
            "Epoch [450/10000], loss: 0.52467 acc: 1.00000 val_loss: 0.55722, val_acc: 0.93333\n",
            "Epoch [460/10000], loss: 0.52038 acc: 1.00000 val_loss: 0.55333, val_acc: 0.93333\n",
            "Epoch [470/10000], loss: 0.51617 acc: 1.00000 val_loss: 0.54949, val_acc: 0.93333\n",
            "Epoch [480/10000], loss: 0.51201 acc: 1.00000 val_loss: 0.54571, val_acc: 0.93333\n",
            "Epoch [490/10000], loss: 0.50793 acc: 1.00000 val_loss: 0.54199, val_acc: 0.93333\n",
            "Epoch [500/10000], loss: 0.50390 acc: 1.00000 val_loss: 0.53833, val_acc: 0.93333\n",
            "Epoch [510/10000], loss: 0.49994 acc: 1.00000 val_loss: 0.53472, val_acc: 0.93333\n",
            "Epoch [520/10000], loss: 0.49604 acc: 1.00000 val_loss: 0.53116, val_acc: 0.93333\n",
            "Epoch [530/10000], loss: 0.49219 acc: 1.00000 val_loss: 0.52766, val_acc: 0.93333\n",
            "Epoch [540/10000], loss: 0.48841 acc: 1.00000 val_loss: 0.52421, val_acc: 0.93333\n",
            "Epoch [550/10000], loss: 0.48468 acc: 1.00000 val_loss: 0.52080, val_acc: 0.93333\n",
            "Epoch [560/10000], loss: 0.48101 acc: 1.00000 val_loss: 0.51745, val_acc: 0.93333\n",
            "Epoch [570/10000], loss: 0.47740 acc: 1.00000 val_loss: 0.51415, val_acc: 0.93333\n",
            "Epoch [580/10000], loss: 0.47384 acc: 1.00000 val_loss: 0.51089, val_acc: 0.93333\n",
            "Epoch [590/10000], loss: 0.47033 acc: 1.00000 val_loss: 0.50769, val_acc: 0.93333\n",
            "Epoch [600/10000], loss: 0.46687 acc: 1.00000 val_loss: 0.50452, val_acc: 0.93333\n",
            "Epoch [610/10000], loss: 0.46347 acc: 1.00000 val_loss: 0.50141, val_acc: 0.93333\n",
            "Epoch [620/10000], loss: 0.46011 acc: 1.00000 val_loss: 0.49833, val_acc: 0.93333\n",
            "Epoch [630/10000], loss: 0.45680 acc: 1.00000 val_loss: 0.49530, val_acc: 0.93333\n",
            "Epoch [640/10000], loss: 0.45355 acc: 1.00000 val_loss: 0.49232, val_acc: 0.93333\n",
            "Epoch [650/10000], loss: 0.45033 acc: 1.00000 val_loss: 0.48937, val_acc: 0.93333\n",
            "Epoch [660/10000], loss: 0.44717 acc: 1.00000 val_loss: 0.48647, val_acc: 0.93333\n",
            "Epoch [670/10000], loss: 0.44405 acc: 1.00000 val_loss: 0.48360, val_acc: 0.93333\n",
            "Epoch [680/10000], loss: 0.44097 acc: 1.00000 val_loss: 0.48078, val_acc: 0.93333\n",
            "Epoch [690/10000], loss: 0.43794 acc: 1.00000 val_loss: 0.47800, val_acc: 0.93333\n",
            "Epoch [700/10000], loss: 0.43495 acc: 1.00000 val_loss: 0.47525, val_acc: 0.93333\n",
            "Epoch [710/10000], loss: 0.43200 acc: 1.00000 val_loss: 0.47254, val_acc: 0.93333\n",
            "Epoch [720/10000], loss: 0.42909 acc: 1.00000 val_loss: 0.46987, val_acc: 0.93333\n",
            "Epoch [730/10000], loss: 0.42623 acc: 1.00000 val_loss: 0.46723, val_acc: 0.93333\n",
            "Epoch [740/10000], loss: 0.42340 acc: 1.00000 val_loss: 0.46463, val_acc: 0.93333\n",
            "Epoch [750/10000], loss: 0.42061 acc: 1.00000 val_loss: 0.46206, val_acc: 0.93333\n",
            "Epoch [760/10000], loss: 0.41786 acc: 1.00000 val_loss: 0.45953, val_acc: 0.93333\n",
            "Epoch [770/10000], loss: 0.41515 acc: 1.00000 val_loss: 0.45703, val_acc: 0.93333\n",
            "Epoch [780/10000], loss: 0.41247 acc: 1.00000 val_loss: 0.45457, val_acc: 0.93333\n",
            "Epoch [790/10000], loss: 0.40983 acc: 1.00000 val_loss: 0.45213, val_acc: 0.93333\n",
            "Epoch [800/10000], loss: 0.40722 acc: 1.00000 val_loss: 0.44973, val_acc: 0.93333\n",
            "Epoch [810/10000], loss: 0.40465 acc: 1.00000 val_loss: 0.44736, val_acc: 0.93333\n",
            "Epoch [820/10000], loss: 0.40211 acc: 1.00000 val_loss: 0.44502, val_acc: 0.93333\n",
            "Epoch [830/10000], loss: 0.39961 acc: 1.00000 val_loss: 0.44271, val_acc: 0.93333\n",
            "Epoch [840/10000], loss: 0.39714 acc: 1.00000 val_loss: 0.44043, val_acc: 0.93333\n",
            "Epoch [850/10000], loss: 0.39470 acc: 1.00000 val_loss: 0.43818, val_acc: 0.93333\n",
            "Epoch [860/10000], loss: 0.39229 acc: 1.00000 val_loss: 0.43596, val_acc: 0.93333\n",
            "Epoch [870/10000], loss: 0.38992 acc: 1.00000 val_loss: 0.43377, val_acc: 0.93333\n",
            "Epoch [880/10000], loss: 0.38757 acc: 1.00000 val_loss: 0.43160, val_acc: 0.93333\n",
            "Epoch [890/10000], loss: 0.38525 acc: 1.00000 val_loss: 0.42946, val_acc: 0.96667\n",
            "Epoch [900/10000], loss: 0.38297 acc: 1.00000 val_loss: 0.42735, val_acc: 0.96667\n",
            "Epoch [910/10000], loss: 0.38071 acc: 1.00000 val_loss: 0.42526, val_acc: 0.96667\n",
            "Epoch [920/10000], loss: 0.37848 acc: 1.00000 val_loss: 0.42320, val_acc: 0.96667\n",
            "Epoch [930/10000], loss: 0.37628 acc: 1.00000 val_loss: 0.42116, val_acc: 0.96667\n",
            "Epoch [940/10000], loss: 0.37410 acc: 1.00000 val_loss: 0.41915, val_acc: 0.96667\n",
            "Epoch [950/10000], loss: 0.37196 acc: 1.00000 val_loss: 0.41717, val_acc: 0.96667\n",
            "Epoch [960/10000], loss: 0.36983 acc: 1.00000 val_loss: 0.41520, val_acc: 0.96667\n",
            "Epoch [970/10000], loss: 0.36774 acc: 1.00000 val_loss: 0.41327, val_acc: 0.96667\n",
            "Epoch [980/10000], loss: 0.36567 acc: 1.00000 val_loss: 0.41135, val_acc: 0.96667\n",
            "Epoch [990/10000], loss: 0.36362 acc: 1.00000 val_loss: 0.40946, val_acc: 0.96667\n",
            "Epoch [1000/10000], loss: 0.36160 acc: 1.00000 val_loss: 0.40759, val_acc: 0.96667\n",
            "Epoch [1010/10000], loss: 0.35961 acc: 1.00000 val_loss: 0.40574, val_acc: 0.96667\n",
            "Epoch [1020/10000], loss: 0.35763 acc: 1.00000 val_loss: 0.40391, val_acc: 0.96667\n",
            "Epoch [1030/10000], loss: 0.35568 acc: 1.00000 val_loss: 0.40211, val_acc: 0.96667\n",
            "Epoch [1040/10000], loss: 0.35376 acc: 1.00000 val_loss: 0.40032, val_acc: 0.96667\n",
            "Epoch [1050/10000], loss: 0.35185 acc: 1.00000 val_loss: 0.39856, val_acc: 0.96667\n",
            "Epoch [1060/10000], loss: 0.34997 acc: 1.00000 val_loss: 0.39682, val_acc: 0.96667\n",
            "Epoch [1070/10000], loss: 0.34811 acc: 1.00000 val_loss: 0.39509, val_acc: 0.96667\n",
            "Epoch [1080/10000], loss: 0.34628 acc: 1.00000 val_loss: 0.39339, val_acc: 0.96667\n",
            "Epoch [1090/10000], loss: 0.34446 acc: 1.00000 val_loss: 0.39171, val_acc: 0.96667\n",
            "Epoch [1100/10000], loss: 0.34266 acc: 1.00000 val_loss: 0.39004, val_acc: 0.96667\n",
            "Epoch [1110/10000], loss: 0.34089 acc: 1.00000 val_loss: 0.38839, val_acc: 0.96667\n",
            "Epoch [1120/10000], loss: 0.33913 acc: 1.00000 val_loss: 0.38677, val_acc: 0.96667\n",
            "Epoch [1130/10000], loss: 0.33739 acc: 1.00000 val_loss: 0.38516, val_acc: 0.96667\n",
            "Epoch [1140/10000], loss: 0.33568 acc: 1.00000 val_loss: 0.38356, val_acc: 0.96667\n",
            "Epoch [1150/10000], loss: 0.33398 acc: 1.00000 val_loss: 0.38199, val_acc: 0.96667\n",
            "Epoch [1160/10000], loss: 0.33230 acc: 1.00000 val_loss: 0.38043, val_acc: 0.96667\n",
            "Epoch [1170/10000], loss: 0.33064 acc: 1.00000 val_loss: 0.37889, val_acc: 0.96667\n",
            "Epoch [1180/10000], loss: 0.32900 acc: 1.00000 val_loss: 0.37737, val_acc: 0.96667\n",
            "Epoch [1190/10000], loss: 0.32737 acc: 1.00000 val_loss: 0.37586, val_acc: 0.96667\n",
            "Epoch [1200/10000], loss: 0.32577 acc: 1.00000 val_loss: 0.37437, val_acc: 0.96667\n",
            "Epoch [1210/10000], loss: 0.32418 acc: 1.00000 val_loss: 0.37290, val_acc: 0.96667\n",
            "Epoch [1220/10000], loss: 0.32260 acc: 1.00000 val_loss: 0.37144, val_acc: 0.96667\n",
            "Epoch [1230/10000], loss: 0.32105 acc: 1.00000 val_loss: 0.37000, val_acc: 0.96667\n",
            "Epoch [1240/10000], loss: 0.31951 acc: 1.00000 val_loss: 0.36857, val_acc: 0.96667\n",
            "Epoch [1250/10000], loss: 0.31799 acc: 1.00000 val_loss: 0.36716, val_acc: 0.96667\n",
            "Epoch [1260/10000], loss: 0.31648 acc: 1.00000 val_loss: 0.36576, val_acc: 0.96667\n",
            "Epoch [1270/10000], loss: 0.31499 acc: 1.00000 val_loss: 0.36437, val_acc: 0.96667\n",
            "Epoch [1280/10000], loss: 0.31351 acc: 1.00000 val_loss: 0.36301, val_acc: 0.96667\n",
            "Epoch [1290/10000], loss: 0.31205 acc: 1.00000 val_loss: 0.36165, val_acc: 0.96667\n",
            "Epoch [1300/10000], loss: 0.31061 acc: 1.00000 val_loss: 0.36031, val_acc: 0.96667\n",
            "Epoch [1310/10000], loss: 0.30918 acc: 1.00000 val_loss: 0.35898, val_acc: 0.96667\n",
            "Epoch [1320/10000], loss: 0.30776 acc: 1.00000 val_loss: 0.35767, val_acc: 0.96667\n",
            "Epoch [1330/10000], loss: 0.30636 acc: 1.00000 val_loss: 0.35637, val_acc: 0.96667\n",
            "Epoch [1340/10000], loss: 0.30498 acc: 1.00000 val_loss: 0.35508, val_acc: 0.96667\n",
            "Epoch [1350/10000], loss: 0.30360 acc: 1.00000 val_loss: 0.35381, val_acc: 0.96667\n",
            "Epoch [1360/10000], loss: 0.30224 acc: 1.00000 val_loss: 0.35255, val_acc: 0.96667\n",
            "Epoch [1370/10000], loss: 0.30090 acc: 1.00000 val_loss: 0.35130, val_acc: 0.96667\n",
            "Epoch [1380/10000], loss: 0.29957 acc: 1.00000 val_loss: 0.35006, val_acc: 0.96667\n",
            "Epoch [1390/10000], loss: 0.29825 acc: 1.00000 val_loss: 0.34884, val_acc: 0.96667\n",
            "Epoch [1400/10000], loss: 0.29694 acc: 1.00000 val_loss: 0.34763, val_acc: 0.96667\n",
            "Epoch [1410/10000], loss: 0.29565 acc: 1.00000 val_loss: 0.34643, val_acc: 0.96667\n",
            "Epoch [1420/10000], loss: 0.29437 acc: 1.00000 val_loss: 0.34524, val_acc: 0.96667\n",
            "Epoch [1430/10000], loss: 0.29310 acc: 1.00000 val_loss: 0.34406, val_acc: 0.96667\n",
            "Epoch [1440/10000], loss: 0.29184 acc: 1.00000 val_loss: 0.34290, val_acc: 0.96667\n",
            "Epoch [1450/10000], loss: 0.29060 acc: 1.00000 val_loss: 0.34174, val_acc: 0.96667\n",
            "Epoch [1460/10000], loss: 0.28937 acc: 1.00000 val_loss: 0.34060, val_acc: 0.96667\n",
            "Epoch [1470/10000], loss: 0.28815 acc: 1.00000 val_loss: 0.33947, val_acc: 0.96667\n",
            "Epoch [1480/10000], loss: 0.28694 acc: 1.00000 val_loss: 0.33834, val_acc: 0.96667\n",
            "Epoch [1490/10000], loss: 0.28574 acc: 1.00000 val_loss: 0.33723, val_acc: 0.96667\n",
            "Epoch [1500/10000], loss: 0.28456 acc: 1.00000 val_loss: 0.33613, val_acc: 0.96667\n",
            "Epoch [1510/10000], loss: 0.28338 acc: 1.00000 val_loss: 0.33504, val_acc: 0.96667\n",
            "Epoch [1520/10000], loss: 0.28222 acc: 1.00000 val_loss: 0.33396, val_acc: 0.96667\n",
            "Epoch [1530/10000], loss: 0.28106 acc: 1.00000 val_loss: 0.33289, val_acc: 0.96667\n",
            "Epoch [1540/10000], loss: 0.27992 acc: 1.00000 val_loss: 0.33183, val_acc: 0.96667\n",
            "Epoch [1550/10000], loss: 0.27879 acc: 1.00000 val_loss: 0.33078, val_acc: 0.96667\n",
            "Epoch [1560/10000], loss: 0.27767 acc: 1.00000 val_loss: 0.32974, val_acc: 0.96667\n",
            "Epoch [1570/10000], loss: 0.27656 acc: 1.00000 val_loss: 0.32871, val_acc: 0.96667\n",
            "Epoch [1580/10000], loss: 0.27545 acc: 1.00000 val_loss: 0.32769, val_acc: 0.96667\n",
            "Epoch [1590/10000], loss: 0.27436 acc: 1.00000 val_loss: 0.32668, val_acc: 0.96667\n",
            "Epoch [1600/10000], loss: 0.27328 acc: 1.00000 val_loss: 0.32568, val_acc: 0.96667\n",
            "Epoch [1610/10000], loss: 0.27221 acc: 1.00000 val_loss: 0.32468, val_acc: 0.96667\n",
            "Epoch [1620/10000], loss: 0.27115 acc: 1.00000 val_loss: 0.32370, val_acc: 0.96667\n",
            "Epoch [1630/10000], loss: 0.27009 acc: 1.00000 val_loss: 0.32272, val_acc: 0.96667\n",
            "Epoch [1640/10000], loss: 0.26905 acc: 1.00000 val_loss: 0.32175, val_acc: 0.96667\n",
            "Epoch [1650/10000], loss: 0.26802 acc: 1.00000 val_loss: 0.32080, val_acc: 0.96667\n",
            "Epoch [1660/10000], loss: 0.26699 acc: 1.00000 val_loss: 0.31985, val_acc: 0.96667\n",
            "Epoch [1670/10000], loss: 0.26597 acc: 1.00000 val_loss: 0.31890, val_acc: 0.96667\n",
            "Epoch [1680/10000], loss: 0.26497 acc: 1.00000 val_loss: 0.31797, val_acc: 0.96667\n",
            "Epoch [1690/10000], loss: 0.26397 acc: 1.00000 val_loss: 0.31704, val_acc: 0.96667\n",
            "Epoch [1700/10000], loss: 0.26298 acc: 1.00000 val_loss: 0.31613, val_acc: 0.96667\n",
            "Epoch [1710/10000], loss: 0.26199 acc: 1.00000 val_loss: 0.31522, val_acc: 0.96667\n",
            "Epoch [1720/10000], loss: 0.26102 acc: 1.00000 val_loss: 0.31431, val_acc: 0.96667\n",
            "Epoch [1730/10000], loss: 0.26005 acc: 1.00000 val_loss: 0.31342, val_acc: 0.96667\n",
            "Epoch [1740/10000], loss: 0.25910 acc: 1.00000 val_loss: 0.31253, val_acc: 0.96667\n",
            "Epoch [1750/10000], loss: 0.25815 acc: 1.00000 val_loss: 0.31165, val_acc: 0.96667\n",
            "Epoch [1760/10000], loss: 0.25721 acc: 1.00000 val_loss: 0.31078, val_acc: 0.96667\n",
            "Epoch [1770/10000], loss: 0.25627 acc: 1.00000 val_loss: 0.30992, val_acc: 0.96667\n",
            "Epoch [1780/10000], loss: 0.25535 acc: 1.00000 val_loss: 0.30906, val_acc: 0.96667\n",
            "Epoch [1790/10000], loss: 0.25443 acc: 1.00000 val_loss: 0.30821, val_acc: 0.96667\n",
            "Epoch [1800/10000], loss: 0.25352 acc: 1.00000 val_loss: 0.30737, val_acc: 0.96667\n",
            "Epoch [1810/10000], loss: 0.25262 acc: 1.00000 val_loss: 0.30653, val_acc: 0.96667\n",
            "Epoch [1820/10000], loss: 0.25172 acc: 1.00000 val_loss: 0.30571, val_acc: 0.96667\n",
            "Epoch [1830/10000], loss: 0.25083 acc: 1.00000 val_loss: 0.30488, val_acc: 0.96667\n",
            "Epoch [1840/10000], loss: 0.24995 acc: 1.00000 val_loss: 0.30407, val_acc: 0.96667\n",
            "Epoch [1850/10000], loss: 0.24908 acc: 1.00000 val_loss: 0.30326, val_acc: 0.96667\n",
            "Epoch [1860/10000], loss: 0.24821 acc: 1.00000 val_loss: 0.30246, val_acc: 0.96667\n",
            "Epoch [1870/10000], loss: 0.24735 acc: 1.00000 val_loss: 0.30166, val_acc: 0.96667\n",
            "Epoch [1880/10000], loss: 0.24650 acc: 1.00000 val_loss: 0.30088, val_acc: 0.96667\n",
            "Epoch [1890/10000], loss: 0.24565 acc: 1.00000 val_loss: 0.30009, val_acc: 0.96667\n",
            "Epoch [1900/10000], loss: 0.24481 acc: 1.00000 val_loss: 0.29932, val_acc: 0.96667\n",
            "Epoch [1910/10000], loss: 0.24398 acc: 1.00000 val_loss: 0.29855, val_acc: 0.96667\n",
            "Epoch [1920/10000], loss: 0.24315 acc: 1.00000 val_loss: 0.29778, val_acc: 0.96667\n",
            "Epoch [1930/10000], loss: 0.24233 acc: 1.00000 val_loss: 0.29702, val_acc: 0.96667\n",
            "Epoch [1940/10000], loss: 0.24152 acc: 1.00000 val_loss: 0.29627, val_acc: 0.96667\n",
            "Epoch [1950/10000], loss: 0.24071 acc: 1.00000 val_loss: 0.29553, val_acc: 0.96667\n",
            "Epoch [1960/10000], loss: 0.23991 acc: 1.00000 val_loss: 0.29479, val_acc: 0.96667\n",
            "Epoch [1970/10000], loss: 0.23911 acc: 1.00000 val_loss: 0.29405, val_acc: 0.96667\n",
            "Epoch [1980/10000], loss: 0.23833 acc: 1.00000 val_loss: 0.29332, val_acc: 0.96667\n",
            "Epoch [1990/10000], loss: 0.23754 acc: 1.00000 val_loss: 0.29260, val_acc: 0.96667\n",
            "Epoch [2000/10000], loss: 0.23677 acc: 1.00000 val_loss: 0.29188, val_acc: 0.96667\n",
            "Epoch [2010/10000], loss: 0.23599 acc: 1.00000 val_loss: 0.29117, val_acc: 0.96667\n",
            "Epoch [2020/10000], loss: 0.23523 acc: 1.00000 val_loss: 0.29047, val_acc: 0.96667\n",
            "Epoch [2030/10000], loss: 0.23447 acc: 1.00000 val_loss: 0.28977, val_acc: 0.96667\n",
            "Epoch [2040/10000], loss: 0.23372 acc: 1.00000 val_loss: 0.28907, val_acc: 0.96667\n",
            "Epoch [2050/10000], loss: 0.23297 acc: 1.00000 val_loss: 0.28838, val_acc: 0.96667\n",
            "Epoch [2060/10000], loss: 0.23223 acc: 1.00000 val_loss: 0.28770, val_acc: 0.96667\n",
            "Epoch [2070/10000], loss: 0.23149 acc: 1.00000 val_loss: 0.28702, val_acc: 0.96667\n",
            "Epoch [2080/10000], loss: 0.23076 acc: 1.00000 val_loss: 0.28634, val_acc: 0.96667\n",
            "Epoch [2090/10000], loss: 0.23003 acc: 1.00000 val_loss: 0.28567, val_acc: 0.96667\n",
            "Epoch [2100/10000], loss: 0.22931 acc: 1.00000 val_loss: 0.28501, val_acc: 0.96667\n",
            "Epoch [2110/10000], loss: 0.22859 acc: 1.00000 val_loss: 0.28435, val_acc: 0.96667\n",
            "Epoch [2120/10000], loss: 0.22788 acc: 1.00000 val_loss: 0.28369, val_acc: 0.96667\n",
            "Epoch [2130/10000], loss: 0.22718 acc: 1.00000 val_loss: 0.28304, val_acc: 0.96667\n",
            "Epoch [2140/10000], loss: 0.22648 acc: 1.00000 val_loss: 0.28240, val_acc: 0.96667\n",
            "Epoch [2150/10000], loss: 0.22578 acc: 1.00000 val_loss: 0.28176, val_acc: 0.96667\n",
            "Epoch [2160/10000], loss: 0.22509 acc: 1.00000 val_loss: 0.28112, val_acc: 0.96667\n",
            "Epoch [2170/10000], loss: 0.22441 acc: 1.00000 val_loss: 0.28049, val_acc: 0.96667\n",
            "Epoch [2180/10000], loss: 0.22373 acc: 1.00000 val_loss: 0.27986, val_acc: 0.96667\n",
            "Epoch [2190/10000], loss: 0.22305 acc: 1.00000 val_loss: 0.27924, val_acc: 0.96667\n",
            "Epoch [2200/10000], loss: 0.22238 acc: 1.00000 val_loss: 0.27862, val_acc: 0.96667\n",
            "Epoch [2210/10000], loss: 0.22171 acc: 1.00000 val_loss: 0.27801, val_acc: 0.96667\n",
            "Epoch [2220/10000], loss: 0.22105 acc: 1.00000 val_loss: 0.27740, val_acc: 0.96667\n",
            "Epoch [2230/10000], loss: 0.22039 acc: 1.00000 val_loss: 0.27680, val_acc: 0.96667\n",
            "Epoch [2240/10000], loss: 0.21974 acc: 1.00000 val_loss: 0.27620, val_acc: 0.96667\n",
            "Epoch [2250/10000], loss: 0.21909 acc: 1.00000 val_loss: 0.27560, val_acc: 0.96667\n",
            "Epoch [2260/10000], loss: 0.21845 acc: 1.00000 val_loss: 0.27501, val_acc: 0.96667\n",
            "Epoch [2270/10000], loss: 0.21781 acc: 1.00000 val_loss: 0.27442, val_acc: 0.96667\n",
            "Epoch [2280/10000], loss: 0.21718 acc: 1.00000 val_loss: 0.27384, val_acc: 0.96667\n",
            "Epoch [2290/10000], loss: 0.21655 acc: 1.00000 val_loss: 0.27326, val_acc: 0.96667\n",
            "Epoch [2300/10000], loss: 0.21592 acc: 1.00000 val_loss: 0.27269, val_acc: 0.96667\n",
            "Epoch [2310/10000], loss: 0.21530 acc: 1.00000 val_loss: 0.27211, val_acc: 0.96667\n",
            "Epoch [2320/10000], loss: 0.21468 acc: 1.00000 val_loss: 0.27155, val_acc: 0.96667\n",
            "Epoch [2330/10000], loss: 0.21407 acc: 1.00000 val_loss: 0.27098, val_acc: 0.96667\n",
            "Epoch [2340/10000], loss: 0.21346 acc: 1.00000 val_loss: 0.27042, val_acc: 0.96667\n",
            "Epoch [2350/10000], loss: 0.21285 acc: 1.00000 val_loss: 0.26987, val_acc: 0.96667\n",
            "Epoch [2360/10000], loss: 0.21225 acc: 1.00000 val_loss: 0.26932, val_acc: 0.96667\n",
            "Epoch [2370/10000], loss: 0.21165 acc: 1.00000 val_loss: 0.26877, val_acc: 0.96667\n",
            "Epoch [2380/10000], loss: 0.21106 acc: 1.00000 val_loss: 0.26822, val_acc: 0.96667\n",
            "Epoch [2390/10000], loss: 0.21047 acc: 1.00000 val_loss: 0.26768, val_acc: 0.96667\n",
            "Epoch [2400/10000], loss: 0.20988 acc: 1.00000 val_loss: 0.26715, val_acc: 0.96667\n",
            "Epoch [2410/10000], loss: 0.20930 acc: 1.00000 val_loss: 0.26661, val_acc: 0.96667\n",
            "Epoch [2420/10000], loss: 0.20872 acc: 1.00000 val_loss: 0.26608, val_acc: 0.96667\n",
            "Epoch [2430/10000], loss: 0.20815 acc: 1.00000 val_loss: 0.26556, val_acc: 0.96667\n",
            "Epoch [2440/10000], loss: 0.20758 acc: 1.00000 val_loss: 0.26503, val_acc: 0.96667\n",
            "Epoch [2450/10000], loss: 0.20701 acc: 1.00000 val_loss: 0.26451, val_acc: 0.96667\n",
            "Epoch [2460/10000], loss: 0.20645 acc: 1.00000 val_loss: 0.26400, val_acc: 0.96667\n",
            "Epoch [2470/10000], loss: 0.20589 acc: 1.00000 val_loss: 0.26349, val_acc: 0.96667\n",
            "Epoch [2480/10000], loss: 0.20533 acc: 1.00000 val_loss: 0.26298, val_acc: 0.96667\n",
            "Epoch [2490/10000], loss: 0.20478 acc: 1.00000 val_loss: 0.26247, val_acc: 0.96667\n",
            "Epoch [2500/10000], loss: 0.20423 acc: 1.00000 val_loss: 0.26197, val_acc: 0.96667\n",
            "Epoch [2510/10000], loss: 0.20369 acc: 1.00000 val_loss: 0.26147, val_acc: 0.96667\n",
            "Epoch [2520/10000], loss: 0.20314 acc: 1.00000 val_loss: 0.26097, val_acc: 0.96667\n",
            "Epoch [2530/10000], loss: 0.20261 acc: 1.00000 val_loss: 0.26048, val_acc: 0.96667\n",
            "Epoch [2540/10000], loss: 0.20207 acc: 1.00000 val_loss: 0.25999, val_acc: 0.96667\n",
            "Epoch [2550/10000], loss: 0.20154 acc: 1.00000 val_loss: 0.25950, val_acc: 0.96667\n",
            "Epoch [2560/10000], loss: 0.20101 acc: 1.00000 val_loss: 0.25902, val_acc: 0.96667\n",
            "Epoch [2570/10000], loss: 0.20048 acc: 1.00000 val_loss: 0.25854, val_acc: 0.96667\n",
            "Epoch [2580/10000], loss: 0.19996 acc: 1.00000 val_loss: 0.25806, val_acc: 0.96667\n",
            "Epoch [2590/10000], loss: 0.19944 acc: 1.00000 val_loss: 0.25759, val_acc: 0.96667\n",
            "Epoch [2600/10000], loss: 0.19893 acc: 1.00000 val_loss: 0.25712, val_acc: 0.96667\n",
            "Epoch [2610/10000], loss: 0.19842 acc: 1.00000 val_loss: 0.25665, val_acc: 0.96667\n",
            "Epoch [2620/10000], loss: 0.19791 acc: 1.00000 val_loss: 0.25619, val_acc: 0.96667\n",
            "Epoch [2630/10000], loss: 0.19740 acc: 1.00000 val_loss: 0.25572, val_acc: 0.96667\n",
            "Epoch [2640/10000], loss: 0.19690 acc: 1.00000 val_loss: 0.25526, val_acc: 0.96667\n",
            "Epoch [2650/10000], loss: 0.19640 acc: 1.00000 val_loss: 0.25481, val_acc: 0.96667\n",
            "Epoch [2660/10000], loss: 0.19590 acc: 1.00000 val_loss: 0.25435, val_acc: 0.96667\n",
            "Epoch [2670/10000], loss: 0.19540 acc: 1.00000 val_loss: 0.25390, val_acc: 0.96667\n",
            "Epoch [2680/10000], loss: 0.19491 acc: 1.00000 val_loss: 0.25345, val_acc: 0.96667\n",
            "Epoch [2690/10000], loss: 0.19442 acc: 1.00000 val_loss: 0.25301, val_acc: 0.96667\n",
            "Epoch [2700/10000], loss: 0.19394 acc: 1.00000 val_loss: 0.25257, val_acc: 0.96667\n",
            "Epoch [2710/10000], loss: 0.19346 acc: 1.00000 val_loss: 0.25213, val_acc: 0.96667\n",
            "Epoch [2720/10000], loss: 0.19298 acc: 1.00000 val_loss: 0.25169, val_acc: 0.96667\n",
            "Epoch [2730/10000], loss: 0.19250 acc: 1.00000 val_loss: 0.25125, val_acc: 0.96667\n",
            "Epoch [2740/10000], loss: 0.19202 acc: 1.00000 val_loss: 0.25082, val_acc: 0.96667\n",
            "Epoch [2750/10000], loss: 0.19155 acc: 1.00000 val_loss: 0.25039, val_acc: 0.96667\n",
            "Epoch [2760/10000], loss: 0.19108 acc: 1.00000 val_loss: 0.24997, val_acc: 0.96667\n",
            "Epoch [2770/10000], loss: 0.19062 acc: 1.00000 val_loss: 0.24954, val_acc: 0.96667\n",
            "Epoch [2780/10000], loss: 0.19016 acc: 1.00000 val_loss: 0.24912, val_acc: 0.96667\n",
            "Epoch [2790/10000], loss: 0.18970 acc: 1.00000 val_loss: 0.24870, val_acc: 0.96667\n",
            "Epoch [2800/10000], loss: 0.18924 acc: 1.00000 val_loss: 0.24828, val_acc: 0.96667\n",
            "Epoch [2810/10000], loss: 0.18878 acc: 1.00000 val_loss: 0.24787, val_acc: 0.96667\n",
            "Epoch [2820/10000], loss: 0.18833 acc: 1.00000 val_loss: 0.24746, val_acc: 0.96667\n",
            "Epoch [2830/10000], loss: 0.18788 acc: 1.00000 val_loss: 0.24705, val_acc: 0.96667\n",
            "Epoch [2840/10000], loss: 0.18743 acc: 1.00000 val_loss: 0.24664, val_acc: 0.96667\n",
            "Epoch [2850/10000], loss: 0.18699 acc: 1.00000 val_loss: 0.24624, val_acc: 0.96667\n",
            "Epoch [2860/10000], loss: 0.18654 acc: 1.00000 val_loss: 0.24584, val_acc: 0.96667\n",
            "Epoch [2870/10000], loss: 0.18610 acc: 1.00000 val_loss: 0.24544, val_acc: 0.96667\n",
            "Epoch [2880/10000], loss: 0.18567 acc: 1.00000 val_loss: 0.24504, val_acc: 0.96667\n",
            "Epoch [2890/10000], loss: 0.18523 acc: 1.00000 val_loss: 0.24464, val_acc: 0.96667\n",
            "Epoch [2900/10000], loss: 0.18480 acc: 1.00000 val_loss: 0.24425, val_acc: 0.96667\n",
            "Epoch [2910/10000], loss: 0.18437 acc: 1.00000 val_loss: 0.24386, val_acc: 0.96667\n",
            "Epoch [2920/10000], loss: 0.18394 acc: 1.00000 val_loss: 0.24347, val_acc: 0.96667\n",
            "Epoch [2930/10000], loss: 0.18352 acc: 1.00000 val_loss: 0.24309, val_acc: 0.96667\n",
            "Epoch [2940/10000], loss: 0.18309 acc: 1.00000 val_loss: 0.24270, val_acc: 0.96667\n",
            "Epoch [2950/10000], loss: 0.18267 acc: 1.00000 val_loss: 0.24232, val_acc: 0.96667\n",
            "Epoch [2960/10000], loss: 0.18225 acc: 1.00000 val_loss: 0.24194, val_acc: 0.96667\n",
            "Epoch [2970/10000], loss: 0.18184 acc: 1.00000 val_loss: 0.24156, val_acc: 0.96667\n",
            "Epoch [2980/10000], loss: 0.18142 acc: 1.00000 val_loss: 0.24119, val_acc: 0.96667\n",
            "Epoch [2990/10000], loss: 0.18101 acc: 1.00000 val_loss: 0.24081, val_acc: 0.96667\n",
            "Epoch [3000/10000], loss: 0.18060 acc: 1.00000 val_loss: 0.24044, val_acc: 0.96667\n",
            "Epoch [3010/10000], loss: 0.18019 acc: 1.00000 val_loss: 0.24008, val_acc: 0.96667\n",
            "Epoch [3020/10000], loss: 0.17979 acc: 1.00000 val_loss: 0.23971, val_acc: 0.96667\n",
            "Epoch [3030/10000], loss: 0.17939 acc: 1.00000 val_loss: 0.23934, val_acc: 0.96667\n",
            "Epoch [3040/10000], loss: 0.17899 acc: 1.00000 val_loss: 0.23898, val_acc: 0.96667\n",
            "Epoch [3050/10000], loss: 0.17859 acc: 1.00000 val_loss: 0.23862, val_acc: 0.96667\n",
            "Epoch [3060/10000], loss: 0.17819 acc: 1.00000 val_loss: 0.23826, val_acc: 0.96667\n",
            "Epoch [3070/10000], loss: 0.17780 acc: 1.00000 val_loss: 0.23790, val_acc: 0.96667\n",
            "Epoch [3080/10000], loss: 0.17740 acc: 1.00000 val_loss: 0.23755, val_acc: 0.96667\n",
            "Epoch [3090/10000], loss: 0.17701 acc: 1.00000 val_loss: 0.23720, val_acc: 0.96667\n",
            "Epoch [3100/10000], loss: 0.17662 acc: 1.00000 val_loss: 0.23685, val_acc: 0.96667\n",
            "Epoch [3110/10000], loss: 0.17624 acc: 1.00000 val_loss: 0.23650, val_acc: 0.96667\n",
            "Epoch [3120/10000], loss: 0.17585 acc: 1.00000 val_loss: 0.23615, val_acc: 0.96667\n",
            "Epoch [3130/10000], loss: 0.17547 acc: 1.00000 val_loss: 0.23580, val_acc: 0.96667\n",
            "Epoch [3140/10000], loss: 0.17509 acc: 1.00000 val_loss: 0.23546, val_acc: 0.96667\n",
            "Epoch [3150/10000], loss: 0.17471 acc: 1.00000 val_loss: 0.23512, val_acc: 0.96667\n",
            "Epoch [3160/10000], loss: 0.17434 acc: 1.00000 val_loss: 0.23478, val_acc: 0.96667\n",
            "Epoch [3170/10000], loss: 0.17396 acc: 1.00000 val_loss: 0.23444, val_acc: 0.96667\n",
            "Epoch [3180/10000], loss: 0.17359 acc: 1.00000 val_loss: 0.23411, val_acc: 0.96667\n",
            "Epoch [3190/10000], loss: 0.17322 acc: 1.00000 val_loss: 0.23377, val_acc: 0.96667\n",
            "Epoch [3200/10000], loss: 0.17285 acc: 1.00000 val_loss: 0.23344, val_acc: 0.96667\n",
            "Epoch [3210/10000], loss: 0.17249 acc: 1.00000 val_loss: 0.23311, val_acc: 0.96667\n",
            "Epoch [3220/10000], loss: 0.17212 acc: 1.00000 val_loss: 0.23278, val_acc: 0.96667\n",
            "Epoch [3230/10000], loss: 0.17176 acc: 1.00000 val_loss: 0.23245, val_acc: 0.96667\n",
            "Epoch [3240/10000], loss: 0.17140 acc: 1.00000 val_loss: 0.23213, val_acc: 0.96667\n",
            "Epoch [3250/10000], loss: 0.17104 acc: 1.00000 val_loss: 0.23180, val_acc: 0.96667\n",
            "Epoch [3260/10000], loss: 0.17068 acc: 1.00000 val_loss: 0.23148, val_acc: 0.96667\n",
            "Epoch [3270/10000], loss: 0.17032 acc: 1.00000 val_loss: 0.23116, val_acc: 0.96667\n",
            "Epoch [3280/10000], loss: 0.16997 acc: 1.00000 val_loss: 0.23084, val_acc: 0.96667\n",
            "Epoch [3290/10000], loss: 0.16962 acc: 1.00000 val_loss: 0.23053, val_acc: 0.96667\n",
            "Epoch [3300/10000], loss: 0.16927 acc: 1.00000 val_loss: 0.23021, val_acc: 0.96667\n",
            "Epoch [3310/10000], loss: 0.16892 acc: 1.00000 val_loss: 0.22990, val_acc: 0.96667\n",
            "Epoch [3320/10000], loss: 0.16857 acc: 1.00000 val_loss: 0.22959, val_acc: 0.96667\n",
            "Epoch [3330/10000], loss: 0.16823 acc: 1.00000 val_loss: 0.22928, val_acc: 0.96667\n",
            "Epoch [3340/10000], loss: 0.16788 acc: 1.00000 val_loss: 0.22897, val_acc: 0.96667\n",
            "Epoch [3350/10000], loss: 0.16754 acc: 1.00000 val_loss: 0.22866, val_acc: 0.96667\n",
            "Epoch [3360/10000], loss: 0.16720 acc: 1.00000 val_loss: 0.22835, val_acc: 0.96667\n",
            "Epoch [3370/10000], loss: 0.16686 acc: 1.00000 val_loss: 0.22805, val_acc: 0.96667\n",
            "Epoch [3380/10000], loss: 0.16653 acc: 1.00000 val_loss: 0.22775, val_acc: 0.96667\n",
            "Epoch [3390/10000], loss: 0.16619 acc: 1.00000 val_loss: 0.22745, val_acc: 0.96667\n",
            "Epoch [3400/10000], loss: 0.16586 acc: 1.00000 val_loss: 0.22715, val_acc: 0.96667\n",
            "Epoch [3410/10000], loss: 0.16553 acc: 1.00000 val_loss: 0.22685, val_acc: 0.96667\n",
            "Epoch [3420/10000], loss: 0.16520 acc: 1.00000 val_loss: 0.22655, val_acc: 0.96667\n",
            "Epoch [3430/10000], loss: 0.16487 acc: 1.00000 val_loss: 0.22626, val_acc: 0.96667\n",
            "Epoch [3440/10000], loss: 0.16454 acc: 1.00000 val_loss: 0.22596, val_acc: 0.96667\n",
            "Epoch [3450/10000], loss: 0.16421 acc: 1.00000 val_loss: 0.22567, val_acc: 0.96667\n",
            "Epoch [3460/10000], loss: 0.16389 acc: 1.00000 val_loss: 0.22538, val_acc: 0.96667\n",
            "Epoch [3470/10000], loss: 0.16357 acc: 1.00000 val_loss: 0.22509, val_acc: 0.96667\n",
            "Epoch [3480/10000], loss: 0.16325 acc: 1.00000 val_loss: 0.22480, val_acc: 0.96667\n",
            "Epoch [3490/10000], loss: 0.16293 acc: 1.00000 val_loss: 0.22452, val_acc: 0.96667\n",
            "Epoch [3500/10000], loss: 0.16261 acc: 1.00000 val_loss: 0.22423, val_acc: 0.96667\n",
            "Epoch [3510/10000], loss: 0.16229 acc: 1.00000 val_loss: 0.22395, val_acc: 0.96667\n",
            "Epoch [3520/10000], loss: 0.16198 acc: 1.00000 val_loss: 0.22367, val_acc: 0.96667\n",
            "Epoch [3530/10000], loss: 0.16166 acc: 1.00000 val_loss: 0.22339, val_acc: 0.96667\n",
            "Epoch [3540/10000], loss: 0.16135 acc: 1.00000 val_loss: 0.22311, val_acc: 0.96667\n",
            "Epoch [3550/10000], loss: 0.16104 acc: 1.00000 val_loss: 0.22283, val_acc: 0.96667\n",
            "Epoch [3560/10000], loss: 0.16073 acc: 1.00000 val_loss: 0.22255, val_acc: 0.96667\n",
            "Epoch [3570/10000], loss: 0.16043 acc: 1.00000 val_loss: 0.22228, val_acc: 0.96667\n",
            "Epoch [3580/10000], loss: 0.16012 acc: 1.00000 val_loss: 0.22200, val_acc: 0.96667\n",
            "Epoch [3590/10000], loss: 0.15981 acc: 1.00000 val_loss: 0.22173, val_acc: 0.96667\n",
            "Epoch [3600/10000], loss: 0.15951 acc: 1.00000 val_loss: 0.22146, val_acc: 0.96667\n",
            "Epoch [3610/10000], loss: 0.15921 acc: 1.00000 val_loss: 0.22119, val_acc: 0.96667\n",
            "Epoch [3620/10000], loss: 0.15891 acc: 1.00000 val_loss: 0.22092, val_acc: 0.96667\n",
            "Epoch [3630/10000], loss: 0.15861 acc: 1.00000 val_loss: 0.22065, val_acc: 0.96667\n",
            "Epoch [3640/10000], loss: 0.15831 acc: 1.00000 val_loss: 0.22039, val_acc: 0.96667\n",
            "Epoch [3650/10000], loss: 0.15801 acc: 1.00000 val_loss: 0.22012, val_acc: 0.96667\n",
            "Epoch [3660/10000], loss: 0.15772 acc: 1.00000 val_loss: 0.21986, val_acc: 0.96667\n",
            "Epoch [3670/10000], loss: 0.15743 acc: 1.00000 val_loss: 0.21960, val_acc: 0.96667\n",
            "Epoch [3680/10000], loss: 0.15713 acc: 1.00000 val_loss: 0.21934, val_acc: 0.96667\n",
            "Epoch [3690/10000], loss: 0.15684 acc: 1.00000 val_loss: 0.21908, val_acc: 0.96667\n",
            "Epoch [3700/10000], loss: 0.15655 acc: 1.00000 val_loss: 0.21882, val_acc: 0.96667\n",
            "Epoch [3710/10000], loss: 0.15626 acc: 1.00000 val_loss: 0.21856, val_acc: 0.96667\n",
            "Epoch [3720/10000], loss: 0.15598 acc: 1.00000 val_loss: 0.21830, val_acc: 0.96667\n",
            "Epoch [3730/10000], loss: 0.15569 acc: 1.00000 val_loss: 0.21805, val_acc: 0.96667\n",
            "Epoch [3740/10000], loss: 0.15540 acc: 1.00000 val_loss: 0.21780, val_acc: 0.96667\n",
            "Epoch [3750/10000], loss: 0.15512 acc: 1.00000 val_loss: 0.21754, val_acc: 0.96667\n",
            "Epoch [3760/10000], loss: 0.15484 acc: 1.00000 val_loss: 0.21729, val_acc: 0.96667\n",
            "Epoch [3770/10000], loss: 0.15456 acc: 1.00000 val_loss: 0.21704, val_acc: 0.96667\n",
            "Epoch [3780/10000], loss: 0.15428 acc: 1.00000 val_loss: 0.21679, val_acc: 0.96667\n",
            "Epoch [3790/10000], loss: 0.15400 acc: 1.00000 val_loss: 0.21655, val_acc: 0.96667\n",
            "Epoch [3800/10000], loss: 0.15372 acc: 1.00000 val_loss: 0.21630, val_acc: 0.96667\n",
            "Epoch [3810/10000], loss: 0.15345 acc: 1.00000 val_loss: 0.21605, val_acc: 0.96667\n",
            "Epoch [3820/10000], loss: 0.15317 acc: 1.00000 val_loss: 0.21581, val_acc: 0.96667\n",
            "Epoch [3830/10000], loss: 0.15290 acc: 1.00000 val_loss: 0.21557, val_acc: 0.96667\n",
            "Epoch [3840/10000], loss: 0.15262 acc: 1.00000 val_loss: 0.21532, val_acc: 0.96667\n",
            "Epoch [3850/10000], loss: 0.15235 acc: 1.00000 val_loss: 0.21508, val_acc: 0.96667\n",
            "Epoch [3860/10000], loss: 0.15208 acc: 1.00000 val_loss: 0.21484, val_acc: 0.96667\n",
            "Epoch [3870/10000], loss: 0.15181 acc: 1.00000 val_loss: 0.21460, val_acc: 0.96667\n",
            "Epoch [3880/10000], loss: 0.15155 acc: 1.00000 val_loss: 0.21436, val_acc: 0.96667\n",
            "Epoch [3890/10000], loss: 0.15128 acc: 1.00000 val_loss: 0.21413, val_acc: 0.96667\n",
            "Epoch [3900/10000], loss: 0.15101 acc: 1.00000 val_loss: 0.21389, val_acc: 0.96667\n",
            "Epoch [3910/10000], loss: 0.15075 acc: 1.00000 val_loss: 0.21366, val_acc: 0.96667\n",
            "Epoch [3920/10000], loss: 0.15049 acc: 1.00000 val_loss: 0.21342, val_acc: 0.96667\n",
            "Epoch [3930/10000], loss: 0.15022 acc: 1.00000 val_loss: 0.21319, val_acc: 0.96667\n",
            "Epoch [3940/10000], loss: 0.14996 acc: 1.00000 val_loss: 0.21296, val_acc: 0.96667\n",
            "Epoch [3950/10000], loss: 0.14970 acc: 1.00000 val_loss: 0.21273, val_acc: 0.96667\n",
            "Epoch [3960/10000], loss: 0.14944 acc: 1.00000 val_loss: 0.21250, val_acc: 0.96667\n",
            "Epoch [3970/10000], loss: 0.14919 acc: 1.00000 val_loss: 0.21227, val_acc: 0.96667\n",
            "Epoch [3980/10000], loss: 0.14893 acc: 1.00000 val_loss: 0.21204, val_acc: 0.96667\n",
            "Epoch [3990/10000], loss: 0.14867 acc: 1.00000 val_loss: 0.21182, val_acc: 0.96667\n",
            "Epoch [4000/10000], loss: 0.14842 acc: 1.00000 val_loss: 0.21159, val_acc: 0.96667\n",
            "Epoch [4010/10000], loss: 0.14816 acc: 1.00000 val_loss: 0.21137, val_acc: 0.96667\n",
            "Epoch [4020/10000], loss: 0.14791 acc: 1.00000 val_loss: 0.21114, val_acc: 0.96667\n",
            "Epoch [4030/10000], loss: 0.14766 acc: 1.00000 val_loss: 0.21092, val_acc: 0.96667\n",
            "Epoch [4040/10000], loss: 0.14741 acc: 1.00000 val_loss: 0.21070, val_acc: 0.96667\n",
            "Epoch [4050/10000], loss: 0.14716 acc: 1.00000 val_loss: 0.21048, val_acc: 0.96667\n",
            "Epoch [4060/10000], loss: 0.14691 acc: 1.00000 val_loss: 0.21026, val_acc: 0.96667\n",
            "Epoch [4070/10000], loss: 0.14667 acc: 1.00000 val_loss: 0.21004, val_acc: 0.96667\n",
            "Epoch [4080/10000], loss: 0.14642 acc: 1.00000 val_loss: 0.20982, val_acc: 0.96667\n",
            "Epoch [4090/10000], loss: 0.14617 acc: 1.00000 val_loss: 0.20961, val_acc: 0.96667\n",
            "Epoch [4100/10000], loss: 0.14593 acc: 1.00000 val_loss: 0.20939, val_acc: 0.96667\n",
            "Epoch [4110/10000], loss: 0.14569 acc: 1.00000 val_loss: 0.20918, val_acc: 0.96667\n",
            "Epoch [4120/10000], loss: 0.14544 acc: 1.00000 val_loss: 0.20896, val_acc: 0.96667\n",
            "Epoch [4130/10000], loss: 0.14520 acc: 1.00000 val_loss: 0.20875, val_acc: 0.96667\n",
            "Epoch [4140/10000], loss: 0.14496 acc: 1.00000 val_loss: 0.20854, val_acc: 0.96667\n",
            "Epoch [4150/10000], loss: 0.14472 acc: 1.00000 val_loss: 0.20833, val_acc: 0.96667\n",
            "Epoch [4160/10000], loss: 0.14448 acc: 1.00000 val_loss: 0.20812, val_acc: 0.96667\n",
            "Epoch [4170/10000], loss: 0.14425 acc: 1.00000 val_loss: 0.20791, val_acc: 0.96667\n",
            "Epoch [4180/10000], loss: 0.14401 acc: 1.00000 val_loss: 0.20770, val_acc: 0.96667\n",
            "Epoch [4190/10000], loss: 0.14377 acc: 1.00000 val_loss: 0.20749, val_acc: 0.96667\n",
            "Epoch [4200/10000], loss: 0.14354 acc: 1.00000 val_loss: 0.20728, val_acc: 0.96667\n",
            "Epoch [4210/10000], loss: 0.14331 acc: 1.00000 val_loss: 0.20708, val_acc: 0.96667\n",
            "Epoch [4220/10000], loss: 0.14307 acc: 1.00000 val_loss: 0.20687, val_acc: 0.96667\n",
            "Epoch [4230/10000], loss: 0.14284 acc: 1.00000 val_loss: 0.20667, val_acc: 0.96667\n",
            "Epoch [4240/10000], loss: 0.14261 acc: 1.00000 val_loss: 0.20647, val_acc: 0.96667\n",
            "Epoch [4250/10000], loss: 0.14238 acc: 1.00000 val_loss: 0.20626, val_acc: 0.96667\n",
            "Epoch [4260/10000], loss: 0.14215 acc: 1.00000 val_loss: 0.20606, val_acc: 0.96667\n",
            "Epoch [4270/10000], loss: 0.14192 acc: 1.00000 val_loss: 0.20586, val_acc: 0.96667\n",
            "Epoch [4280/10000], loss: 0.14170 acc: 1.00000 val_loss: 0.20566, val_acc: 0.96667\n",
            "Epoch [4290/10000], loss: 0.14147 acc: 1.00000 val_loss: 0.20546, val_acc: 0.96667\n",
            "Epoch [4300/10000], loss: 0.14124 acc: 1.00000 val_loss: 0.20526, val_acc: 0.96667\n",
            "Epoch [4310/10000], loss: 0.14102 acc: 1.00000 val_loss: 0.20507, val_acc: 0.96667\n",
            "Epoch [4320/10000], loss: 0.14080 acc: 1.00000 val_loss: 0.20487, val_acc: 0.96667\n",
            "Epoch [4330/10000], loss: 0.14057 acc: 1.00000 val_loss: 0.20467, val_acc: 0.96667\n",
            "Epoch [4340/10000], loss: 0.14035 acc: 1.00000 val_loss: 0.20448, val_acc: 0.96667\n",
            "Epoch [4350/10000], loss: 0.14013 acc: 1.00000 val_loss: 0.20429, val_acc: 0.96667\n",
            "Epoch [4360/10000], loss: 0.13991 acc: 1.00000 val_loss: 0.20409, val_acc: 0.96667\n",
            "Epoch [4370/10000], loss: 0.13969 acc: 1.00000 val_loss: 0.20390, val_acc: 0.96667\n",
            "Epoch [4380/10000], loss: 0.13947 acc: 1.00000 val_loss: 0.20371, val_acc: 0.96667\n",
            "Epoch [4390/10000], loss: 0.13925 acc: 1.00000 val_loss: 0.20352, val_acc: 0.96667\n",
            "Epoch [4400/10000], loss: 0.13904 acc: 1.00000 val_loss: 0.20333, val_acc: 0.96667\n",
            "Epoch [4410/10000], loss: 0.13882 acc: 1.00000 val_loss: 0.20314, val_acc: 0.96667\n",
            "Epoch [4420/10000], loss: 0.13860 acc: 1.00000 val_loss: 0.20295, val_acc: 0.96667\n",
            "Epoch [4430/10000], loss: 0.13839 acc: 1.00000 val_loss: 0.20276, val_acc: 0.96667\n",
            "Epoch [4440/10000], loss: 0.13818 acc: 1.00000 val_loss: 0.20257, val_acc: 0.96667\n",
            "Epoch [4450/10000], loss: 0.13796 acc: 1.00000 val_loss: 0.20239, val_acc: 0.96667\n",
            "Epoch [4460/10000], loss: 0.13775 acc: 1.00000 val_loss: 0.20220, val_acc: 0.96667\n",
            "Epoch [4470/10000], loss: 0.13754 acc: 1.00000 val_loss: 0.20202, val_acc: 0.96667\n",
            "Epoch [4480/10000], loss: 0.13733 acc: 1.00000 val_loss: 0.20183, val_acc: 0.96667\n",
            "Epoch [4490/10000], loss: 0.13712 acc: 1.00000 val_loss: 0.20165, val_acc: 0.96667\n",
            "Epoch [4500/10000], loss: 0.13691 acc: 1.00000 val_loss: 0.20147, val_acc: 0.96667\n",
            "Epoch [4510/10000], loss: 0.13670 acc: 1.00000 val_loss: 0.20128, val_acc: 0.96667\n",
            "Epoch [4520/10000], loss: 0.13650 acc: 1.00000 val_loss: 0.20110, val_acc: 0.96667\n",
            "Epoch [4530/10000], loss: 0.13629 acc: 1.00000 val_loss: 0.20092, val_acc: 0.96667\n",
            "Epoch [4540/10000], loss: 0.13608 acc: 1.00000 val_loss: 0.20074, val_acc: 0.96667\n",
            "Epoch [4550/10000], loss: 0.13588 acc: 1.00000 val_loss: 0.20056, val_acc: 0.96667\n",
            "Epoch [4560/10000], loss: 0.13567 acc: 1.00000 val_loss: 0.20038, val_acc: 0.96667\n",
            "Epoch [4570/10000], loss: 0.13547 acc: 1.00000 val_loss: 0.20021, val_acc: 0.96667\n",
            "Epoch [4580/10000], loss: 0.13527 acc: 1.00000 val_loss: 0.20003, val_acc: 0.96667\n",
            "Epoch [4590/10000], loss: 0.13507 acc: 1.00000 val_loss: 0.19985, val_acc: 0.96667\n",
            "Epoch [4600/10000], loss: 0.13486 acc: 1.00000 val_loss: 0.19968, val_acc: 0.96667\n",
            "Epoch [4610/10000], loss: 0.13466 acc: 1.00000 val_loss: 0.19950, val_acc: 0.96667\n",
            "Epoch [4620/10000], loss: 0.13446 acc: 1.00000 val_loss: 0.19933, val_acc: 0.96667\n",
            "Epoch [4630/10000], loss: 0.13426 acc: 1.00000 val_loss: 0.19916, val_acc: 0.96667\n",
            "Epoch [4640/10000], loss: 0.13407 acc: 1.00000 val_loss: 0.19898, val_acc: 0.96667\n",
            "Epoch [4650/10000], loss: 0.13387 acc: 1.00000 val_loss: 0.19881, val_acc: 0.96667\n",
            "Epoch [4660/10000], loss: 0.13367 acc: 1.00000 val_loss: 0.19864, val_acc: 0.96667\n",
            "Epoch [4670/10000], loss: 0.13348 acc: 1.00000 val_loss: 0.19847, val_acc: 0.96667\n",
            "Epoch [4680/10000], loss: 0.13328 acc: 1.00000 val_loss: 0.19830, val_acc: 0.96667\n",
            "Epoch [4690/10000], loss: 0.13308 acc: 1.00000 val_loss: 0.19813, val_acc: 0.96667\n",
            "Epoch [4700/10000], loss: 0.13289 acc: 1.00000 val_loss: 0.19796, val_acc: 0.96667\n",
            "Epoch [4710/10000], loss: 0.13270 acc: 1.00000 val_loss: 0.19779, val_acc: 0.96667\n",
            "Epoch [4720/10000], loss: 0.13250 acc: 1.00000 val_loss: 0.19762, val_acc: 0.96667\n",
            "Epoch [4730/10000], loss: 0.13231 acc: 1.00000 val_loss: 0.19746, val_acc: 0.96667\n",
            "Epoch [4740/10000], loss: 0.13212 acc: 1.00000 val_loss: 0.19729, val_acc: 0.96667\n",
            "Epoch [4750/10000], loss: 0.13193 acc: 1.00000 val_loss: 0.19712, val_acc: 0.96667\n",
            "Epoch [4760/10000], loss: 0.13174 acc: 1.00000 val_loss: 0.19696, val_acc: 0.96667\n",
            "Epoch [4770/10000], loss: 0.13155 acc: 1.00000 val_loss: 0.19679, val_acc: 0.96667\n",
            "Epoch [4780/10000], loss: 0.13136 acc: 1.00000 val_loss: 0.19663, val_acc: 0.96667\n",
            "Epoch [4790/10000], loss: 0.13117 acc: 1.00000 val_loss: 0.19647, val_acc: 0.96667\n",
            "Epoch [4800/10000], loss: 0.13099 acc: 1.00000 val_loss: 0.19630, val_acc: 0.96667\n",
            "Epoch [4810/10000], loss: 0.13080 acc: 1.00000 val_loss: 0.19614, val_acc: 0.96667\n",
            "Epoch [4820/10000], loss: 0.13061 acc: 1.00000 val_loss: 0.19598, val_acc: 0.96667\n",
            "Epoch [4830/10000], loss: 0.13043 acc: 1.00000 val_loss: 0.19582, val_acc: 0.96667\n",
            "Epoch [4840/10000], loss: 0.13024 acc: 1.00000 val_loss: 0.19566, val_acc: 0.96667\n",
            "Epoch [4850/10000], loss: 0.13006 acc: 1.00000 val_loss: 0.19550, val_acc: 0.96667\n",
            "Epoch [4860/10000], loss: 0.12988 acc: 1.00000 val_loss: 0.19534, val_acc: 0.96667\n",
            "Epoch [4870/10000], loss: 0.12969 acc: 1.00000 val_loss: 0.19518, val_acc: 0.96667\n",
            "Epoch [4880/10000], loss: 0.12951 acc: 1.00000 val_loss: 0.19502, val_acc: 0.96667\n",
            "Epoch [4890/10000], loss: 0.12933 acc: 1.00000 val_loss: 0.19487, val_acc: 0.96667\n",
            "Epoch [4900/10000], loss: 0.12915 acc: 1.00000 val_loss: 0.19471, val_acc: 0.96667\n",
            "Epoch [4910/10000], loss: 0.12897 acc: 1.00000 val_loss: 0.19455, val_acc: 0.96667\n",
            "Epoch [4920/10000], loss: 0.12879 acc: 1.00000 val_loss: 0.19440, val_acc: 0.96667\n",
            "Epoch [4930/10000], loss: 0.12861 acc: 1.00000 val_loss: 0.19424, val_acc: 0.96667\n",
            "Epoch [4940/10000], loss: 0.12843 acc: 1.00000 val_loss: 0.19409, val_acc: 0.96667\n",
            "Epoch [4950/10000], loss: 0.12825 acc: 1.00000 val_loss: 0.19394, val_acc: 0.96667\n",
            "Epoch [4960/10000], loss: 0.12808 acc: 1.00000 val_loss: 0.19378, val_acc: 0.96667\n",
            "Epoch [4970/10000], loss: 0.12790 acc: 1.00000 val_loss: 0.19363, val_acc: 0.96667\n",
            "Epoch [4980/10000], loss: 0.12772 acc: 1.00000 val_loss: 0.19348, val_acc: 0.96667\n",
            "Epoch [4990/10000], loss: 0.12755 acc: 1.00000 val_loss: 0.19333, val_acc: 0.96667\n",
            "Epoch [5000/10000], loss: 0.12737 acc: 1.00000 val_loss: 0.19317, val_acc: 0.96667\n",
            "Epoch [5010/10000], loss: 0.12720 acc: 1.00000 val_loss: 0.19302, val_acc: 0.96667\n",
            "Epoch [5020/10000], loss: 0.12703 acc: 1.00000 val_loss: 0.19287, val_acc: 0.96667\n",
            "Epoch [5030/10000], loss: 0.12685 acc: 1.00000 val_loss: 0.19273, val_acc: 0.96667\n",
            "Epoch [5040/10000], loss: 0.12668 acc: 1.00000 val_loss: 0.19258, val_acc: 0.96667\n",
            "Epoch [5050/10000], loss: 0.12651 acc: 1.00000 val_loss: 0.19243, val_acc: 0.96667\n",
            "Epoch [5060/10000], loss: 0.12634 acc: 1.00000 val_loss: 0.19228, val_acc: 0.96667\n",
            "Epoch [5070/10000], loss: 0.12617 acc: 1.00000 val_loss: 0.19213, val_acc: 0.96667\n",
            "Epoch [5080/10000], loss: 0.12600 acc: 1.00000 val_loss: 0.19199, val_acc: 0.96667\n",
            "Epoch [5090/10000], loss: 0.12583 acc: 1.00000 val_loss: 0.19184, val_acc: 0.96667\n",
            "Epoch [5100/10000], loss: 0.12566 acc: 1.00000 val_loss: 0.19169, val_acc: 0.96667\n",
            "Epoch [5110/10000], loss: 0.12549 acc: 1.00000 val_loss: 0.19155, val_acc: 0.96667\n",
            "Epoch [5120/10000], loss: 0.12532 acc: 1.00000 val_loss: 0.19140, val_acc: 0.96667\n",
            "Epoch [5130/10000], loss: 0.12515 acc: 1.00000 val_loss: 0.19126, val_acc: 0.96667\n",
            "Epoch [5140/10000], loss: 0.12499 acc: 1.00000 val_loss: 0.19112, val_acc: 0.96667\n",
            "Epoch [5150/10000], loss: 0.12482 acc: 1.00000 val_loss: 0.19097, val_acc: 0.96667\n",
            "Epoch [5160/10000], loss: 0.12465 acc: 1.00000 val_loss: 0.19083, val_acc: 0.96667\n",
            "Epoch [5170/10000], loss: 0.12449 acc: 1.00000 val_loss: 0.19069, val_acc: 0.96667\n",
            "Epoch [5180/10000], loss: 0.12432 acc: 1.00000 val_loss: 0.19055, val_acc: 0.96667\n",
            "Epoch [5190/10000], loss: 0.12416 acc: 1.00000 val_loss: 0.19041, val_acc: 0.96667\n",
            "Epoch [5200/10000], loss: 0.12400 acc: 1.00000 val_loss: 0.19027, val_acc: 0.96667\n",
            "Epoch [5210/10000], loss: 0.12383 acc: 1.00000 val_loss: 0.19013, val_acc: 0.96667\n",
            "Epoch [5220/10000], loss: 0.12367 acc: 1.00000 val_loss: 0.18999, val_acc: 0.96667\n",
            "Epoch [5230/10000], loss: 0.12351 acc: 1.00000 val_loss: 0.18985, val_acc: 0.96667\n",
            "Epoch [5240/10000], loss: 0.12335 acc: 1.00000 val_loss: 0.18971, val_acc: 0.96667\n",
            "Epoch [5250/10000], loss: 0.12319 acc: 1.00000 val_loss: 0.18957, val_acc: 0.96667\n",
            "Epoch [5260/10000], loss: 0.12303 acc: 1.00000 val_loss: 0.18943, val_acc: 0.96667\n",
            "Epoch [5270/10000], loss: 0.12287 acc: 1.00000 val_loss: 0.18930, val_acc: 0.96667\n",
            "Epoch [5280/10000], loss: 0.12271 acc: 1.00000 val_loss: 0.18916, val_acc: 0.96667\n",
            "Epoch [5290/10000], loss: 0.12255 acc: 1.00000 val_loss: 0.18902, val_acc: 0.96667\n",
            "Epoch [5300/10000], loss: 0.12239 acc: 1.00000 val_loss: 0.18889, val_acc: 0.96667\n",
            "Epoch [5310/10000], loss: 0.12223 acc: 1.00000 val_loss: 0.18875, val_acc: 0.96667\n",
            "Epoch [5320/10000], loss: 0.12207 acc: 1.00000 val_loss: 0.18862, val_acc: 0.96667\n",
            "Epoch [5330/10000], loss: 0.12192 acc: 1.00000 val_loss: 0.18848, val_acc: 0.96667\n",
            "Epoch [5340/10000], loss: 0.12176 acc: 1.00000 val_loss: 0.18835, val_acc: 0.96667\n",
            "Epoch [5350/10000], loss: 0.12160 acc: 1.00000 val_loss: 0.18821, val_acc: 0.96667\n",
            "Epoch [5360/10000], loss: 0.12145 acc: 1.00000 val_loss: 0.18808, val_acc: 0.96667\n",
            "Epoch [5370/10000], loss: 0.12129 acc: 1.00000 val_loss: 0.18795, val_acc: 0.96667\n",
            "Epoch [5380/10000], loss: 0.12114 acc: 1.00000 val_loss: 0.18782, val_acc: 0.96667\n",
            "Epoch [5390/10000], loss: 0.12099 acc: 1.00000 val_loss: 0.18768, val_acc: 0.96667\n",
            "Epoch [5400/10000], loss: 0.12083 acc: 1.00000 val_loss: 0.18755, val_acc: 0.96667\n",
            "Epoch [5410/10000], loss: 0.12068 acc: 1.00000 val_loss: 0.18742, val_acc: 0.96667\n",
            "Epoch [5420/10000], loss: 0.12053 acc: 1.00000 val_loss: 0.18729, val_acc: 0.96667\n",
            "Epoch [5430/10000], loss: 0.12037 acc: 1.00000 val_loss: 0.18716, val_acc: 0.96667\n",
            "Epoch [5440/10000], loss: 0.12022 acc: 1.00000 val_loss: 0.18703, val_acc: 0.96667\n",
            "Epoch [5450/10000], loss: 0.12007 acc: 1.00000 val_loss: 0.18690, val_acc: 0.96667\n",
            "Epoch [5460/10000], loss: 0.11992 acc: 1.00000 val_loss: 0.18678, val_acc: 0.96667\n",
            "Epoch [5470/10000], loss: 0.11977 acc: 1.00000 val_loss: 0.18665, val_acc: 0.96667\n",
            "Epoch [5480/10000], loss: 0.11962 acc: 1.00000 val_loss: 0.18652, val_acc: 0.96667\n",
            "Epoch [5490/10000], loss: 0.11947 acc: 1.00000 val_loss: 0.18639, val_acc: 0.96667\n",
            "Epoch [5500/10000], loss: 0.11932 acc: 1.00000 val_loss: 0.18627, val_acc: 0.96667\n",
            "Epoch [5510/10000], loss: 0.11918 acc: 1.00000 val_loss: 0.18614, val_acc: 0.96667\n",
            "Epoch [5520/10000], loss: 0.11903 acc: 1.00000 val_loss: 0.18601, val_acc: 0.96667\n",
            "Epoch [5530/10000], loss: 0.11888 acc: 1.00000 val_loss: 0.18589, val_acc: 0.96667\n",
            "Epoch [5540/10000], loss: 0.11873 acc: 1.00000 val_loss: 0.18576, val_acc: 0.96667\n",
            "Epoch [5550/10000], loss: 0.11859 acc: 1.00000 val_loss: 0.18564, val_acc: 0.96667\n",
            "Epoch [5560/10000], loss: 0.11844 acc: 1.00000 val_loss: 0.18551, val_acc: 0.96667\n",
            "Epoch [5570/10000], loss: 0.11830 acc: 1.00000 val_loss: 0.18539, val_acc: 0.96667\n",
            "Epoch [5580/10000], loss: 0.11815 acc: 1.00000 val_loss: 0.18527, val_acc: 0.96667\n",
            "Epoch [5590/10000], loss: 0.11801 acc: 1.00000 val_loss: 0.18514, val_acc: 0.96667\n",
            "Epoch [5600/10000], loss: 0.11786 acc: 1.00000 val_loss: 0.18502, val_acc: 0.96667\n",
            "Epoch [5610/10000], loss: 0.11772 acc: 1.00000 val_loss: 0.18490, val_acc: 0.96667\n",
            "Epoch [5620/10000], loss: 0.11757 acc: 1.00000 val_loss: 0.18478, val_acc: 0.96667\n",
            "Epoch [5630/10000], loss: 0.11743 acc: 1.00000 val_loss: 0.18465, val_acc: 0.96667\n",
            "Epoch [5640/10000], loss: 0.11729 acc: 1.00000 val_loss: 0.18453, val_acc: 0.96667\n",
            "Epoch [5650/10000], loss: 0.11715 acc: 1.00000 val_loss: 0.18441, val_acc: 0.96667\n",
            "Epoch [5660/10000], loss: 0.11701 acc: 1.00000 val_loss: 0.18429, val_acc: 0.96667\n",
            "Epoch [5670/10000], loss: 0.11686 acc: 1.00000 val_loss: 0.18417, val_acc: 0.96667\n",
            "Epoch [5680/10000], loss: 0.11672 acc: 1.00000 val_loss: 0.18405, val_acc: 0.96667\n",
            "Epoch [5690/10000], loss: 0.11658 acc: 1.00000 val_loss: 0.18393, val_acc: 0.96667\n",
            "Epoch [5700/10000], loss: 0.11644 acc: 1.00000 val_loss: 0.18381, val_acc: 0.96667\n",
            "Epoch [5710/10000], loss: 0.11630 acc: 1.00000 val_loss: 0.18370, val_acc: 0.96667\n",
            "Epoch [5720/10000], loss: 0.11616 acc: 1.00000 val_loss: 0.18358, val_acc: 0.96667\n",
            "Epoch [5730/10000], loss: 0.11603 acc: 1.00000 val_loss: 0.18346, val_acc: 0.96667\n",
            "Epoch [5740/10000], loss: 0.11589 acc: 1.00000 val_loss: 0.18334, val_acc: 0.96667\n",
            "Epoch [5750/10000], loss: 0.11575 acc: 1.00000 val_loss: 0.18323, val_acc: 0.96667\n",
            "Epoch [5760/10000], loss: 0.11561 acc: 1.00000 val_loss: 0.18311, val_acc: 0.96667\n",
            "Epoch [5770/10000], loss: 0.11547 acc: 1.00000 val_loss: 0.18299, val_acc: 0.96667\n",
            "Epoch [5780/10000], loss: 0.11534 acc: 1.00000 val_loss: 0.18288, val_acc: 0.96667\n",
            "Epoch [5790/10000], loss: 0.11520 acc: 1.00000 val_loss: 0.18276, val_acc: 0.96667\n",
            "Epoch [5800/10000], loss: 0.11507 acc: 1.00000 val_loss: 0.18265, val_acc: 0.96667\n",
            "Epoch [5810/10000], loss: 0.11493 acc: 1.00000 val_loss: 0.18253, val_acc: 0.96667\n",
            "Epoch [5820/10000], loss: 0.11480 acc: 1.00000 val_loss: 0.18242, val_acc: 0.96667\n",
            "Epoch [5830/10000], loss: 0.11466 acc: 1.00000 val_loss: 0.18230, val_acc: 0.96667\n",
            "Epoch [5840/10000], loss: 0.11453 acc: 1.00000 val_loss: 0.18219, val_acc: 0.96667\n",
            "Epoch [5850/10000], loss: 0.11439 acc: 1.00000 val_loss: 0.18208, val_acc: 0.96667\n",
            "Epoch [5860/10000], loss: 0.11426 acc: 1.00000 val_loss: 0.18197, val_acc: 0.96667\n",
            "Epoch [5870/10000], loss: 0.11413 acc: 1.00000 val_loss: 0.18185, val_acc: 0.96667\n",
            "Epoch [5880/10000], loss: 0.11399 acc: 1.00000 val_loss: 0.18174, val_acc: 0.96667\n",
            "Epoch [5890/10000], loss: 0.11386 acc: 1.00000 val_loss: 0.18163, val_acc: 0.96667\n",
            "Epoch [5900/10000], loss: 0.11373 acc: 1.00000 val_loss: 0.18152, val_acc: 0.96667\n",
            "Epoch [5910/10000], loss: 0.11360 acc: 1.00000 val_loss: 0.18141, val_acc: 0.96667\n",
            "Epoch [5920/10000], loss: 0.11347 acc: 1.00000 val_loss: 0.18130, val_acc: 0.96667\n",
            "Epoch [5930/10000], loss: 0.11333 acc: 1.00000 val_loss: 0.18119, val_acc: 0.96667\n",
            "Epoch [5940/10000], loss: 0.11320 acc: 1.00000 val_loss: 0.18108, val_acc: 0.96667\n",
            "Epoch [5950/10000], loss: 0.11307 acc: 1.00000 val_loss: 0.18097, val_acc: 0.96667\n",
            "Epoch [5960/10000], loss: 0.11294 acc: 1.00000 val_loss: 0.18086, val_acc: 0.96667\n",
            "Epoch [5970/10000], loss: 0.11282 acc: 1.00000 val_loss: 0.18075, val_acc: 0.96667\n",
            "Epoch [5980/10000], loss: 0.11269 acc: 1.00000 val_loss: 0.18064, val_acc: 0.96667\n",
            "Epoch [5990/10000], loss: 0.11256 acc: 1.00000 val_loss: 0.18053, val_acc: 0.96667\n",
            "Epoch [6000/10000], loss: 0.11243 acc: 1.00000 val_loss: 0.18042, val_acc: 0.96667\n",
            "Epoch [6010/10000], loss: 0.11230 acc: 1.00000 val_loss: 0.18031, val_acc: 0.96667\n",
            "Epoch [6020/10000], loss: 0.11217 acc: 1.00000 val_loss: 0.18021, val_acc: 0.96667\n",
            "Epoch [6030/10000], loss: 0.11205 acc: 1.00000 val_loss: 0.18010, val_acc: 0.96667\n",
            "Epoch [6040/10000], loss: 0.11192 acc: 1.00000 val_loss: 0.17999, val_acc: 0.96667\n",
            "Epoch [6050/10000], loss: 0.11179 acc: 1.00000 val_loss: 0.17989, val_acc: 0.96667\n",
            "Epoch [6060/10000], loss: 0.11167 acc: 1.00000 val_loss: 0.17978, val_acc: 0.96667\n",
            "Epoch [6070/10000], loss: 0.11154 acc: 1.00000 val_loss: 0.17968, val_acc: 0.96667\n",
            "Epoch [6080/10000], loss: 0.11142 acc: 1.00000 val_loss: 0.17957, val_acc: 0.96667\n",
            "Epoch [6090/10000], loss: 0.11129 acc: 1.00000 val_loss: 0.17947, val_acc: 0.96667\n",
            "Epoch [6100/10000], loss: 0.11117 acc: 1.00000 val_loss: 0.17936, val_acc: 0.96667\n",
            "Epoch [6110/10000], loss: 0.11104 acc: 1.00000 val_loss: 0.17926, val_acc: 0.96667\n",
            "Epoch [6120/10000], loss: 0.11092 acc: 1.00000 val_loss: 0.17915, val_acc: 0.96667\n",
            "Epoch [6130/10000], loss: 0.11079 acc: 1.00000 val_loss: 0.17905, val_acc: 0.96667\n",
            "Epoch [6140/10000], loss: 0.11067 acc: 1.00000 val_loss: 0.17894, val_acc: 0.96667\n",
            "Epoch [6150/10000], loss: 0.11055 acc: 1.00000 val_loss: 0.17884, val_acc: 0.96667\n",
            "Epoch [6160/10000], loss: 0.11043 acc: 1.00000 val_loss: 0.17874, val_acc: 0.96667\n",
            "Epoch [6170/10000], loss: 0.11030 acc: 1.00000 val_loss: 0.17864, val_acc: 0.96667\n",
            "Epoch [6180/10000], loss: 0.11018 acc: 1.00000 val_loss: 0.17853, val_acc: 0.96667\n",
            "Epoch [6190/10000], loss: 0.11006 acc: 1.00000 val_loss: 0.17843, val_acc: 0.96667\n",
            "Epoch [6200/10000], loss: 0.10994 acc: 1.00000 val_loss: 0.17833, val_acc: 0.96667\n",
            "Epoch [6210/10000], loss: 0.10982 acc: 1.00000 val_loss: 0.17823, val_acc: 0.96667\n",
            "Epoch [6220/10000], loss: 0.10970 acc: 1.00000 val_loss: 0.17813, val_acc: 0.96667\n",
            "Epoch [6230/10000], loss: 0.10958 acc: 1.00000 val_loss: 0.17803, val_acc: 0.96667\n",
            "Epoch [6240/10000], loss: 0.10946 acc: 1.00000 val_loss: 0.17793, val_acc: 0.96667\n",
            "Epoch [6250/10000], loss: 0.10934 acc: 1.00000 val_loss: 0.17783, val_acc: 0.96667\n",
            "Epoch [6260/10000], loss: 0.10922 acc: 1.00000 val_loss: 0.17773, val_acc: 0.96667\n",
            "Epoch [6270/10000], loss: 0.10910 acc: 1.00000 val_loss: 0.17763, val_acc: 0.96667\n",
            "Epoch [6280/10000], loss: 0.10898 acc: 1.00000 val_loss: 0.17753, val_acc: 0.96667\n",
            "Epoch [6290/10000], loss: 0.10886 acc: 1.00000 val_loss: 0.17743, val_acc: 0.96667\n",
            "Epoch [6300/10000], loss: 0.10874 acc: 1.00000 val_loss: 0.17733, val_acc: 0.96667\n",
            "Epoch [6310/10000], loss: 0.10863 acc: 1.00000 val_loss: 0.17723, val_acc: 0.96667\n",
            "Epoch [6320/10000], loss: 0.10851 acc: 1.00000 val_loss: 0.17713, val_acc: 0.96667\n",
            "Epoch [6330/10000], loss: 0.10839 acc: 1.00000 val_loss: 0.17704, val_acc: 0.96667\n",
            "Epoch [6340/10000], loss: 0.10828 acc: 1.00000 val_loss: 0.17694, val_acc: 0.96667\n",
            "Epoch [6350/10000], loss: 0.10816 acc: 1.00000 val_loss: 0.17684, val_acc: 0.96667\n",
            "Epoch [6360/10000], loss: 0.10804 acc: 1.00000 val_loss: 0.17675, val_acc: 0.96667\n",
            "Epoch [6370/10000], loss: 0.10793 acc: 1.00000 val_loss: 0.17665, val_acc: 0.96667\n",
            "Epoch [6380/10000], loss: 0.10781 acc: 1.00000 val_loss: 0.17655, val_acc: 0.96667\n",
            "Epoch [6390/10000], loss: 0.10770 acc: 1.00000 val_loss: 0.17646, val_acc: 0.96667\n",
            "Epoch [6400/10000], loss: 0.10758 acc: 1.00000 val_loss: 0.17636, val_acc: 0.96667\n",
            "Epoch [6410/10000], loss: 0.10747 acc: 1.00000 val_loss: 0.17627, val_acc: 0.96667\n",
            "Epoch [6420/10000], loss: 0.10735 acc: 1.00000 val_loss: 0.17617, val_acc: 0.96667\n",
            "Epoch [6430/10000], loss: 0.10724 acc: 1.00000 val_loss: 0.17608, val_acc: 0.96667\n",
            "Epoch [6440/10000], loss: 0.10712 acc: 1.00000 val_loss: 0.17598, val_acc: 0.96667\n",
            "Epoch [6450/10000], loss: 0.10701 acc: 1.00000 val_loss: 0.17589, val_acc: 0.96667\n",
            "Epoch [6460/10000], loss: 0.10690 acc: 1.00000 val_loss: 0.17579, val_acc: 0.96667\n",
            "Epoch [6470/10000], loss: 0.10679 acc: 1.00000 val_loss: 0.17570, val_acc: 0.96667\n",
            "Epoch [6480/10000], loss: 0.10667 acc: 1.00000 val_loss: 0.17560, val_acc: 0.96667\n",
            "Epoch [6490/10000], loss: 0.10656 acc: 1.00000 val_loss: 0.17551, val_acc: 0.96667\n",
            "Epoch [6500/10000], loss: 0.10645 acc: 1.00000 val_loss: 0.17542, val_acc: 0.96667\n",
            "Epoch [6510/10000], loss: 0.10634 acc: 1.00000 val_loss: 0.17533, val_acc: 0.96667\n",
            "Epoch [6520/10000], loss: 0.10623 acc: 1.00000 val_loss: 0.17523, val_acc: 0.96667\n",
            "Epoch [6530/10000], loss: 0.10612 acc: 1.00000 val_loss: 0.17514, val_acc: 0.96667\n",
            "Epoch [6540/10000], loss: 0.10600 acc: 1.00000 val_loss: 0.17505, val_acc: 0.96667\n",
            "Epoch [6550/10000], loss: 0.10589 acc: 1.00000 val_loss: 0.17496, val_acc: 0.96667\n",
            "Epoch [6560/10000], loss: 0.10578 acc: 1.00000 val_loss: 0.17487, val_acc: 0.96667\n",
            "Epoch [6570/10000], loss: 0.10567 acc: 1.00000 val_loss: 0.17478, val_acc: 0.96667\n",
            "Epoch [6580/10000], loss: 0.10556 acc: 1.00000 val_loss: 0.17468, val_acc: 0.96667\n",
            "Epoch [6590/10000], loss: 0.10546 acc: 1.00000 val_loss: 0.17459, val_acc: 0.96667\n",
            "Epoch [6600/10000], loss: 0.10535 acc: 1.00000 val_loss: 0.17450, val_acc: 0.96667\n",
            "Epoch [6610/10000], loss: 0.10524 acc: 1.00000 val_loss: 0.17441, val_acc: 0.96667\n",
            "Epoch [6620/10000], loss: 0.10513 acc: 1.00000 val_loss: 0.17432, val_acc: 0.96667\n",
            "Epoch [6630/10000], loss: 0.10502 acc: 1.00000 val_loss: 0.17423, val_acc: 0.96667\n",
            "Epoch [6640/10000], loss: 0.10491 acc: 1.00000 val_loss: 0.17414, val_acc: 0.96667\n",
            "Epoch [6650/10000], loss: 0.10481 acc: 1.00000 val_loss: 0.17406, val_acc: 0.96667\n",
            "Epoch [6660/10000], loss: 0.10470 acc: 1.00000 val_loss: 0.17397, val_acc: 0.96667\n",
            "Epoch [6670/10000], loss: 0.10459 acc: 1.00000 val_loss: 0.17388, val_acc: 0.96667\n",
            "Epoch [6680/10000], loss: 0.10448 acc: 1.00000 val_loss: 0.17379, val_acc: 0.96667\n",
            "Epoch [6690/10000], loss: 0.10438 acc: 1.00000 val_loss: 0.17370, val_acc: 0.96667\n",
            "Epoch [6700/10000], loss: 0.10427 acc: 1.00000 val_loss: 0.17361, val_acc: 0.96667\n",
            "Epoch [6710/10000], loss: 0.10417 acc: 1.00000 val_loss: 0.17353, val_acc: 0.96667\n",
            "Epoch [6720/10000], loss: 0.10406 acc: 1.00000 val_loss: 0.17344, val_acc: 0.96667\n",
            "Epoch [6730/10000], loss: 0.10395 acc: 1.00000 val_loss: 0.17335, val_acc: 0.96667\n",
            "Epoch [6740/10000], loss: 0.10385 acc: 1.00000 val_loss: 0.17326, val_acc: 0.96667\n",
            "Epoch [6750/10000], loss: 0.10374 acc: 1.00000 val_loss: 0.17318, val_acc: 0.96667\n",
            "Epoch [6760/10000], loss: 0.10364 acc: 1.00000 val_loss: 0.17309, val_acc: 0.96667\n",
            "Epoch [6770/10000], loss: 0.10354 acc: 1.00000 val_loss: 0.17301, val_acc: 0.96667\n",
            "Epoch [6780/10000], loss: 0.10343 acc: 1.00000 val_loss: 0.17292, val_acc: 0.96667\n",
            "Epoch [6790/10000], loss: 0.10333 acc: 1.00000 val_loss: 0.17283, val_acc: 0.96667\n",
            "Epoch [6800/10000], loss: 0.10322 acc: 1.00000 val_loss: 0.17275, val_acc: 0.96667\n",
            "Epoch [6810/10000], loss: 0.10312 acc: 1.00000 val_loss: 0.17266, val_acc: 0.96667\n",
            "Epoch [6820/10000], loss: 0.10302 acc: 1.00000 val_loss: 0.17258, val_acc: 0.96667\n",
            "Epoch [6830/10000], loss: 0.10292 acc: 1.00000 val_loss: 0.17249, val_acc: 0.96667\n",
            "Epoch [6840/10000], loss: 0.10281 acc: 1.00000 val_loss: 0.17241, val_acc: 0.96667\n",
            "Epoch [6850/10000], loss: 0.10271 acc: 1.00000 val_loss: 0.17232, val_acc: 0.96667\n",
            "Epoch [6860/10000], loss: 0.10261 acc: 1.00000 val_loss: 0.17224, val_acc: 0.96667\n",
            "Epoch [6870/10000], loss: 0.10251 acc: 1.00000 val_loss: 0.17216, val_acc: 0.96667\n",
            "Epoch [6880/10000], loss: 0.10241 acc: 1.00000 val_loss: 0.17207, val_acc: 0.96667\n",
            "Epoch [6890/10000], loss: 0.10230 acc: 1.00000 val_loss: 0.17199, val_acc: 0.96667\n",
            "Epoch [6900/10000], loss: 0.10220 acc: 1.00000 val_loss: 0.17191, val_acc: 0.96667\n",
            "Epoch [6910/10000], loss: 0.10210 acc: 1.00000 val_loss: 0.17182, val_acc: 0.96667\n",
            "Epoch [6920/10000], loss: 0.10200 acc: 1.00000 val_loss: 0.17174, val_acc: 0.96667\n",
            "Epoch [6930/10000], loss: 0.10190 acc: 1.00000 val_loss: 0.17166, val_acc: 0.96667\n",
            "Epoch [6940/10000], loss: 0.10180 acc: 1.00000 val_loss: 0.17158, val_acc: 0.96667\n",
            "Epoch [6950/10000], loss: 0.10170 acc: 1.00000 val_loss: 0.17150, val_acc: 0.96667\n",
            "Epoch [6960/10000], loss: 0.10160 acc: 1.00000 val_loss: 0.17141, val_acc: 0.96667\n",
            "Epoch [6970/10000], loss: 0.10150 acc: 1.00000 val_loss: 0.17133, val_acc: 0.96667\n",
            "Epoch [6980/10000], loss: 0.10140 acc: 1.00000 val_loss: 0.17125, val_acc: 0.96667\n",
            "Epoch [6990/10000], loss: 0.10130 acc: 1.00000 val_loss: 0.17117, val_acc: 0.96667\n",
            "Epoch [7000/10000], loss: 0.10121 acc: 1.00000 val_loss: 0.17109, val_acc: 0.96667\n",
            "Epoch [7010/10000], loss: 0.10111 acc: 1.00000 val_loss: 0.17101, val_acc: 0.96667\n",
            "Epoch [7020/10000], loss: 0.10101 acc: 1.00000 val_loss: 0.17093, val_acc: 0.96667\n",
            "Epoch [7030/10000], loss: 0.10091 acc: 1.00000 val_loss: 0.17085, val_acc: 0.96667\n",
            "Epoch [7040/10000], loss: 0.10081 acc: 1.00000 val_loss: 0.17077, val_acc: 0.96667\n",
            "Epoch [7050/10000], loss: 0.10072 acc: 1.00000 val_loss: 0.17069, val_acc: 0.96667\n",
            "Epoch [7060/10000], loss: 0.10062 acc: 1.00000 val_loss: 0.17061, val_acc: 0.96667\n",
            "Epoch [7070/10000], loss: 0.10052 acc: 1.00000 val_loss: 0.17053, val_acc: 0.96667\n",
            "Epoch [7080/10000], loss: 0.10043 acc: 1.00000 val_loss: 0.17045, val_acc: 0.96667\n",
            "Epoch [7090/10000], loss: 0.10033 acc: 1.00000 val_loss: 0.17037, val_acc: 0.96667\n",
            "Epoch [7100/10000], loss: 0.10023 acc: 1.00000 val_loss: 0.17029, val_acc: 0.96667\n",
            "Epoch [7110/10000], loss: 0.10014 acc: 1.00000 val_loss: 0.17021, val_acc: 0.96667\n",
            "Epoch [7120/10000], loss: 0.10004 acc: 1.00000 val_loss: 0.17013, val_acc: 0.96667\n",
            "Epoch [7130/10000], loss: 0.09995 acc: 1.00000 val_loss: 0.17006, val_acc: 0.96667\n",
            "Epoch [7140/10000], loss: 0.09985 acc: 1.00000 val_loss: 0.16998, val_acc: 0.96667\n",
            "Epoch [7150/10000], loss: 0.09976 acc: 1.00000 val_loss: 0.16990, val_acc: 0.96667\n",
            "Epoch [7160/10000], loss: 0.09966 acc: 1.00000 val_loss: 0.16982, val_acc: 0.96667\n",
            "Epoch [7170/10000], loss: 0.09957 acc: 1.00000 val_loss: 0.16975, val_acc: 0.96667\n",
            "Epoch [7180/10000], loss: 0.09947 acc: 1.00000 val_loss: 0.16967, val_acc: 0.96667\n",
            "Epoch [7190/10000], loss: 0.09938 acc: 1.00000 val_loss: 0.16959, val_acc: 0.96667\n",
            "Epoch [7200/10000], loss: 0.09928 acc: 1.00000 val_loss: 0.16952, val_acc: 0.96667\n",
            "Epoch [7210/10000], loss: 0.09919 acc: 1.00000 val_loss: 0.16944, val_acc: 0.96667\n",
            "Epoch [7220/10000], loss: 0.09910 acc: 1.00000 val_loss: 0.16936, val_acc: 0.96667\n",
            "Epoch [7230/10000], loss: 0.09900 acc: 1.00000 val_loss: 0.16929, val_acc: 0.96667\n",
            "Epoch [7240/10000], loss: 0.09891 acc: 1.00000 val_loss: 0.16921, val_acc: 0.96667\n",
            "Epoch [7250/10000], loss: 0.09882 acc: 1.00000 val_loss: 0.16914, val_acc: 0.96667\n",
            "Epoch [7260/10000], loss: 0.09873 acc: 1.00000 val_loss: 0.16906, val_acc: 0.96667\n",
            "Epoch [7270/10000], loss: 0.09863 acc: 1.00000 val_loss: 0.16899, val_acc: 0.96667\n",
            "Epoch [7280/10000], loss: 0.09854 acc: 1.00000 val_loss: 0.16891, val_acc: 0.96667\n",
            "Epoch [7290/10000], loss: 0.09845 acc: 1.00000 val_loss: 0.16884, val_acc: 0.96667\n",
            "Epoch [7300/10000], loss: 0.09836 acc: 1.00000 val_loss: 0.16876, val_acc: 0.96667\n",
            "Epoch [7310/10000], loss: 0.09827 acc: 1.00000 val_loss: 0.16869, val_acc: 0.96667\n",
            "Epoch [7320/10000], loss: 0.09817 acc: 1.00000 val_loss: 0.16861, val_acc: 0.96667\n",
            "Epoch [7330/10000], loss: 0.09808 acc: 1.00000 val_loss: 0.16854, val_acc: 0.96667\n",
            "Epoch [7340/10000], loss: 0.09799 acc: 1.00000 val_loss: 0.16846, val_acc: 0.96667\n",
            "Epoch [7350/10000], loss: 0.09790 acc: 1.00000 val_loss: 0.16839, val_acc: 0.96667\n",
            "Epoch [7360/10000], loss: 0.09781 acc: 1.00000 val_loss: 0.16832, val_acc: 0.96667\n",
            "Epoch [7370/10000], loss: 0.09772 acc: 1.00000 val_loss: 0.16824, val_acc: 0.96667\n",
            "Epoch [7380/10000], loss: 0.09763 acc: 1.00000 val_loss: 0.16817, val_acc: 0.96667\n",
            "Epoch [7390/10000], loss: 0.09754 acc: 1.00000 val_loss: 0.16810, val_acc: 0.96667\n",
            "Epoch [7400/10000], loss: 0.09745 acc: 1.00000 val_loss: 0.16802, val_acc: 0.96667\n",
            "Epoch [7410/10000], loss: 0.09736 acc: 1.00000 val_loss: 0.16795, val_acc: 0.96667\n",
            "Epoch [7420/10000], loss: 0.09727 acc: 1.00000 val_loss: 0.16788, val_acc: 0.96667\n",
            "Epoch [7430/10000], loss: 0.09718 acc: 1.00000 val_loss: 0.16781, val_acc: 0.96667\n",
            "Epoch [7440/10000], loss: 0.09710 acc: 1.00000 val_loss: 0.16774, val_acc: 0.96667\n",
            "Epoch [7450/10000], loss: 0.09701 acc: 1.00000 val_loss: 0.16766, val_acc: 0.96667\n",
            "Epoch [7460/10000], loss: 0.09692 acc: 1.00000 val_loss: 0.16759, val_acc: 0.96667\n",
            "Epoch [7470/10000], loss: 0.09683 acc: 1.00000 val_loss: 0.16752, val_acc: 0.96667\n",
            "Epoch [7480/10000], loss: 0.09674 acc: 1.00000 val_loss: 0.16745, val_acc: 0.96667\n",
            "Epoch [7490/10000], loss: 0.09665 acc: 1.00000 val_loss: 0.16738, val_acc: 0.96667\n",
            "Epoch [7500/10000], loss: 0.09657 acc: 1.00000 val_loss: 0.16731, val_acc: 0.96667\n",
            "Epoch [7510/10000], loss: 0.09648 acc: 1.00000 val_loss: 0.16724, val_acc: 0.96667\n",
            "Epoch [7520/10000], loss: 0.09639 acc: 1.00000 val_loss: 0.16717, val_acc: 0.96667\n",
            "Epoch [7530/10000], loss: 0.09631 acc: 1.00000 val_loss: 0.16710, val_acc: 0.96667\n",
            "Epoch [7540/10000], loss: 0.09622 acc: 1.00000 val_loss: 0.16703, val_acc: 0.96667\n",
            "Epoch [7550/10000], loss: 0.09613 acc: 1.00000 val_loss: 0.16696, val_acc: 0.96667\n",
            "Epoch [7560/10000], loss: 0.09605 acc: 1.00000 val_loss: 0.16689, val_acc: 0.96667\n",
            "Epoch [7570/10000], loss: 0.09596 acc: 1.00000 val_loss: 0.16682, val_acc: 0.96667\n",
            "Epoch [7580/10000], loss: 0.09587 acc: 1.00000 val_loss: 0.16675, val_acc: 0.96667\n",
            "Epoch [7590/10000], loss: 0.09579 acc: 1.00000 val_loss: 0.16668, val_acc: 0.96667\n",
            "Epoch [7600/10000], loss: 0.09570 acc: 1.00000 val_loss: 0.16661, val_acc: 0.96667\n",
            "Epoch [7610/10000], loss: 0.09562 acc: 1.00000 val_loss: 0.16654, val_acc: 0.96667\n",
            "Epoch [7620/10000], loss: 0.09553 acc: 1.00000 val_loss: 0.16647, val_acc: 0.96667\n",
            "Epoch [7630/10000], loss: 0.09545 acc: 1.00000 val_loss: 0.16640, val_acc: 0.96667\n",
            "Epoch [7640/10000], loss: 0.09536 acc: 1.00000 val_loss: 0.16633, val_acc: 0.96667\n",
            "Epoch [7650/10000], loss: 0.09528 acc: 1.00000 val_loss: 0.16626, val_acc: 0.96667\n",
            "Epoch [7660/10000], loss: 0.09519 acc: 1.00000 val_loss: 0.16620, val_acc: 0.96667\n",
            "Epoch [7670/10000], loss: 0.09511 acc: 1.00000 val_loss: 0.16613, val_acc: 0.96667\n",
            "Epoch [7680/10000], loss: 0.09502 acc: 1.00000 val_loss: 0.16606, val_acc: 0.96667\n",
            "Epoch [7690/10000], loss: 0.09494 acc: 1.00000 val_loss: 0.16599, val_acc: 0.96667\n",
            "Epoch [7700/10000], loss: 0.09486 acc: 1.00000 val_loss: 0.16593, val_acc: 0.96667\n",
            "Epoch [7710/10000], loss: 0.09477 acc: 1.00000 val_loss: 0.16586, val_acc: 0.96667\n",
            "Epoch [7720/10000], loss: 0.09469 acc: 1.00000 val_loss: 0.16579, val_acc: 0.96667\n",
            "Epoch [7730/10000], loss: 0.09461 acc: 1.00000 val_loss: 0.16572, val_acc: 0.96667\n",
            "Epoch [7740/10000], loss: 0.09452 acc: 1.00000 val_loss: 0.16566, val_acc: 0.96667\n",
            "Epoch [7750/10000], loss: 0.09444 acc: 1.00000 val_loss: 0.16559, val_acc: 0.96667\n",
            "Epoch [7760/10000], loss: 0.09436 acc: 1.00000 val_loss: 0.16552, val_acc: 0.96667\n",
            "Epoch [7770/10000], loss: 0.09428 acc: 1.00000 val_loss: 0.16546, val_acc: 0.96667\n",
            "Epoch [7780/10000], loss: 0.09419 acc: 1.00000 val_loss: 0.16539, val_acc: 0.96667\n",
            "Epoch [7790/10000], loss: 0.09411 acc: 1.00000 val_loss: 0.16533, val_acc: 0.96667\n",
            "Epoch [7800/10000], loss: 0.09403 acc: 1.00000 val_loss: 0.16526, val_acc: 0.96667\n",
            "Epoch [7810/10000], loss: 0.09395 acc: 1.00000 val_loss: 0.16519, val_acc: 0.96667\n",
            "Epoch [7820/10000], loss: 0.09387 acc: 1.00000 val_loss: 0.16513, val_acc: 0.96667\n",
            "Epoch [7830/10000], loss: 0.09378 acc: 1.00000 val_loss: 0.16506, val_acc: 0.96667\n",
            "Epoch [7840/10000], loss: 0.09370 acc: 1.00000 val_loss: 0.16500, val_acc: 0.96667\n",
            "Epoch [7850/10000], loss: 0.09362 acc: 1.00000 val_loss: 0.16493, val_acc: 0.96667\n",
            "Epoch [7860/10000], loss: 0.09354 acc: 1.00000 val_loss: 0.16487, val_acc: 0.96667\n",
            "Epoch [7870/10000], loss: 0.09346 acc: 1.00000 val_loss: 0.16480, val_acc: 0.96667\n",
            "Epoch [7880/10000], loss: 0.09338 acc: 1.00000 val_loss: 0.16474, val_acc: 0.96667\n",
            "Epoch [7890/10000], loss: 0.09330 acc: 1.00000 val_loss: 0.16468, val_acc: 0.96667\n",
            "Epoch [7900/10000], loss: 0.09322 acc: 1.00000 val_loss: 0.16461, val_acc: 0.96667\n",
            "Epoch [7910/10000], loss: 0.09314 acc: 1.00000 val_loss: 0.16455, val_acc: 0.96667\n",
            "Epoch [7920/10000], loss: 0.09306 acc: 1.00000 val_loss: 0.16448, val_acc: 0.96667\n",
            "Epoch [7930/10000], loss: 0.09298 acc: 1.00000 val_loss: 0.16442, val_acc: 0.96667\n",
            "Epoch [7940/10000], loss: 0.09290 acc: 1.00000 val_loss: 0.16436, val_acc: 0.96667\n",
            "Epoch [7950/10000], loss: 0.09282 acc: 1.00000 val_loss: 0.16429, val_acc: 0.96667\n",
            "Epoch [7960/10000], loss: 0.09274 acc: 1.00000 val_loss: 0.16423, val_acc: 0.96667\n",
            "Epoch [7970/10000], loss: 0.09266 acc: 1.00000 val_loss: 0.16417, val_acc: 0.96667\n",
            "Epoch [7980/10000], loss: 0.09259 acc: 1.00000 val_loss: 0.16410, val_acc: 0.96667\n",
            "Epoch [7990/10000], loss: 0.09251 acc: 1.00000 val_loss: 0.16404, val_acc: 0.96667\n",
            "Epoch [8000/10000], loss: 0.09243 acc: 1.00000 val_loss: 0.16398, val_acc: 0.96667\n",
            "Epoch [8010/10000], loss: 0.09235 acc: 1.00000 val_loss: 0.16392, val_acc: 0.96667\n",
            "Epoch [8020/10000], loss: 0.09227 acc: 1.00000 val_loss: 0.16385, val_acc: 0.96667\n",
            "Epoch [8030/10000], loss: 0.09219 acc: 1.00000 val_loss: 0.16379, val_acc: 0.96667\n",
            "Epoch [8040/10000], loss: 0.09212 acc: 1.00000 val_loss: 0.16373, val_acc: 0.96667\n",
            "Epoch [8050/10000], loss: 0.09204 acc: 1.00000 val_loss: 0.16367, val_acc: 0.96667\n",
            "Epoch [8060/10000], loss: 0.09196 acc: 1.00000 val_loss: 0.16361, val_acc: 0.96667\n",
            "Epoch [8070/10000], loss: 0.09188 acc: 1.00000 val_loss: 0.16354, val_acc: 0.96667\n",
            "Epoch [8080/10000], loss: 0.09181 acc: 1.00000 val_loss: 0.16348, val_acc: 0.96667\n",
            "Epoch [8090/10000], loss: 0.09173 acc: 1.00000 val_loss: 0.16342, val_acc: 0.96667\n",
            "Epoch [8100/10000], loss: 0.09165 acc: 1.00000 val_loss: 0.16336, val_acc: 0.96667\n",
            "Epoch [8110/10000], loss: 0.09158 acc: 1.00000 val_loss: 0.16330, val_acc: 0.96667\n",
            "Epoch [8120/10000], loss: 0.09150 acc: 1.00000 val_loss: 0.16324, val_acc: 0.96667\n",
            "Epoch [8130/10000], loss: 0.09142 acc: 1.00000 val_loss: 0.16318, val_acc: 0.96667\n",
            "Epoch [8140/10000], loss: 0.09135 acc: 1.00000 val_loss: 0.16312, val_acc: 0.96667\n",
            "Epoch [8150/10000], loss: 0.09127 acc: 1.00000 val_loss: 0.16306, val_acc: 0.96667\n",
            "Epoch [8160/10000], loss: 0.09120 acc: 1.00000 val_loss: 0.16300, val_acc: 0.96667\n",
            "Epoch [8170/10000], loss: 0.09112 acc: 1.00000 val_loss: 0.16294, val_acc: 0.96667\n",
            "Epoch [8180/10000], loss: 0.09105 acc: 1.00000 val_loss: 0.16288, val_acc: 0.96667\n",
            "Epoch [8190/10000], loss: 0.09097 acc: 1.00000 val_loss: 0.16282, val_acc: 0.96667\n",
            "Epoch [8200/10000], loss: 0.09089 acc: 1.00000 val_loss: 0.16276, val_acc: 0.96667\n",
            "Epoch [8210/10000], loss: 0.09082 acc: 1.00000 val_loss: 0.16270, val_acc: 0.96667\n",
            "Epoch [8220/10000], loss: 0.09074 acc: 1.00000 val_loss: 0.16264, val_acc: 0.96667\n",
            "Epoch [8230/10000], loss: 0.09067 acc: 1.00000 val_loss: 0.16258, val_acc: 0.96667\n",
            "Epoch [8240/10000], loss: 0.09060 acc: 1.00000 val_loss: 0.16252, val_acc: 0.96667\n",
            "Epoch [8250/10000], loss: 0.09052 acc: 1.00000 val_loss: 0.16246, val_acc: 0.96667\n",
            "Epoch [8260/10000], loss: 0.09045 acc: 1.00000 val_loss: 0.16240, val_acc: 0.96667\n",
            "Epoch [8270/10000], loss: 0.09037 acc: 1.00000 val_loss: 0.16234, val_acc: 0.96667\n",
            "Epoch [8280/10000], loss: 0.09030 acc: 1.00000 val_loss: 0.16228, val_acc: 0.96667\n",
            "Epoch [8290/10000], loss: 0.09023 acc: 1.00000 val_loss: 0.16222, val_acc: 0.96667\n",
            "Epoch [8300/10000], loss: 0.09015 acc: 1.00000 val_loss: 0.16217, val_acc: 0.96667\n",
            "Epoch [8310/10000], loss: 0.09008 acc: 1.00000 val_loss: 0.16211, val_acc: 0.96667\n",
            "Epoch [8320/10000], loss: 0.09000 acc: 1.00000 val_loss: 0.16205, val_acc: 0.96667\n",
            "Epoch [8330/10000], loss: 0.08993 acc: 1.00000 val_loss: 0.16199, val_acc: 0.96667\n",
            "Epoch [8340/10000], loss: 0.08986 acc: 1.00000 val_loss: 0.16193, val_acc: 0.96667\n",
            "Epoch [8350/10000], loss: 0.08979 acc: 1.00000 val_loss: 0.16188, val_acc: 0.96667\n",
            "Epoch [8360/10000], loss: 0.08971 acc: 1.00000 val_loss: 0.16182, val_acc: 0.96667\n",
            "Epoch [8370/10000], loss: 0.08964 acc: 1.00000 val_loss: 0.16176, val_acc: 0.96667\n",
            "Epoch [8380/10000], loss: 0.08957 acc: 1.00000 val_loss: 0.16170, val_acc: 0.96667\n",
            "Epoch [8390/10000], loss: 0.08950 acc: 1.00000 val_loss: 0.16165, val_acc: 0.96667\n",
            "Epoch [8400/10000], loss: 0.08942 acc: 1.00000 val_loss: 0.16159, val_acc: 0.96667\n",
            "Epoch [8410/10000], loss: 0.08935 acc: 1.00000 val_loss: 0.16153, val_acc: 0.96667\n",
            "Epoch [8420/10000], loss: 0.08928 acc: 1.00000 val_loss: 0.16148, val_acc: 0.96667\n",
            "Epoch [8430/10000], loss: 0.08921 acc: 1.00000 val_loss: 0.16142, val_acc: 0.96667\n",
            "Epoch [8440/10000], loss: 0.08914 acc: 1.00000 val_loss: 0.16136, val_acc: 0.96667\n",
            "Epoch [8450/10000], loss: 0.08907 acc: 1.00000 val_loss: 0.16131, val_acc: 0.96667\n",
            "Epoch [8460/10000], loss: 0.08899 acc: 1.00000 val_loss: 0.16125, val_acc: 0.96667\n",
            "Epoch [8470/10000], loss: 0.08892 acc: 1.00000 val_loss: 0.16119, val_acc: 0.96667\n",
            "Epoch [8480/10000], loss: 0.08885 acc: 1.00000 val_loss: 0.16114, val_acc: 0.96667\n",
            "Epoch [8490/10000], loss: 0.08878 acc: 1.00000 val_loss: 0.16108, val_acc: 0.96667\n",
            "Epoch [8500/10000], loss: 0.08871 acc: 1.00000 val_loss: 0.16103, val_acc: 0.96667\n",
            "Epoch [8510/10000], loss: 0.08864 acc: 1.00000 val_loss: 0.16097, val_acc: 0.96667\n",
            "Epoch [8520/10000], loss: 0.08857 acc: 1.00000 val_loss: 0.16092, val_acc: 0.96667\n",
            "Epoch [8530/10000], loss: 0.08850 acc: 1.00000 val_loss: 0.16086, val_acc: 0.96667\n",
            "Epoch [8540/10000], loss: 0.08843 acc: 1.00000 val_loss: 0.16081, val_acc: 0.96667\n",
            "Epoch [8550/10000], loss: 0.08836 acc: 1.00000 val_loss: 0.16075, val_acc: 0.96667\n",
            "Epoch [8560/10000], loss: 0.08829 acc: 1.00000 val_loss: 0.16070, val_acc: 0.96667\n",
            "Epoch [8570/10000], loss: 0.08822 acc: 1.00000 val_loss: 0.16064, val_acc: 0.96667\n",
            "Epoch [8580/10000], loss: 0.08815 acc: 1.00000 val_loss: 0.16059, val_acc: 0.96667\n",
            "Epoch [8590/10000], loss: 0.08808 acc: 1.00000 val_loss: 0.16053, val_acc: 0.96667\n",
            "Epoch [8600/10000], loss: 0.08801 acc: 1.00000 val_loss: 0.16048, val_acc: 0.96667\n",
            "Epoch [8610/10000], loss: 0.08794 acc: 1.00000 val_loss: 0.16042, val_acc: 0.96667\n",
            "Epoch [8620/10000], loss: 0.08787 acc: 1.00000 val_loss: 0.16037, val_acc: 0.96667\n",
            "Epoch [8630/10000], loss: 0.08780 acc: 1.00000 val_loss: 0.16031, val_acc: 0.96667\n",
            "Epoch [8640/10000], loss: 0.08774 acc: 1.00000 val_loss: 0.16026, val_acc: 0.96667\n",
            "Epoch [8650/10000], loss: 0.08767 acc: 1.00000 val_loss: 0.16021, val_acc: 0.96667\n",
            "Epoch [8660/10000], loss: 0.08760 acc: 1.00000 val_loss: 0.16015, val_acc: 0.96667\n",
            "Epoch [8670/10000], loss: 0.08753 acc: 1.00000 val_loss: 0.16010, val_acc: 0.96667\n",
            "Epoch [8680/10000], loss: 0.08746 acc: 1.00000 val_loss: 0.16005, val_acc: 0.96667\n",
            "Epoch [8690/10000], loss: 0.08739 acc: 1.00000 val_loss: 0.15999, val_acc: 0.96667\n",
            "Epoch [8700/10000], loss: 0.08733 acc: 1.00000 val_loss: 0.15994, val_acc: 0.96667\n",
            "Epoch [8710/10000], loss: 0.08726 acc: 1.00000 val_loss: 0.15989, val_acc: 0.96667\n",
            "Epoch [8720/10000], loss: 0.08719 acc: 1.00000 val_loss: 0.15983, val_acc: 0.96667\n",
            "Epoch [8730/10000], loss: 0.08712 acc: 1.00000 val_loss: 0.15978, val_acc: 0.96667\n",
            "Epoch [8740/10000], loss: 0.08706 acc: 1.00000 val_loss: 0.15973, val_acc: 0.96667\n",
            "Epoch [8750/10000], loss: 0.08699 acc: 1.00000 val_loss: 0.15967, val_acc: 0.96667\n",
            "Epoch [8760/10000], loss: 0.08692 acc: 1.00000 val_loss: 0.15962, val_acc: 0.96667\n",
            "Epoch [8770/10000], loss: 0.08685 acc: 1.00000 val_loss: 0.15957, val_acc: 0.96667\n",
            "Epoch [8780/10000], loss: 0.08679 acc: 1.00000 val_loss: 0.15952, val_acc: 0.96667\n",
            "Epoch [8790/10000], loss: 0.08672 acc: 1.00000 val_loss: 0.15946, val_acc: 0.96667\n",
            "Epoch [8800/10000], loss: 0.08665 acc: 1.00000 val_loss: 0.15941, val_acc: 0.96667\n",
            "Epoch [8810/10000], loss: 0.08659 acc: 1.00000 val_loss: 0.15936, val_acc: 0.96667\n",
            "Epoch [8820/10000], loss: 0.08652 acc: 1.00000 val_loss: 0.15931, val_acc: 0.96667\n",
            "Epoch [8830/10000], loss: 0.08646 acc: 1.00000 val_loss: 0.15926, val_acc: 0.96667\n",
            "Epoch [8840/10000], loss: 0.08639 acc: 1.00000 val_loss: 0.15921, val_acc: 0.96667\n",
            "Epoch [8850/10000], loss: 0.08632 acc: 1.00000 val_loss: 0.15915, val_acc: 0.96667\n",
            "Epoch [8860/10000], loss: 0.08626 acc: 1.00000 val_loss: 0.15910, val_acc: 0.96667\n",
            "Epoch [8870/10000], loss: 0.08619 acc: 1.00000 val_loss: 0.15905, val_acc: 0.96667\n",
            "Epoch [8880/10000], loss: 0.08613 acc: 1.00000 val_loss: 0.15900, val_acc: 0.96667\n",
            "Epoch [8890/10000], loss: 0.08606 acc: 1.00000 val_loss: 0.15895, val_acc: 0.96667\n",
            "Epoch [8900/10000], loss: 0.08600 acc: 1.00000 val_loss: 0.15890, val_acc: 0.96667\n",
            "Epoch [8910/10000], loss: 0.08593 acc: 1.00000 val_loss: 0.15885, val_acc: 0.96667\n",
            "Epoch [8920/10000], loss: 0.08587 acc: 1.00000 val_loss: 0.15880, val_acc: 0.96667\n",
            "Epoch [8930/10000], loss: 0.08580 acc: 1.00000 val_loss: 0.15875, val_acc: 0.96667\n",
            "Epoch [8940/10000], loss: 0.08574 acc: 1.00000 val_loss: 0.15870, val_acc: 0.96667\n",
            "Epoch [8950/10000], loss: 0.08567 acc: 1.00000 val_loss: 0.15864, val_acc: 0.96667\n",
            "Epoch [8960/10000], loss: 0.08561 acc: 1.00000 val_loss: 0.15859, val_acc: 0.96667\n",
            "Epoch [8970/10000], loss: 0.08554 acc: 1.00000 val_loss: 0.15854, val_acc: 0.96667\n",
            "Epoch [8980/10000], loss: 0.08548 acc: 1.00000 val_loss: 0.15849, val_acc: 0.96667\n",
            "Epoch [8990/10000], loss: 0.08541 acc: 1.00000 val_loss: 0.15844, val_acc: 0.96667\n",
            "Epoch [9000/10000], loss: 0.08535 acc: 1.00000 val_loss: 0.15839, val_acc: 0.96667\n",
            "Epoch [9010/10000], loss: 0.08529 acc: 1.00000 val_loss: 0.15834, val_acc: 0.96667\n",
            "Epoch [9020/10000], loss: 0.08522 acc: 1.00000 val_loss: 0.15830, val_acc: 0.96667\n",
            "Epoch [9030/10000], loss: 0.08516 acc: 1.00000 val_loss: 0.15825, val_acc: 0.96667\n",
            "Epoch [9040/10000], loss: 0.08509 acc: 1.00000 val_loss: 0.15820, val_acc: 0.96667\n",
            "Epoch [9050/10000], loss: 0.08503 acc: 1.00000 val_loss: 0.15815, val_acc: 0.96667\n",
            "Epoch [9060/10000], loss: 0.08497 acc: 1.00000 val_loss: 0.15810, val_acc: 0.96667\n",
            "Epoch [9070/10000], loss: 0.08490 acc: 1.00000 val_loss: 0.15805, val_acc: 0.96667\n",
            "Epoch [9080/10000], loss: 0.08484 acc: 1.00000 val_loss: 0.15800, val_acc: 0.96667\n",
            "Epoch [9090/10000], loss: 0.08478 acc: 1.00000 val_loss: 0.15795, val_acc: 0.96667\n",
            "Epoch [9100/10000], loss: 0.08472 acc: 1.00000 val_loss: 0.15790, val_acc: 0.96667\n",
            "Epoch [9110/10000], loss: 0.08465 acc: 1.00000 val_loss: 0.15785, val_acc: 0.96667\n",
            "Epoch [9120/10000], loss: 0.08459 acc: 1.00000 val_loss: 0.15780, val_acc: 0.96667\n",
            "Epoch [9130/10000], loss: 0.08453 acc: 1.00000 val_loss: 0.15776, val_acc: 0.96667\n",
            "Epoch [9140/10000], loss: 0.08446 acc: 1.00000 val_loss: 0.15771, val_acc: 0.96667\n",
            "Epoch [9150/10000], loss: 0.08440 acc: 1.00000 val_loss: 0.15766, val_acc: 0.96667\n",
            "Epoch [9160/10000], loss: 0.08434 acc: 1.00000 val_loss: 0.15761, val_acc: 0.96667\n",
            "Epoch [9170/10000], loss: 0.08428 acc: 1.00000 val_loss: 0.15756, val_acc: 0.96667\n",
            "Epoch [9180/10000], loss: 0.08422 acc: 1.00000 val_loss: 0.15752, val_acc: 0.96667\n",
            "Epoch [9190/10000], loss: 0.08415 acc: 1.00000 val_loss: 0.15747, val_acc: 0.96667\n",
            "Epoch [9200/10000], loss: 0.08409 acc: 1.00000 val_loss: 0.15742, val_acc: 0.96667\n",
            "Epoch [9210/10000], loss: 0.08403 acc: 1.00000 val_loss: 0.15737, val_acc: 0.96667\n",
            "Epoch [9220/10000], loss: 0.08397 acc: 1.00000 val_loss: 0.15733, val_acc: 0.96667\n",
            "Epoch [9230/10000], loss: 0.08391 acc: 1.00000 val_loss: 0.15728, val_acc: 0.96667\n",
            "Epoch [9240/10000], loss: 0.08385 acc: 1.00000 val_loss: 0.15723, val_acc: 0.96667\n",
            "Epoch [9250/10000], loss: 0.08379 acc: 1.00000 val_loss: 0.15718, val_acc: 0.96667\n",
            "Epoch [9260/10000], loss: 0.08372 acc: 1.00000 val_loss: 0.15714, val_acc: 0.96667\n",
            "Epoch [9270/10000], loss: 0.08366 acc: 1.00000 val_loss: 0.15709, val_acc: 0.96667\n",
            "Epoch [9280/10000], loss: 0.08360 acc: 1.00000 val_loss: 0.15704, val_acc: 0.96667\n",
            "Epoch [9290/10000], loss: 0.08354 acc: 1.00000 val_loss: 0.15700, val_acc: 0.96667\n",
            "Epoch [9300/10000], loss: 0.08348 acc: 1.00000 val_loss: 0.15695, val_acc: 0.96667\n",
            "Epoch [9310/10000], loss: 0.08342 acc: 1.00000 val_loss: 0.15690, val_acc: 0.96667\n",
            "Epoch [9320/10000], loss: 0.08336 acc: 1.00000 val_loss: 0.15686, val_acc: 0.96667\n",
            "Epoch [9330/10000], loss: 0.08330 acc: 1.00000 val_loss: 0.15681, val_acc: 0.96667\n",
            "Epoch [9340/10000], loss: 0.08324 acc: 1.00000 val_loss: 0.15676, val_acc: 0.96667\n",
            "Epoch [9350/10000], loss: 0.08318 acc: 1.00000 val_loss: 0.15672, val_acc: 0.96667\n",
            "Epoch [9360/10000], loss: 0.08312 acc: 1.00000 val_loss: 0.15667, val_acc: 0.96667\n",
            "Epoch [9370/10000], loss: 0.08306 acc: 1.00000 val_loss: 0.15662, val_acc: 0.96667\n",
            "Epoch [9380/10000], loss: 0.08300 acc: 1.00000 val_loss: 0.15658, val_acc: 0.96667\n",
            "Epoch [9390/10000], loss: 0.08294 acc: 1.00000 val_loss: 0.15653, val_acc: 0.96667\n",
            "Epoch [9400/10000], loss: 0.08288 acc: 1.00000 val_loss: 0.15649, val_acc: 0.96667\n",
            "Epoch [9410/10000], loss: 0.08282 acc: 1.00000 val_loss: 0.15644, val_acc: 0.96667\n",
            "Epoch [9420/10000], loss: 0.08276 acc: 1.00000 val_loss: 0.15640, val_acc: 0.96667\n",
            "Epoch [9430/10000], loss: 0.08270 acc: 1.00000 val_loss: 0.15635, val_acc: 0.96667\n",
            "Epoch [9440/10000], loss: 0.08265 acc: 1.00000 val_loss: 0.15630, val_acc: 0.96667\n",
            "Epoch [9450/10000], loss: 0.08259 acc: 1.00000 val_loss: 0.15626, val_acc: 0.96667\n",
            "Epoch [9460/10000], loss: 0.08253 acc: 1.00000 val_loss: 0.15621, val_acc: 0.96667\n",
            "Epoch [9470/10000], loss: 0.08247 acc: 1.00000 val_loss: 0.15617, val_acc: 0.96667\n",
            "Epoch [9480/10000], loss: 0.08241 acc: 1.00000 val_loss: 0.15612, val_acc: 0.96667\n",
            "Epoch [9490/10000], loss: 0.08235 acc: 1.00000 val_loss: 0.15608, val_acc: 0.96667\n",
            "Epoch [9500/10000], loss: 0.08229 acc: 1.00000 val_loss: 0.15603, val_acc: 0.96667\n",
            "Epoch [9510/10000], loss: 0.08224 acc: 1.00000 val_loss: 0.15599, val_acc: 0.96667\n",
            "Epoch [9520/10000], loss: 0.08218 acc: 1.00000 val_loss: 0.15594, val_acc: 0.96667\n",
            "Epoch [9530/10000], loss: 0.08212 acc: 1.00000 val_loss: 0.15590, val_acc: 0.96667\n",
            "Epoch [9540/10000], loss: 0.08206 acc: 1.00000 val_loss: 0.15586, val_acc: 0.96667\n",
            "Epoch [9550/10000], loss: 0.08200 acc: 1.00000 val_loss: 0.15581, val_acc: 0.96667\n",
            "Epoch [9560/10000], loss: 0.08195 acc: 1.00000 val_loss: 0.15577, val_acc: 0.96667\n",
            "Epoch [9570/10000], loss: 0.08189 acc: 1.00000 val_loss: 0.15572, val_acc: 0.96667\n",
            "Epoch [9580/10000], loss: 0.08183 acc: 1.00000 val_loss: 0.15568, val_acc: 0.96667\n",
            "Epoch [9590/10000], loss: 0.08177 acc: 1.00000 val_loss: 0.15563, val_acc: 0.96667\n",
            "Epoch [9600/10000], loss: 0.08172 acc: 1.00000 val_loss: 0.15559, val_acc: 0.96667\n",
            "Epoch [9610/10000], loss: 0.08166 acc: 1.00000 val_loss: 0.15555, val_acc: 0.96667\n",
            "Epoch [9620/10000], loss: 0.08160 acc: 1.00000 val_loss: 0.15550, val_acc: 0.96667\n",
            "Epoch [9630/10000], loss: 0.08154 acc: 1.00000 val_loss: 0.15546, val_acc: 0.96667\n",
            "Epoch [9640/10000], loss: 0.08149 acc: 1.00000 val_loss: 0.15542, val_acc: 0.96667\n",
            "Epoch [9650/10000], loss: 0.08143 acc: 1.00000 val_loss: 0.15537, val_acc: 0.96667\n",
            "Epoch [9660/10000], loss: 0.08137 acc: 1.00000 val_loss: 0.15533, val_acc: 0.96667\n",
            "Epoch [9670/10000], loss: 0.08132 acc: 1.00000 val_loss: 0.15529, val_acc: 0.96667\n",
            "Epoch [9680/10000], loss: 0.08126 acc: 1.00000 val_loss: 0.15524, val_acc: 0.96667\n",
            "Epoch [9690/10000], loss: 0.08120 acc: 1.00000 val_loss: 0.15520, val_acc: 0.96667\n",
            "Epoch [9700/10000], loss: 0.08115 acc: 1.00000 val_loss: 0.15516, val_acc: 0.96667\n",
            "Epoch [9710/10000], loss: 0.08109 acc: 1.00000 val_loss: 0.15511, val_acc: 0.96667\n",
            "Epoch [9720/10000], loss: 0.08103 acc: 1.00000 val_loss: 0.15507, val_acc: 0.96667\n",
            "Epoch [9730/10000], loss: 0.08098 acc: 1.00000 val_loss: 0.15503, val_acc: 0.96667\n",
            "Epoch [9740/10000], loss: 0.08092 acc: 1.00000 val_loss: 0.15499, val_acc: 0.96667\n",
            "Epoch [9750/10000], loss: 0.08087 acc: 1.00000 val_loss: 0.15494, val_acc: 0.96667\n",
            "Epoch [9760/10000], loss: 0.08081 acc: 1.00000 val_loss: 0.15490, val_acc: 0.96667\n",
            "Epoch [9770/10000], loss: 0.08076 acc: 1.00000 val_loss: 0.15486, val_acc: 0.96667\n",
            "Epoch [9780/10000], loss: 0.08070 acc: 1.00000 val_loss: 0.15482, val_acc: 0.96667\n",
            "Epoch [9790/10000], loss: 0.08064 acc: 1.00000 val_loss: 0.15477, val_acc: 0.96667\n",
            "Epoch [9800/10000], loss: 0.08059 acc: 1.00000 val_loss: 0.15473, val_acc: 0.96667\n",
            "Epoch [9810/10000], loss: 0.08053 acc: 1.00000 val_loss: 0.15469, val_acc: 0.96667\n",
            "Epoch [9820/10000], loss: 0.08048 acc: 1.00000 val_loss: 0.15465, val_acc: 0.96667\n",
            "Epoch [9830/10000], loss: 0.08042 acc: 1.00000 val_loss: 0.15461, val_acc: 0.96667\n",
            "Epoch [9840/10000], loss: 0.08037 acc: 1.00000 val_loss: 0.15456, val_acc: 0.96667\n",
            "Epoch [9850/10000], loss: 0.08031 acc: 1.00000 val_loss: 0.15452, val_acc: 0.96667\n",
            "Epoch [9860/10000], loss: 0.08026 acc: 1.00000 val_loss: 0.15448, val_acc: 0.96667\n",
            "Epoch [9870/10000], loss: 0.08020 acc: 1.00000 val_loss: 0.15444, val_acc: 0.96667\n",
            "Epoch [9880/10000], loss: 0.08015 acc: 1.00000 val_loss: 0.15440, val_acc: 0.96667\n",
            "Epoch [9890/10000], loss: 0.08009 acc: 1.00000 val_loss: 0.15436, val_acc: 0.96667\n",
            "Epoch [9900/10000], loss: 0.08004 acc: 1.00000 val_loss: 0.15432, val_acc: 0.96667\n",
            "Epoch [9910/10000], loss: 0.07999 acc: 1.00000 val_loss: 0.15427, val_acc: 0.96667\n",
            "Epoch [9920/10000], loss: 0.07993 acc: 1.00000 val_loss: 0.15423, val_acc: 0.96667\n",
            "Epoch [9930/10000], loss: 0.07988 acc: 1.00000 val_loss: 0.15419, val_acc: 0.96667\n",
            "Epoch [9940/10000], loss: 0.07982 acc: 1.00000 val_loss: 0.15415, val_acc: 0.96667\n",
            "Epoch [9950/10000], loss: 0.07977 acc: 1.00000 val_loss: 0.15411, val_acc: 0.96667\n",
            "Epoch [9960/10000], loss: 0.07972 acc: 1.00000 val_loss: 0.15407, val_acc: 0.96667\n",
            "Epoch [9970/10000], loss: 0.07966 acc: 1.00000 val_loss: 0.15403, val_acc: 0.96667\n",
            "Epoch [9980/10000], loss: 0.07961 acc: 1.00000 val_loss: 0.15399, val_acc: 0.96667\n",
            "Epoch [9990/10000], loss: 0.07955 acc: 1.00000 val_loss: 0.15395, val_acc: 0.96667\n"
          ]
        }
      ],
      "source": [
        "# 繰り返し計算メインループ\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # 訓練フェーズ\n",
        "    \n",
        "    #勾配値初期化\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 予測計算\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # 損失計算\n",
        "    loss = criterion(outputs, labels1)\n",
        "\n",
        "    # 勾配計算\n",
        "    loss.backward()\n",
        "    \n",
        "    # パラメータ修正\n",
        "    optimizer.step()\n",
        "\n",
        "    # 損失の保存(スカラー値の取得)\n",
        "    train_loss = loss.item()\n",
        "\n",
        "    # 予測ラベル(1 or 0)計算\n",
        "    predicted = torch.where(outputs < 0.5, 0, 1)\n",
        "    \n",
        "    # 精度計算\n",
        "    train_acc = (predicted == labels1).sum() / len(y_train)\n",
        "\n",
        "    # 予測フェーズ\n",
        "\n",
        "    # 予測計算\n",
        "    outputs_test = net(inputs_test)\n",
        "\n",
        "    # 損失計算\n",
        "    loss_test = criterion(outputs_test, labels1_test)\n",
        "\n",
        "    # 損失の保存（スカラー値の取得）\n",
        "    val_loss =  loss_test.item()\n",
        "        \n",
        "    # 予測ラベル(1 or 0)計算\n",
        "    predicted_test = torch.where(outputs_test < 0.5, 0, 1)\n",
        "\n",
        "    # 精度計算\n",
        "    val_acc = (predicted_test == labels1_test).sum() / len(y_test)\n",
        "    \n",
        "    if ( epoch % 10 == 0):\n",
        "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
        "        item = np.array([epoch, train_loss, train_acc, val_loss, val_acc])\n",
        "        history = np.vstack((history, item))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTk6dHwfPsqm"
      },
      "source": [
        "## 6.10 結果確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6YBWkJXvPsqm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "初期状態: 損失: 4.49384 精度: 0.50000\n",
            "最終状態: 損失: 0.15395 精度: 0.96667\n"
          ]
        }
      ],
      "source": [
        "#損失と精度の確認\n",
        "\n",
        "print(f'初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
        "print(f'最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "E_FBeQjBPsqn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 23398 (\\N{CJK UNIFIED IDEOGRAPH-5B66}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 32722 (\\N{CJK UNIFIED IDEOGRAPH-7FD2}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 32218 (\\N{CJK UNIFIED IDEOGRAPH-7DDA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 25613 (\\N{CJK UNIFIED IDEOGRAPH-640D}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 22833 (\\N{CJK UNIFIED IDEOGRAPH-5931}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 32368 (\\N{CJK UNIFIED IDEOGRAPH-7E70}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 12426 (\\N{HIRAGANA LETTER RI}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 36820 (\\N{CJK UNIFIED IDEOGRAPH-8FD4}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 12375 (\\N{HIRAGANA LETTER SI}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 22238 (\\N{CJK UNIFIED IDEOGRAPH-56DE}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 35347 (\\N{CJK UNIFIED IDEOGRAPH-8A13}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 32244 (\\N{CJK UNIFIED IDEOGRAPH-7DF4}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 26908 (\\N{CJK UNIFIED IDEOGRAPH-691C}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 35388 (\\N{CJK UNIFIED IDEOGRAPH-8A3C}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 学習曲線の表示 (損失)\n",
        "\n",
        "plt.plot(history[:,0], history[:,1], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,3], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('損失')\n",
        "plt.title('学習曲線(損失)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PsEjWTI2Psqn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 23398 (\\N{CJK UNIFIED IDEOGRAPH-5B66}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 32722 (\\N{CJK UNIFIED IDEOGRAPH-7FD2}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 32218 (\\N{CJK UNIFIED IDEOGRAPH-7DDA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 31934 (\\N{CJK UNIFIED IDEOGRAPH-7CBE}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 32368 (\\N{CJK UNIFIED IDEOGRAPH-7E70}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 12426 (\\N{HIRAGANA LETTER RI}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 36820 (\\N{CJK UNIFIED IDEOGRAPH-8FD4}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 12375 (\\N{HIRAGANA LETTER SI}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 22238 (\\N{CJK UNIFIED IDEOGRAPH-56DE}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 35347 (\\N{CJK UNIFIED IDEOGRAPH-8A13}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 32244 (\\N{CJK UNIFIED IDEOGRAPH-7DF4}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 26908 (\\N{CJK UNIFIED IDEOGRAPH-691C}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 35388 (\\N{CJK UNIFIED IDEOGRAPH-8A3C}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 学習曲線の表示 (精度)\n",
        "\n",
        "plt.plot(history[:,0], history[:,2], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,4], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('精度')\n",
        "plt.title('学習曲線(精度)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtiZzCnKPsqn"
      },
      "source": [
        "### 決定境界のグラフ表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZEV3sKftPsqo"
      },
      "outputs": [],
      "source": [
        "# 検証データを散布図用に準備\n",
        "\n",
        "x_t0 = x_test[y_test==0]\n",
        "x_t1 = x_test[y_test==1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "3knK_C7kPsqo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BIAS = [0.33861223], WEIGHT = [[ 2.9700334 -5.300017 ]]\n",
            "xl = [4.4 7. ]  yl = [2.52956915 3.98656204]\n"
          ]
        }
      ],
      "source": [
        "# パラメータの取得\n",
        "\n",
        "bias = net.l1.bias.data.numpy()\n",
        "weight = net.l1.weight.data.numpy()\n",
        "print(f'BIAS = {bias}, WEIGHT = {weight}')\n",
        "\n",
        "# 決定境界描画用 x1の値から x2の値を計算する\n",
        "def decision(x):\n",
        "    return(-(bias + weight[0,0] * x)/ weight[0,1])\n",
        "\n",
        "# 散布図のx1の最小値と最大値\n",
        "xl = np.array([x_test[:,0].min(), x_test[:,0].max()])\n",
        "yl = decision(xl)\n",
        "\n",
        "# 結果確認\n",
        "print(f'xl = {xl}  yl = {yl}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wV_ncIo0Psqo"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 散布図表示\n",
        "plt.scatter(x_t0[:,0], x_t0[:,1], marker='x', \n",
        "        c='b', s=50, label='class 0')\n",
        "plt.scatter(x_t1[:,0], x_t1[:,1], marker='o', \n",
        "        c='k', s=50, label='class 1')\n",
        "\n",
        "# 決定境界直線\n",
        "plt.plot(xl, yl, c='b')\n",
        "plt.xlabel('sepal_length')\n",
        "plt.ylabel('sepal_width')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0jF0iMzPsqo"
      },
      "source": [
        "## コラム　BCELoss関数とBCEWithLogitsLoss関数の違い"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0yNjht06Psqp"
      },
      "outputs": [],
      "source": [
        "# モデルの定義\n",
        "# 2入力1出力のロジスティック回帰モデル\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_input, n_output):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(n_input, n_output)\n",
        "                \n",
        "        # 初期値を全部1にする\n",
        "        # 「ディープラーニングの数学」と条件を合わせる目的        \n",
        "        self.l1.weight.data.fill_(1.0)\n",
        "        self.l1.bias.data.fill_(1.0)        \n",
        "        \n",
        "    # 予測関数の定義\n",
        "    def forward(self, x):\n",
        "        # 入力値と行列の積を計算する\n",
        "        x1 = self.l1(x)\n",
        "        return x1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "A3dil0VDPsqp"
      },
      "outputs": [],
      "source": [
        "# 学習率\n",
        "lr = 0.01\n",
        "\n",
        "# 初期化\n",
        "net = Net(n_input, n_output)\n",
        "\n",
        "# 損失関数： logits付き交差エントロピー関数\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# 最適化関数: 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 10000\n",
        "\n",
        "# 記録用リストの初期化\n",
        "history = np.zeros((0,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "abFfu6brPsqp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [0/10000], loss: 4.77294 acc: 0.50000 val_loss: 4.49384, val_acc: 0.50000\n",
            "Epoch [10/10000], loss: 3.80546 acc: 0.50000 val_loss: 3.56537, val_acc: 0.50000\n",
            "Epoch [20/10000], loss: 2.84328 acc: 0.50000 val_loss: 2.64328, val_acc: 0.50000\n",
            "Epoch [30/10000], loss: 1.91613 acc: 0.50000 val_loss: 1.76244, val_acc: 0.50000\n",
            "Epoch [40/10000], loss: 1.17137 acc: 0.50000 val_loss: 1.08537, val_acc: 0.50000\n",
            "Epoch [50/10000], loss: 0.84140 acc: 0.50000 val_loss: 0.81872, val_acc: 0.50000\n",
            "Epoch [60/10000], loss: 0.77087 acc: 0.50000 val_loss: 0.77093, val_acc: 0.50000\n",
            "Epoch [70/10000], loss: 0.75450 acc: 0.34286 val_loss: 0.76105, val_acc: 0.33333\n",
            "Epoch [80/10000], loss: 0.74542 acc: 0.25714 val_loss: 0.75447, val_acc: 0.20000\n",
            "Epoch [90/10000], loss: 0.73734 acc: 0.24286 val_loss: 0.74778, val_acc: 0.16667\n",
            "Epoch [100/10000], loss: 0.72949 acc: 0.24286 val_loss: 0.74098, val_acc: 0.13333\n",
            "Epoch [110/10000], loss: 0.72180 acc: 0.27143 val_loss: 0.73419, val_acc: 0.16667\n",
            "Epoch [120/10000], loss: 0.71423 acc: 0.31429 val_loss: 0.72748, val_acc: 0.20000\n",
            "Epoch [130/10000], loss: 0.70680 acc: 0.41429 val_loss: 0.72087, val_acc: 0.20000\n",
            "Epoch [140/10000], loss: 0.69949 acc: 0.47143 val_loss: 0.71437, val_acc: 0.26667\n",
            "Epoch [150/10000], loss: 0.69230 acc: 0.52857 val_loss: 0.70797, val_acc: 0.30000\n",
            "Epoch [160/10000], loss: 0.68524 acc: 0.60000 val_loss: 0.70167, val_acc: 0.36667\n",
            "Epoch [170/10000], loss: 0.67829 acc: 0.62857 val_loss: 0.69548, val_acc: 0.43333\n",
            "Epoch [180/10000], loss: 0.67147 acc: 0.68571 val_loss: 0.68938, val_acc: 0.50000\n",
            "Epoch [190/10000], loss: 0.66476 acc: 0.75714 val_loss: 0.68339, val_acc: 0.56667\n",
            "Epoch [200/10000], loss: 0.65816 acc: 0.81429 val_loss: 0.67749, val_acc: 0.70000\n",
            "Epoch [210/10000], loss: 0.65168 acc: 0.84286 val_loss: 0.67169, val_acc: 0.70000\n",
            "Epoch [220/10000], loss: 0.64531 acc: 0.85714 val_loss: 0.66599, val_acc: 0.73333\n",
            "Epoch [230/10000], loss: 0.63904 acc: 0.85714 val_loss: 0.66037, val_acc: 0.76667\n",
            "Epoch [240/10000], loss: 0.63288 acc: 0.88571 val_loss: 0.65485, val_acc: 0.80000\n",
            "Epoch [250/10000], loss: 0.62682 acc: 0.88571 val_loss: 0.64942, val_acc: 0.83333\n",
            "Epoch [260/10000], loss: 0.62087 acc: 0.90000 val_loss: 0.64408, val_acc: 0.83333\n",
            "Epoch [270/10000], loss: 0.61501 acc: 0.91429 val_loss: 0.63882, val_acc: 0.83333\n",
            "Epoch [280/10000], loss: 0.60925 acc: 0.92857 val_loss: 0.63364, val_acc: 0.86667\n",
            "Epoch [290/10000], loss: 0.60359 acc: 0.94286 val_loss: 0.62855, val_acc: 0.90000\n",
            "Epoch [300/10000], loss: 0.59803 acc: 0.94286 val_loss: 0.62354, val_acc: 0.90000\n",
            "Epoch [310/10000], loss: 0.59255 acc: 0.94286 val_loss: 0.61861, val_acc: 0.90000\n",
            "Epoch [320/10000], loss: 0.58717 acc: 0.94286 val_loss: 0.61376, val_acc: 0.93333\n",
            "Epoch [330/10000], loss: 0.58187 acc: 0.94286 val_loss: 0.60899, val_acc: 0.93333\n",
            "Epoch [340/10000], loss: 0.57667 acc: 0.97143 val_loss: 0.60429, val_acc: 0.93333\n",
            "Epoch [350/10000], loss: 0.57154 acc: 0.97143 val_loss: 0.59967, val_acc: 0.93333\n",
            "Epoch [360/10000], loss: 0.56650 acc: 0.97143 val_loss: 0.59512, val_acc: 0.93333\n",
            "Epoch [370/10000], loss: 0.56155 acc: 0.98571 val_loss: 0.59064, val_acc: 0.93333\n",
            "Epoch [380/10000], loss: 0.55667 acc: 0.98571 val_loss: 0.58623, val_acc: 0.93333\n",
            "Epoch [390/10000], loss: 0.55188 acc: 0.98571 val_loss: 0.58189, val_acc: 0.93333\n",
            "Epoch [400/10000], loss: 0.54716 acc: 0.98571 val_loss: 0.57762, val_acc: 0.93333\n",
            "Epoch [410/10000], loss: 0.54251 acc: 0.98571 val_loss: 0.57341, val_acc: 0.93333\n",
            "Epoch [420/10000], loss: 0.53795 acc: 0.98571 val_loss: 0.56927, val_acc: 0.93333\n",
            "Epoch [430/10000], loss: 0.53345 acc: 1.00000 val_loss: 0.56519, val_acc: 0.93333\n",
            "Epoch [440/10000], loss: 0.52902 acc: 1.00000 val_loss: 0.56117, val_acc: 0.93333\n",
            "Epoch [450/10000], loss: 0.52467 acc: 1.00000 val_loss: 0.55722, val_acc: 0.93333\n",
            "Epoch [460/10000], loss: 0.52038 acc: 1.00000 val_loss: 0.55333, val_acc: 0.93333\n",
            "Epoch [470/10000], loss: 0.51617 acc: 1.00000 val_loss: 0.54949, val_acc: 0.93333\n",
            "Epoch [480/10000], loss: 0.51201 acc: 1.00000 val_loss: 0.54571, val_acc: 0.93333\n",
            "Epoch [490/10000], loss: 0.50793 acc: 1.00000 val_loss: 0.54199, val_acc: 0.93333\n",
            "Epoch [500/10000], loss: 0.50390 acc: 1.00000 val_loss: 0.53833, val_acc: 0.93333\n",
            "Epoch [510/10000], loss: 0.49994 acc: 1.00000 val_loss: 0.53472, val_acc: 0.93333\n",
            "Epoch [520/10000], loss: 0.49604 acc: 1.00000 val_loss: 0.53116, val_acc: 0.93333\n",
            "Epoch [530/10000], loss: 0.49219 acc: 1.00000 val_loss: 0.52766, val_acc: 0.93333\n",
            "Epoch [540/10000], loss: 0.48841 acc: 1.00000 val_loss: 0.52421, val_acc: 0.93333\n",
            "Epoch [550/10000], loss: 0.48468 acc: 1.00000 val_loss: 0.52080, val_acc: 0.93333\n",
            "Epoch [560/10000], loss: 0.48101 acc: 1.00000 val_loss: 0.51745, val_acc: 0.93333\n",
            "Epoch [570/10000], loss: 0.47740 acc: 1.00000 val_loss: 0.51415, val_acc: 0.93333\n",
            "Epoch [580/10000], loss: 0.47384 acc: 1.00000 val_loss: 0.51089, val_acc: 0.93333\n",
            "Epoch [590/10000], loss: 0.47033 acc: 1.00000 val_loss: 0.50769, val_acc: 0.93333\n",
            "Epoch [600/10000], loss: 0.46687 acc: 1.00000 val_loss: 0.50452, val_acc: 0.93333\n",
            "Epoch [610/10000], loss: 0.46347 acc: 1.00000 val_loss: 0.50141, val_acc: 0.93333\n",
            "Epoch [620/10000], loss: 0.46011 acc: 1.00000 val_loss: 0.49833, val_acc: 0.93333\n",
            "Epoch [630/10000], loss: 0.45680 acc: 1.00000 val_loss: 0.49530, val_acc: 0.93333\n",
            "Epoch [640/10000], loss: 0.45355 acc: 1.00000 val_loss: 0.49232, val_acc: 0.93333\n",
            "Epoch [650/10000], loss: 0.45033 acc: 1.00000 val_loss: 0.48937, val_acc: 0.93333\n",
            "Epoch [660/10000], loss: 0.44717 acc: 1.00000 val_loss: 0.48647, val_acc: 0.93333\n",
            "Epoch [670/10000], loss: 0.44405 acc: 1.00000 val_loss: 0.48360, val_acc: 0.93333\n",
            "Epoch [680/10000], loss: 0.44097 acc: 1.00000 val_loss: 0.48078, val_acc: 0.93333\n",
            "Epoch [690/10000], loss: 0.43794 acc: 1.00000 val_loss: 0.47800, val_acc: 0.93333\n",
            "Epoch [700/10000], loss: 0.43495 acc: 1.00000 val_loss: 0.47525, val_acc: 0.93333\n",
            "Epoch [710/10000], loss: 0.43200 acc: 1.00000 val_loss: 0.47254, val_acc: 0.93333\n",
            "Epoch [720/10000], loss: 0.42909 acc: 1.00000 val_loss: 0.46987, val_acc: 0.93333\n",
            "Epoch [730/10000], loss: 0.42623 acc: 1.00000 val_loss: 0.46723, val_acc: 0.93333\n",
            "Epoch [740/10000], loss: 0.42340 acc: 1.00000 val_loss: 0.46463, val_acc: 0.93333\n",
            "Epoch [750/10000], loss: 0.42061 acc: 1.00000 val_loss: 0.46206, val_acc: 0.93333\n",
            "Epoch [760/10000], loss: 0.41786 acc: 1.00000 val_loss: 0.45953, val_acc: 0.93333\n",
            "Epoch [770/10000], loss: 0.41515 acc: 1.00000 val_loss: 0.45703, val_acc: 0.93333\n",
            "Epoch [780/10000], loss: 0.41247 acc: 1.00000 val_loss: 0.45457, val_acc: 0.93333\n",
            "Epoch [790/10000], loss: 0.40983 acc: 1.00000 val_loss: 0.45213, val_acc: 0.93333\n",
            "Epoch [800/10000], loss: 0.40722 acc: 1.00000 val_loss: 0.44973, val_acc: 0.93333\n",
            "Epoch [810/10000], loss: 0.40465 acc: 1.00000 val_loss: 0.44736, val_acc: 0.93333\n",
            "Epoch [820/10000], loss: 0.40211 acc: 1.00000 val_loss: 0.44502, val_acc: 0.93333\n",
            "Epoch [830/10000], loss: 0.39961 acc: 1.00000 val_loss: 0.44271, val_acc: 0.93333\n",
            "Epoch [840/10000], loss: 0.39714 acc: 1.00000 val_loss: 0.44043, val_acc: 0.93333\n",
            "Epoch [850/10000], loss: 0.39470 acc: 1.00000 val_loss: 0.43818, val_acc: 0.93333\n",
            "Epoch [860/10000], loss: 0.39229 acc: 1.00000 val_loss: 0.43596, val_acc: 0.93333\n",
            "Epoch [870/10000], loss: 0.38992 acc: 1.00000 val_loss: 0.43377, val_acc: 0.93333\n",
            "Epoch [880/10000], loss: 0.38757 acc: 1.00000 val_loss: 0.43160, val_acc: 0.93333\n",
            "Epoch [890/10000], loss: 0.38525 acc: 1.00000 val_loss: 0.42946, val_acc: 0.96667\n",
            "Epoch [900/10000], loss: 0.38297 acc: 1.00000 val_loss: 0.42735, val_acc: 0.96667\n",
            "Epoch [910/10000], loss: 0.38071 acc: 1.00000 val_loss: 0.42526, val_acc: 0.96667\n",
            "Epoch [920/10000], loss: 0.37848 acc: 1.00000 val_loss: 0.42320, val_acc: 0.96667\n",
            "Epoch [930/10000], loss: 0.37628 acc: 1.00000 val_loss: 0.42116, val_acc: 0.96667\n",
            "Epoch [940/10000], loss: 0.37410 acc: 1.00000 val_loss: 0.41915, val_acc: 0.96667\n",
            "Epoch [950/10000], loss: 0.37196 acc: 1.00000 val_loss: 0.41717, val_acc: 0.96667\n",
            "Epoch [960/10000], loss: 0.36983 acc: 1.00000 val_loss: 0.41520, val_acc: 0.96667\n",
            "Epoch [970/10000], loss: 0.36774 acc: 1.00000 val_loss: 0.41327, val_acc: 0.96667\n",
            "Epoch [980/10000], loss: 0.36567 acc: 1.00000 val_loss: 0.41135, val_acc: 0.96667\n",
            "Epoch [990/10000], loss: 0.36362 acc: 1.00000 val_loss: 0.40946, val_acc: 0.96667\n",
            "Epoch [1000/10000], loss: 0.36160 acc: 1.00000 val_loss: 0.40759, val_acc: 0.96667\n",
            "Epoch [1010/10000], loss: 0.35961 acc: 1.00000 val_loss: 0.40574, val_acc: 0.96667\n",
            "Epoch [1020/10000], loss: 0.35763 acc: 1.00000 val_loss: 0.40391, val_acc: 0.96667\n",
            "Epoch [1030/10000], loss: 0.35568 acc: 1.00000 val_loss: 0.40211, val_acc: 0.96667\n",
            "Epoch [1040/10000], loss: 0.35376 acc: 1.00000 val_loss: 0.40032, val_acc: 0.96667\n",
            "Epoch [1050/10000], loss: 0.35186 acc: 1.00000 val_loss: 0.39856, val_acc: 0.96667\n",
            "Epoch [1060/10000], loss: 0.34997 acc: 1.00000 val_loss: 0.39682, val_acc: 0.96667\n",
            "Epoch [1070/10000], loss: 0.34811 acc: 1.00000 val_loss: 0.39509, val_acc: 0.96667\n",
            "Epoch [1080/10000], loss: 0.34628 acc: 1.00000 val_loss: 0.39339, val_acc: 0.96667\n",
            "Epoch [1090/10000], loss: 0.34446 acc: 1.00000 val_loss: 0.39171, val_acc: 0.96667\n",
            "Epoch [1100/10000], loss: 0.34266 acc: 1.00000 val_loss: 0.39004, val_acc: 0.96667\n",
            "Epoch [1110/10000], loss: 0.34089 acc: 1.00000 val_loss: 0.38839, val_acc: 0.96667\n",
            "Epoch [1120/10000], loss: 0.33913 acc: 1.00000 val_loss: 0.38677, val_acc: 0.96667\n",
            "Epoch [1130/10000], loss: 0.33739 acc: 1.00000 val_loss: 0.38516, val_acc: 0.96667\n",
            "Epoch [1140/10000], loss: 0.33568 acc: 1.00000 val_loss: 0.38357, val_acc: 0.96667\n",
            "Epoch [1150/10000], loss: 0.33398 acc: 1.00000 val_loss: 0.38199, val_acc: 0.96667\n",
            "Epoch [1160/10000], loss: 0.33230 acc: 1.00000 val_loss: 0.38043, val_acc: 0.96667\n",
            "Epoch [1170/10000], loss: 0.33064 acc: 1.00000 val_loss: 0.37889, val_acc: 0.96667\n",
            "Epoch [1180/10000], loss: 0.32900 acc: 1.00000 val_loss: 0.37737, val_acc: 0.96667\n",
            "Epoch [1190/10000], loss: 0.32737 acc: 1.00000 val_loss: 0.37586, val_acc: 0.96667\n",
            "Epoch [1200/10000], loss: 0.32577 acc: 1.00000 val_loss: 0.37437, val_acc: 0.96667\n",
            "Epoch [1210/10000], loss: 0.32418 acc: 1.00000 val_loss: 0.37290, val_acc: 0.96667\n",
            "Epoch [1220/10000], loss: 0.32260 acc: 1.00000 val_loss: 0.37144, val_acc: 0.96667\n",
            "Epoch [1230/10000], loss: 0.32105 acc: 1.00000 val_loss: 0.37000, val_acc: 0.96667\n",
            "Epoch [1240/10000], loss: 0.31951 acc: 1.00000 val_loss: 0.36857, val_acc: 0.96667\n",
            "Epoch [1250/10000], loss: 0.31799 acc: 1.00000 val_loss: 0.36716, val_acc: 0.96667\n",
            "Epoch [1260/10000], loss: 0.31648 acc: 1.00000 val_loss: 0.36576, val_acc: 0.96667\n",
            "Epoch [1270/10000], loss: 0.31499 acc: 1.00000 val_loss: 0.36437, val_acc: 0.96667\n",
            "Epoch [1280/10000], loss: 0.31351 acc: 1.00000 val_loss: 0.36301, val_acc: 0.96667\n",
            "Epoch [1290/10000], loss: 0.31205 acc: 1.00000 val_loss: 0.36165, val_acc: 0.96667\n",
            "Epoch [1300/10000], loss: 0.31061 acc: 1.00000 val_loss: 0.36031, val_acc: 0.96667\n",
            "Epoch [1310/10000], loss: 0.30918 acc: 1.00000 val_loss: 0.35898, val_acc: 0.96667\n",
            "Epoch [1320/10000], loss: 0.30776 acc: 1.00000 val_loss: 0.35767, val_acc: 0.96667\n",
            "Epoch [1330/10000], loss: 0.30636 acc: 1.00000 val_loss: 0.35637, val_acc: 0.96667\n",
            "Epoch [1340/10000], loss: 0.30498 acc: 1.00000 val_loss: 0.35508, val_acc: 0.96667\n",
            "Epoch [1350/10000], loss: 0.30360 acc: 1.00000 val_loss: 0.35381, val_acc: 0.96667\n",
            "Epoch [1360/10000], loss: 0.30224 acc: 1.00000 val_loss: 0.35255, val_acc: 0.96667\n",
            "Epoch [1370/10000], loss: 0.30090 acc: 1.00000 val_loss: 0.35130, val_acc: 0.96667\n",
            "Epoch [1380/10000], loss: 0.29957 acc: 1.00000 val_loss: 0.35006, val_acc: 0.96667\n",
            "Epoch [1390/10000], loss: 0.29825 acc: 1.00000 val_loss: 0.34884, val_acc: 0.96667\n",
            "Epoch [1400/10000], loss: 0.29694 acc: 1.00000 val_loss: 0.34763, val_acc: 0.96667\n",
            "Epoch [1410/10000], loss: 0.29565 acc: 1.00000 val_loss: 0.34643, val_acc: 0.96667\n",
            "Epoch [1420/10000], loss: 0.29437 acc: 1.00000 val_loss: 0.34524, val_acc: 0.96667\n",
            "Epoch [1430/10000], loss: 0.29310 acc: 1.00000 val_loss: 0.34406, val_acc: 0.96667\n",
            "Epoch [1440/10000], loss: 0.29184 acc: 1.00000 val_loss: 0.34290, val_acc: 0.96667\n",
            "Epoch [1450/10000], loss: 0.29060 acc: 1.00000 val_loss: 0.34174, val_acc: 0.96667\n",
            "Epoch [1460/10000], loss: 0.28937 acc: 1.00000 val_loss: 0.34060, val_acc: 0.96667\n",
            "Epoch [1470/10000], loss: 0.28815 acc: 1.00000 val_loss: 0.33947, val_acc: 0.96667\n",
            "Epoch [1480/10000], loss: 0.28694 acc: 1.00000 val_loss: 0.33834, val_acc: 0.96667\n",
            "Epoch [1490/10000], loss: 0.28574 acc: 1.00000 val_loss: 0.33723, val_acc: 0.96667\n",
            "Epoch [1500/10000], loss: 0.28456 acc: 1.00000 val_loss: 0.33613, val_acc: 0.96667\n",
            "Epoch [1510/10000], loss: 0.28338 acc: 1.00000 val_loss: 0.33504, val_acc: 0.96667\n",
            "Epoch [1520/10000], loss: 0.28222 acc: 1.00000 val_loss: 0.33396, val_acc: 0.96667\n",
            "Epoch [1530/10000], loss: 0.28106 acc: 1.00000 val_loss: 0.33289, val_acc: 0.96667\n",
            "Epoch [1540/10000], loss: 0.27992 acc: 1.00000 val_loss: 0.33183, val_acc: 0.96667\n",
            "Epoch [1550/10000], loss: 0.27879 acc: 1.00000 val_loss: 0.33078, val_acc: 0.96667\n",
            "Epoch [1560/10000], loss: 0.27767 acc: 1.00000 val_loss: 0.32974, val_acc: 0.96667\n",
            "Epoch [1570/10000], loss: 0.27656 acc: 1.00000 val_loss: 0.32871, val_acc: 0.96667\n",
            "Epoch [1580/10000], loss: 0.27545 acc: 1.00000 val_loss: 0.32769, val_acc: 0.96667\n",
            "Epoch [1590/10000], loss: 0.27436 acc: 1.00000 val_loss: 0.32668, val_acc: 0.96667\n",
            "Epoch [1600/10000], loss: 0.27328 acc: 1.00000 val_loss: 0.32568, val_acc: 0.96667\n",
            "Epoch [1610/10000], loss: 0.27221 acc: 1.00000 val_loss: 0.32468, val_acc: 0.96667\n",
            "Epoch [1620/10000], loss: 0.27115 acc: 1.00000 val_loss: 0.32370, val_acc: 0.96667\n",
            "Epoch [1630/10000], loss: 0.27009 acc: 1.00000 val_loss: 0.32272, val_acc: 0.96667\n",
            "Epoch [1640/10000], loss: 0.26905 acc: 1.00000 val_loss: 0.32175, val_acc: 0.96667\n",
            "Epoch [1650/10000], loss: 0.26802 acc: 1.00000 val_loss: 0.32080, val_acc: 0.96667\n",
            "Epoch [1660/10000], loss: 0.26699 acc: 1.00000 val_loss: 0.31985, val_acc: 0.96667\n",
            "Epoch [1670/10000], loss: 0.26597 acc: 1.00000 val_loss: 0.31890, val_acc: 0.96667\n",
            "Epoch [1680/10000], loss: 0.26497 acc: 1.00000 val_loss: 0.31797, val_acc: 0.96667\n",
            "Epoch [1690/10000], loss: 0.26397 acc: 1.00000 val_loss: 0.31704, val_acc: 0.96667\n",
            "Epoch [1700/10000], loss: 0.26298 acc: 1.00000 val_loss: 0.31613, val_acc: 0.96667\n",
            "Epoch [1710/10000], loss: 0.26199 acc: 1.00000 val_loss: 0.31522, val_acc: 0.96667\n",
            "Epoch [1720/10000], loss: 0.26102 acc: 1.00000 val_loss: 0.31431, val_acc: 0.96667\n",
            "Epoch [1730/10000], loss: 0.26005 acc: 1.00000 val_loss: 0.31342, val_acc: 0.96667\n",
            "Epoch [1740/10000], loss: 0.25910 acc: 1.00000 val_loss: 0.31253, val_acc: 0.96667\n",
            "Epoch [1750/10000], loss: 0.25815 acc: 1.00000 val_loss: 0.31165, val_acc: 0.96667\n",
            "Epoch [1760/10000], loss: 0.25721 acc: 1.00000 val_loss: 0.31078, val_acc: 0.96667\n",
            "Epoch [1770/10000], loss: 0.25627 acc: 1.00000 val_loss: 0.30992, val_acc: 0.96667\n",
            "Epoch [1780/10000], loss: 0.25535 acc: 1.00000 val_loss: 0.30906, val_acc: 0.96667\n",
            "Epoch [1790/10000], loss: 0.25443 acc: 1.00000 val_loss: 0.30821, val_acc: 0.96667\n",
            "Epoch [1800/10000], loss: 0.25352 acc: 1.00000 val_loss: 0.30737, val_acc: 0.96667\n",
            "Epoch [1810/10000], loss: 0.25262 acc: 1.00000 val_loss: 0.30653, val_acc: 0.96667\n",
            "Epoch [1820/10000], loss: 0.25172 acc: 1.00000 val_loss: 0.30571, val_acc: 0.96667\n",
            "Epoch [1830/10000], loss: 0.25083 acc: 1.00000 val_loss: 0.30488, val_acc: 0.96667\n",
            "Epoch [1840/10000], loss: 0.24995 acc: 1.00000 val_loss: 0.30407, val_acc: 0.96667\n",
            "Epoch [1850/10000], loss: 0.24908 acc: 1.00000 val_loss: 0.30326, val_acc: 0.96667\n",
            "Epoch [1860/10000], loss: 0.24821 acc: 1.00000 val_loss: 0.30246, val_acc: 0.96667\n",
            "Epoch [1870/10000], loss: 0.24735 acc: 1.00000 val_loss: 0.30166, val_acc: 0.96667\n",
            "Epoch [1880/10000], loss: 0.24650 acc: 1.00000 val_loss: 0.30087, val_acc: 0.96667\n",
            "Epoch [1890/10000], loss: 0.24565 acc: 1.00000 val_loss: 0.30009, val_acc: 0.96667\n",
            "Epoch [1900/10000], loss: 0.24481 acc: 1.00000 val_loss: 0.29932, val_acc: 0.96667\n",
            "Epoch [1910/10000], loss: 0.24398 acc: 1.00000 val_loss: 0.29855, val_acc: 0.96667\n",
            "Epoch [1920/10000], loss: 0.24315 acc: 1.00000 val_loss: 0.29778, val_acc: 0.96667\n",
            "Epoch [1930/10000], loss: 0.24233 acc: 1.00000 val_loss: 0.29702, val_acc: 0.96667\n",
            "Epoch [1940/10000], loss: 0.24152 acc: 1.00000 val_loss: 0.29627, val_acc: 0.96667\n",
            "Epoch [1950/10000], loss: 0.24071 acc: 1.00000 val_loss: 0.29553, val_acc: 0.96667\n",
            "Epoch [1960/10000], loss: 0.23991 acc: 1.00000 val_loss: 0.29479, val_acc: 0.96667\n",
            "Epoch [1970/10000], loss: 0.23911 acc: 1.00000 val_loss: 0.29405, val_acc: 0.96667\n",
            "Epoch [1980/10000], loss: 0.23833 acc: 1.00000 val_loss: 0.29332, val_acc: 0.96667\n",
            "Epoch [1990/10000], loss: 0.23754 acc: 1.00000 val_loss: 0.29260, val_acc: 0.96667\n",
            "Epoch [2000/10000], loss: 0.23677 acc: 1.00000 val_loss: 0.29188, val_acc: 0.96667\n",
            "Epoch [2010/10000], loss: 0.23599 acc: 1.00000 val_loss: 0.29117, val_acc: 0.96667\n",
            "Epoch [2020/10000], loss: 0.23523 acc: 1.00000 val_loss: 0.29047, val_acc: 0.96667\n",
            "Epoch [2030/10000], loss: 0.23447 acc: 1.00000 val_loss: 0.28977, val_acc: 0.96667\n",
            "Epoch [2040/10000], loss: 0.23372 acc: 1.00000 val_loss: 0.28907, val_acc: 0.96667\n",
            "Epoch [2050/10000], loss: 0.23297 acc: 1.00000 val_loss: 0.28838, val_acc: 0.96667\n",
            "Epoch [2060/10000], loss: 0.23223 acc: 1.00000 val_loss: 0.28770, val_acc: 0.96667\n",
            "Epoch [2070/10000], loss: 0.23149 acc: 1.00000 val_loss: 0.28702, val_acc: 0.96667\n",
            "Epoch [2080/10000], loss: 0.23076 acc: 1.00000 val_loss: 0.28634, val_acc: 0.96667\n",
            "Epoch [2090/10000], loss: 0.23003 acc: 1.00000 val_loss: 0.28567, val_acc: 0.96667\n",
            "Epoch [2100/10000], loss: 0.22931 acc: 1.00000 val_loss: 0.28501, val_acc: 0.96667\n",
            "Epoch [2110/10000], loss: 0.22859 acc: 1.00000 val_loss: 0.28435, val_acc: 0.96667\n",
            "Epoch [2120/10000], loss: 0.22788 acc: 1.00000 val_loss: 0.28369, val_acc: 0.96667\n",
            "Epoch [2130/10000], loss: 0.22718 acc: 1.00000 val_loss: 0.28304, val_acc: 0.96667\n",
            "Epoch [2140/10000], loss: 0.22648 acc: 1.00000 val_loss: 0.28240, val_acc: 0.96667\n",
            "Epoch [2150/10000], loss: 0.22578 acc: 1.00000 val_loss: 0.28176, val_acc: 0.96667\n",
            "Epoch [2160/10000], loss: 0.22509 acc: 1.00000 val_loss: 0.28112, val_acc: 0.96667\n",
            "Epoch [2170/10000], loss: 0.22441 acc: 1.00000 val_loss: 0.28049, val_acc: 0.96667\n",
            "Epoch [2180/10000], loss: 0.22373 acc: 1.00000 val_loss: 0.27986, val_acc: 0.96667\n",
            "Epoch [2190/10000], loss: 0.22305 acc: 1.00000 val_loss: 0.27924, val_acc: 0.96667\n",
            "Epoch [2200/10000], loss: 0.22238 acc: 1.00000 val_loss: 0.27862, val_acc: 0.96667\n",
            "Epoch [2210/10000], loss: 0.22171 acc: 1.00000 val_loss: 0.27801, val_acc: 0.96667\n",
            "Epoch [2220/10000], loss: 0.22105 acc: 1.00000 val_loss: 0.27740, val_acc: 0.96667\n",
            "Epoch [2230/10000], loss: 0.22039 acc: 1.00000 val_loss: 0.27680, val_acc: 0.96667\n",
            "Epoch [2240/10000], loss: 0.21974 acc: 1.00000 val_loss: 0.27620, val_acc: 0.96667\n",
            "Epoch [2250/10000], loss: 0.21909 acc: 1.00000 val_loss: 0.27560, val_acc: 0.96667\n",
            "Epoch [2260/10000], loss: 0.21845 acc: 1.00000 val_loss: 0.27501, val_acc: 0.96667\n",
            "Epoch [2270/10000], loss: 0.21781 acc: 1.00000 val_loss: 0.27442, val_acc: 0.96667\n",
            "Epoch [2280/10000], loss: 0.21718 acc: 1.00000 val_loss: 0.27384, val_acc: 0.96667\n",
            "Epoch [2290/10000], loss: 0.21655 acc: 1.00000 val_loss: 0.27326, val_acc: 0.96667\n",
            "Epoch [2300/10000], loss: 0.21592 acc: 1.00000 val_loss: 0.27269, val_acc: 0.96667\n",
            "Epoch [2310/10000], loss: 0.21530 acc: 1.00000 val_loss: 0.27211, val_acc: 0.96667\n",
            "Epoch [2320/10000], loss: 0.21468 acc: 1.00000 val_loss: 0.27155, val_acc: 0.96667\n",
            "Epoch [2330/10000], loss: 0.21407 acc: 1.00000 val_loss: 0.27098, val_acc: 0.96667\n",
            "Epoch [2340/10000], loss: 0.21346 acc: 1.00000 val_loss: 0.27042, val_acc: 0.96667\n",
            "Epoch [2350/10000], loss: 0.21285 acc: 1.00000 val_loss: 0.26987, val_acc: 0.96667\n",
            "Epoch [2360/10000], loss: 0.21225 acc: 1.00000 val_loss: 0.26932, val_acc: 0.96667\n",
            "Epoch [2370/10000], loss: 0.21165 acc: 1.00000 val_loss: 0.26877, val_acc: 0.96667\n",
            "Epoch [2380/10000], loss: 0.21106 acc: 1.00000 val_loss: 0.26822, val_acc: 0.96667\n",
            "Epoch [2390/10000], loss: 0.21047 acc: 1.00000 val_loss: 0.26768, val_acc: 0.96667\n",
            "Epoch [2400/10000], loss: 0.20988 acc: 1.00000 val_loss: 0.26715, val_acc: 0.96667\n",
            "Epoch [2410/10000], loss: 0.20930 acc: 1.00000 val_loss: 0.26661, val_acc: 0.96667\n",
            "Epoch [2420/10000], loss: 0.20872 acc: 1.00000 val_loss: 0.26608, val_acc: 0.96667\n",
            "Epoch [2430/10000], loss: 0.20815 acc: 1.00000 val_loss: 0.26556, val_acc: 0.96667\n",
            "Epoch [2440/10000], loss: 0.20758 acc: 1.00000 val_loss: 0.26503, val_acc: 0.96667\n",
            "Epoch [2450/10000], loss: 0.20701 acc: 1.00000 val_loss: 0.26451, val_acc: 0.96667\n",
            "Epoch [2460/10000], loss: 0.20645 acc: 1.00000 val_loss: 0.26400, val_acc: 0.96667\n",
            "Epoch [2470/10000], loss: 0.20589 acc: 1.00000 val_loss: 0.26349, val_acc: 0.96667\n",
            "Epoch [2480/10000], loss: 0.20533 acc: 1.00000 val_loss: 0.26298, val_acc: 0.96667\n",
            "Epoch [2490/10000], loss: 0.20478 acc: 1.00000 val_loss: 0.26247, val_acc: 0.96667\n",
            "Epoch [2500/10000], loss: 0.20423 acc: 1.00000 val_loss: 0.26197, val_acc: 0.96667\n",
            "Epoch [2510/10000], loss: 0.20369 acc: 1.00000 val_loss: 0.26147, val_acc: 0.96667\n",
            "Epoch [2520/10000], loss: 0.20314 acc: 1.00000 val_loss: 0.26097, val_acc: 0.96667\n",
            "Epoch [2530/10000], loss: 0.20261 acc: 1.00000 val_loss: 0.26048, val_acc: 0.96667\n",
            "Epoch [2540/10000], loss: 0.20207 acc: 1.00000 val_loss: 0.25999, val_acc: 0.96667\n",
            "Epoch [2550/10000], loss: 0.20154 acc: 1.00000 val_loss: 0.25950, val_acc: 0.96667\n",
            "Epoch [2560/10000], loss: 0.20101 acc: 1.00000 val_loss: 0.25902, val_acc: 0.96667\n",
            "Epoch [2570/10000], loss: 0.20048 acc: 1.00000 val_loss: 0.25854, val_acc: 0.96667\n",
            "Epoch [2580/10000], loss: 0.19996 acc: 1.00000 val_loss: 0.25806, val_acc: 0.96667\n",
            "Epoch [2590/10000], loss: 0.19944 acc: 1.00000 val_loss: 0.25759, val_acc: 0.96667\n",
            "Epoch [2600/10000], loss: 0.19893 acc: 1.00000 val_loss: 0.25712, val_acc: 0.96667\n",
            "Epoch [2610/10000], loss: 0.19841 acc: 1.00000 val_loss: 0.25665, val_acc: 0.96667\n",
            "Epoch [2620/10000], loss: 0.19791 acc: 1.00000 val_loss: 0.25618, val_acc: 0.96667\n",
            "Epoch [2630/10000], loss: 0.19740 acc: 1.00000 val_loss: 0.25572, val_acc: 0.96667\n",
            "Epoch [2640/10000], loss: 0.19690 acc: 1.00000 val_loss: 0.25526, val_acc: 0.96667\n",
            "Epoch [2650/10000], loss: 0.19640 acc: 1.00000 val_loss: 0.25481, val_acc: 0.96667\n",
            "Epoch [2660/10000], loss: 0.19590 acc: 1.00000 val_loss: 0.25435, val_acc: 0.96667\n",
            "Epoch [2670/10000], loss: 0.19540 acc: 1.00000 val_loss: 0.25390, val_acc: 0.96667\n",
            "Epoch [2680/10000], loss: 0.19491 acc: 1.00000 val_loss: 0.25345, val_acc: 0.96667\n",
            "Epoch [2690/10000], loss: 0.19442 acc: 1.00000 val_loss: 0.25301, val_acc: 0.96667\n",
            "Epoch [2700/10000], loss: 0.19394 acc: 1.00000 val_loss: 0.25257, val_acc: 0.96667\n",
            "Epoch [2710/10000], loss: 0.19346 acc: 1.00000 val_loss: 0.25213, val_acc: 0.96667\n",
            "Epoch [2720/10000], loss: 0.19298 acc: 1.00000 val_loss: 0.25169, val_acc: 0.96667\n",
            "Epoch [2730/10000], loss: 0.19250 acc: 1.00000 val_loss: 0.25125, val_acc: 0.96667\n",
            "Epoch [2740/10000], loss: 0.19202 acc: 1.00000 val_loss: 0.25082, val_acc: 0.96667\n",
            "Epoch [2750/10000], loss: 0.19155 acc: 1.00000 val_loss: 0.25039, val_acc: 0.96667\n",
            "Epoch [2760/10000], loss: 0.19108 acc: 1.00000 val_loss: 0.24997, val_acc: 0.96667\n",
            "Epoch [2770/10000], loss: 0.19062 acc: 1.00000 val_loss: 0.24954, val_acc: 0.96667\n",
            "Epoch [2780/10000], loss: 0.19016 acc: 1.00000 val_loss: 0.24912, val_acc: 0.96667\n",
            "Epoch [2790/10000], loss: 0.18970 acc: 1.00000 val_loss: 0.24870, val_acc: 0.96667\n",
            "Epoch [2800/10000], loss: 0.18924 acc: 1.00000 val_loss: 0.24828, val_acc: 0.96667\n",
            "Epoch [2810/10000], loss: 0.18878 acc: 1.00000 val_loss: 0.24787, val_acc: 0.96667\n",
            "Epoch [2820/10000], loss: 0.18833 acc: 1.00000 val_loss: 0.24746, val_acc: 0.96667\n",
            "Epoch [2830/10000], loss: 0.18788 acc: 1.00000 val_loss: 0.24705, val_acc: 0.96667\n",
            "Epoch [2840/10000], loss: 0.18743 acc: 1.00000 val_loss: 0.24664, val_acc: 0.96667\n",
            "Epoch [2850/10000], loss: 0.18699 acc: 1.00000 val_loss: 0.24624, val_acc: 0.96667\n",
            "Epoch [2860/10000], loss: 0.18654 acc: 1.00000 val_loss: 0.24584, val_acc: 0.96667\n",
            "Epoch [2870/10000], loss: 0.18610 acc: 1.00000 val_loss: 0.24544, val_acc: 0.96667\n",
            "Epoch [2880/10000], loss: 0.18567 acc: 1.00000 val_loss: 0.24504, val_acc: 0.96667\n",
            "Epoch [2890/10000], loss: 0.18523 acc: 1.00000 val_loss: 0.24464, val_acc: 0.96667\n",
            "Epoch [2900/10000], loss: 0.18480 acc: 1.00000 val_loss: 0.24425, val_acc: 0.96667\n",
            "Epoch [2910/10000], loss: 0.18437 acc: 1.00000 val_loss: 0.24386, val_acc: 0.96667\n",
            "Epoch [2920/10000], loss: 0.18394 acc: 1.00000 val_loss: 0.24347, val_acc: 0.96667\n",
            "Epoch [2930/10000], loss: 0.18352 acc: 1.00000 val_loss: 0.24309, val_acc: 0.96667\n",
            "Epoch [2940/10000], loss: 0.18309 acc: 1.00000 val_loss: 0.24270, val_acc: 0.96667\n",
            "Epoch [2950/10000], loss: 0.18267 acc: 1.00000 val_loss: 0.24232, val_acc: 0.96667\n",
            "Epoch [2960/10000], loss: 0.18225 acc: 1.00000 val_loss: 0.24194, val_acc: 0.96667\n",
            "Epoch [2970/10000], loss: 0.18184 acc: 1.00000 val_loss: 0.24156, val_acc: 0.96667\n",
            "Epoch [2980/10000], loss: 0.18142 acc: 1.00000 val_loss: 0.24119, val_acc: 0.96667\n",
            "Epoch [2990/10000], loss: 0.18101 acc: 1.00000 val_loss: 0.24081, val_acc: 0.96667\n",
            "Epoch [3000/10000], loss: 0.18060 acc: 1.00000 val_loss: 0.24044, val_acc: 0.96667\n",
            "Epoch [3010/10000], loss: 0.18019 acc: 1.00000 val_loss: 0.24008, val_acc: 0.96667\n",
            "Epoch [3020/10000], loss: 0.17979 acc: 1.00000 val_loss: 0.23971, val_acc: 0.96667\n",
            "Epoch [3030/10000], loss: 0.17939 acc: 1.00000 val_loss: 0.23934, val_acc: 0.96667\n",
            "Epoch [3040/10000], loss: 0.17899 acc: 1.00000 val_loss: 0.23898, val_acc: 0.96667\n",
            "Epoch [3050/10000], loss: 0.17859 acc: 1.00000 val_loss: 0.23862, val_acc: 0.96667\n",
            "Epoch [3060/10000], loss: 0.17819 acc: 1.00000 val_loss: 0.23826, val_acc: 0.96667\n",
            "Epoch [3070/10000], loss: 0.17780 acc: 1.00000 val_loss: 0.23790, val_acc: 0.96667\n",
            "Epoch [3080/10000], loss: 0.17740 acc: 1.00000 val_loss: 0.23755, val_acc: 0.96667\n",
            "Epoch [3090/10000], loss: 0.17701 acc: 1.00000 val_loss: 0.23720, val_acc: 0.96667\n",
            "Epoch [3100/10000], loss: 0.17662 acc: 1.00000 val_loss: 0.23685, val_acc: 0.96667\n",
            "Epoch [3110/10000], loss: 0.17624 acc: 1.00000 val_loss: 0.23650, val_acc: 0.96667\n",
            "Epoch [3120/10000], loss: 0.17585 acc: 1.00000 val_loss: 0.23615, val_acc: 0.96667\n",
            "Epoch [3130/10000], loss: 0.17547 acc: 1.00000 val_loss: 0.23580, val_acc: 0.96667\n",
            "Epoch [3140/10000], loss: 0.17509 acc: 1.00000 val_loss: 0.23546, val_acc: 0.96667\n",
            "Epoch [3150/10000], loss: 0.17471 acc: 1.00000 val_loss: 0.23512, val_acc: 0.96667\n",
            "Epoch [3160/10000], loss: 0.17434 acc: 1.00000 val_loss: 0.23478, val_acc: 0.96667\n",
            "Epoch [3170/10000], loss: 0.17396 acc: 1.00000 val_loss: 0.23444, val_acc: 0.96667\n",
            "Epoch [3180/10000], loss: 0.17359 acc: 1.00000 val_loss: 0.23411, val_acc: 0.96667\n",
            "Epoch [3190/10000], loss: 0.17322 acc: 1.00000 val_loss: 0.23377, val_acc: 0.96667\n",
            "Epoch [3200/10000], loss: 0.17285 acc: 1.00000 val_loss: 0.23344, val_acc: 0.96667\n",
            "Epoch [3210/10000], loss: 0.17249 acc: 1.00000 val_loss: 0.23311, val_acc: 0.96667\n",
            "Epoch [3220/10000], loss: 0.17212 acc: 1.00000 val_loss: 0.23278, val_acc: 0.96667\n",
            "Epoch [3230/10000], loss: 0.17176 acc: 1.00000 val_loss: 0.23245, val_acc: 0.96667\n",
            "Epoch [3240/10000], loss: 0.17140 acc: 1.00000 val_loss: 0.23213, val_acc: 0.96667\n",
            "Epoch [3250/10000], loss: 0.17104 acc: 1.00000 val_loss: 0.23180, val_acc: 0.96667\n",
            "Epoch [3260/10000], loss: 0.17068 acc: 1.00000 val_loss: 0.23148, val_acc: 0.96667\n",
            "Epoch [3270/10000], loss: 0.17032 acc: 1.00000 val_loss: 0.23116, val_acc: 0.96667\n",
            "Epoch [3280/10000], loss: 0.16997 acc: 1.00000 val_loss: 0.23084, val_acc: 0.96667\n",
            "Epoch [3290/10000], loss: 0.16962 acc: 1.00000 val_loss: 0.23053, val_acc: 0.96667\n",
            "Epoch [3300/10000], loss: 0.16927 acc: 1.00000 val_loss: 0.23021, val_acc: 0.96667\n",
            "Epoch [3310/10000], loss: 0.16892 acc: 1.00000 val_loss: 0.22990, val_acc: 0.96667\n",
            "Epoch [3320/10000], loss: 0.16857 acc: 1.00000 val_loss: 0.22959, val_acc: 0.96667\n",
            "Epoch [3330/10000], loss: 0.16823 acc: 1.00000 val_loss: 0.22927, val_acc: 0.96667\n",
            "Epoch [3340/10000], loss: 0.16788 acc: 1.00000 val_loss: 0.22897, val_acc: 0.96667\n",
            "Epoch [3350/10000], loss: 0.16754 acc: 1.00000 val_loss: 0.22866, val_acc: 0.96667\n",
            "Epoch [3360/10000], loss: 0.16720 acc: 1.00000 val_loss: 0.22835, val_acc: 0.96667\n",
            "Epoch [3370/10000], loss: 0.16686 acc: 1.00000 val_loss: 0.22805, val_acc: 0.96667\n",
            "Epoch [3380/10000], loss: 0.16653 acc: 1.00000 val_loss: 0.22775, val_acc: 0.96667\n",
            "Epoch [3390/10000], loss: 0.16619 acc: 1.00000 val_loss: 0.22745, val_acc: 0.96667\n",
            "Epoch [3400/10000], loss: 0.16586 acc: 1.00000 val_loss: 0.22715, val_acc: 0.96667\n",
            "Epoch [3410/10000], loss: 0.16553 acc: 1.00000 val_loss: 0.22685, val_acc: 0.96667\n",
            "Epoch [3420/10000], loss: 0.16520 acc: 1.00000 val_loss: 0.22655, val_acc: 0.96667\n",
            "Epoch [3430/10000], loss: 0.16487 acc: 1.00000 val_loss: 0.22626, val_acc: 0.96667\n",
            "Epoch [3440/10000], loss: 0.16454 acc: 1.00000 val_loss: 0.22596, val_acc: 0.96667\n",
            "Epoch [3450/10000], loss: 0.16421 acc: 1.00000 val_loss: 0.22567, val_acc: 0.96667\n",
            "Epoch [3460/10000], loss: 0.16389 acc: 1.00000 val_loss: 0.22538, val_acc: 0.96667\n",
            "Epoch [3470/10000], loss: 0.16357 acc: 1.00000 val_loss: 0.22509, val_acc: 0.96667\n",
            "Epoch [3480/10000], loss: 0.16325 acc: 1.00000 val_loss: 0.22480, val_acc: 0.96667\n",
            "Epoch [3490/10000], loss: 0.16293 acc: 1.00000 val_loss: 0.22452, val_acc: 0.96667\n",
            "Epoch [3500/10000], loss: 0.16261 acc: 1.00000 val_loss: 0.22423, val_acc: 0.96667\n",
            "Epoch [3510/10000], loss: 0.16229 acc: 1.00000 val_loss: 0.22395, val_acc: 0.96667\n",
            "Epoch [3520/10000], loss: 0.16198 acc: 1.00000 val_loss: 0.22367, val_acc: 0.96667\n",
            "Epoch [3530/10000], loss: 0.16166 acc: 1.00000 val_loss: 0.22339, val_acc: 0.96667\n",
            "Epoch [3540/10000], loss: 0.16135 acc: 1.00000 val_loss: 0.22311, val_acc: 0.96667\n",
            "Epoch [3550/10000], loss: 0.16104 acc: 1.00000 val_loss: 0.22283, val_acc: 0.96667\n",
            "Epoch [3560/10000], loss: 0.16073 acc: 1.00000 val_loss: 0.22255, val_acc: 0.96667\n",
            "Epoch [3570/10000], loss: 0.16043 acc: 1.00000 val_loss: 0.22228, val_acc: 0.96667\n",
            "Epoch [3580/10000], loss: 0.16012 acc: 1.00000 val_loss: 0.22200, val_acc: 0.96667\n",
            "Epoch [3590/10000], loss: 0.15981 acc: 1.00000 val_loss: 0.22173, val_acc: 0.96667\n",
            "Epoch [3600/10000], loss: 0.15951 acc: 1.00000 val_loss: 0.22146, val_acc: 0.96667\n",
            "Epoch [3610/10000], loss: 0.15921 acc: 1.00000 val_loss: 0.22119, val_acc: 0.96667\n",
            "Epoch [3620/10000], loss: 0.15891 acc: 1.00000 val_loss: 0.22092, val_acc: 0.96667\n",
            "Epoch [3630/10000], loss: 0.15861 acc: 1.00000 val_loss: 0.22065, val_acc: 0.96667\n",
            "Epoch [3640/10000], loss: 0.15831 acc: 1.00000 val_loss: 0.22039, val_acc: 0.96667\n",
            "Epoch [3650/10000], loss: 0.15801 acc: 1.00000 val_loss: 0.22012, val_acc: 0.96667\n",
            "Epoch [3660/10000], loss: 0.15772 acc: 1.00000 val_loss: 0.21986, val_acc: 0.96667\n",
            "Epoch [3670/10000], loss: 0.15743 acc: 1.00000 val_loss: 0.21960, val_acc: 0.96667\n",
            "Epoch [3680/10000], loss: 0.15713 acc: 1.00000 val_loss: 0.21934, val_acc: 0.96667\n",
            "Epoch [3690/10000], loss: 0.15684 acc: 1.00000 val_loss: 0.21908, val_acc: 0.96667\n",
            "Epoch [3700/10000], loss: 0.15655 acc: 1.00000 val_loss: 0.21882, val_acc: 0.96667\n",
            "Epoch [3710/10000], loss: 0.15626 acc: 1.00000 val_loss: 0.21856, val_acc: 0.96667\n",
            "Epoch [3720/10000], loss: 0.15598 acc: 1.00000 val_loss: 0.21830, val_acc: 0.96667\n",
            "Epoch [3730/10000], loss: 0.15569 acc: 1.00000 val_loss: 0.21805, val_acc: 0.96667\n",
            "Epoch [3740/10000], loss: 0.15540 acc: 1.00000 val_loss: 0.21780, val_acc: 0.96667\n",
            "Epoch [3750/10000], loss: 0.15512 acc: 1.00000 val_loss: 0.21754, val_acc: 0.96667\n",
            "Epoch [3760/10000], loss: 0.15484 acc: 1.00000 val_loss: 0.21729, val_acc: 0.96667\n",
            "Epoch [3770/10000], loss: 0.15456 acc: 1.00000 val_loss: 0.21704, val_acc: 0.96667\n",
            "Epoch [3780/10000], loss: 0.15428 acc: 1.00000 val_loss: 0.21679, val_acc: 0.96667\n",
            "Epoch [3790/10000], loss: 0.15400 acc: 1.00000 val_loss: 0.21655, val_acc: 0.96667\n",
            "Epoch [3800/10000], loss: 0.15372 acc: 1.00000 val_loss: 0.21630, val_acc: 0.96667\n",
            "Epoch [3810/10000], loss: 0.15345 acc: 1.00000 val_loss: 0.21605, val_acc: 0.96667\n",
            "Epoch [3820/10000], loss: 0.15317 acc: 1.00000 val_loss: 0.21581, val_acc: 0.96667\n",
            "Epoch [3830/10000], loss: 0.15290 acc: 1.00000 val_loss: 0.21557, val_acc: 0.96667\n",
            "Epoch [3840/10000], loss: 0.15262 acc: 1.00000 val_loss: 0.21532, val_acc: 0.96667\n",
            "Epoch [3850/10000], loss: 0.15235 acc: 1.00000 val_loss: 0.21508, val_acc: 0.96667\n",
            "Epoch [3860/10000], loss: 0.15208 acc: 1.00000 val_loss: 0.21484, val_acc: 0.96667\n",
            "Epoch [3870/10000], loss: 0.15181 acc: 1.00000 val_loss: 0.21460, val_acc: 0.96667\n",
            "Epoch [3880/10000], loss: 0.15155 acc: 1.00000 val_loss: 0.21436, val_acc: 0.96667\n",
            "Epoch [3890/10000], loss: 0.15128 acc: 1.00000 val_loss: 0.21413, val_acc: 0.96667\n",
            "Epoch [3900/10000], loss: 0.15101 acc: 1.00000 val_loss: 0.21389, val_acc: 0.96667\n",
            "Epoch [3910/10000], loss: 0.15075 acc: 1.00000 val_loss: 0.21366, val_acc: 0.96667\n",
            "Epoch [3920/10000], loss: 0.15049 acc: 1.00000 val_loss: 0.21342, val_acc: 0.96667\n",
            "Epoch [3930/10000], loss: 0.15022 acc: 1.00000 val_loss: 0.21319, val_acc: 0.96667\n",
            "Epoch [3940/10000], loss: 0.14996 acc: 1.00000 val_loss: 0.21296, val_acc: 0.96667\n",
            "Epoch [3950/10000], loss: 0.14970 acc: 1.00000 val_loss: 0.21273, val_acc: 0.96667\n",
            "Epoch [3960/10000], loss: 0.14944 acc: 1.00000 val_loss: 0.21250, val_acc: 0.96667\n",
            "Epoch [3970/10000], loss: 0.14919 acc: 1.00000 val_loss: 0.21227, val_acc: 0.96667\n",
            "Epoch [3980/10000], loss: 0.14893 acc: 1.00000 val_loss: 0.21204, val_acc: 0.96667\n",
            "Epoch [3990/10000], loss: 0.14867 acc: 1.00000 val_loss: 0.21182, val_acc: 0.96667\n",
            "Epoch [4000/10000], loss: 0.14842 acc: 1.00000 val_loss: 0.21159, val_acc: 0.96667\n",
            "Epoch [4010/10000], loss: 0.14816 acc: 1.00000 val_loss: 0.21137, val_acc: 0.96667\n",
            "Epoch [4020/10000], loss: 0.14791 acc: 1.00000 val_loss: 0.21114, val_acc: 0.96667\n",
            "Epoch [4030/10000], loss: 0.14766 acc: 1.00000 val_loss: 0.21092, val_acc: 0.96667\n",
            "Epoch [4040/10000], loss: 0.14741 acc: 1.00000 val_loss: 0.21070, val_acc: 0.96667\n",
            "Epoch [4050/10000], loss: 0.14716 acc: 1.00000 val_loss: 0.21048, val_acc: 0.96667\n",
            "Epoch [4060/10000], loss: 0.14691 acc: 1.00000 val_loss: 0.21026, val_acc: 0.96667\n",
            "Epoch [4070/10000], loss: 0.14667 acc: 1.00000 val_loss: 0.21004, val_acc: 0.96667\n",
            "Epoch [4080/10000], loss: 0.14642 acc: 1.00000 val_loss: 0.20982, val_acc: 0.96667\n",
            "Epoch [4090/10000], loss: 0.14617 acc: 1.00000 val_loss: 0.20961, val_acc: 0.96667\n",
            "Epoch [4100/10000], loss: 0.14593 acc: 1.00000 val_loss: 0.20939, val_acc: 0.96667\n",
            "Epoch [4110/10000], loss: 0.14569 acc: 1.00000 val_loss: 0.20918, val_acc: 0.96667\n",
            "Epoch [4120/10000], loss: 0.14544 acc: 1.00000 val_loss: 0.20896, val_acc: 0.96667\n",
            "Epoch [4130/10000], loss: 0.14520 acc: 1.00000 val_loss: 0.20875, val_acc: 0.96667\n",
            "Epoch [4140/10000], loss: 0.14496 acc: 1.00000 val_loss: 0.20854, val_acc: 0.96667\n",
            "Epoch [4150/10000], loss: 0.14472 acc: 1.00000 val_loss: 0.20833, val_acc: 0.96667\n",
            "Epoch [4160/10000], loss: 0.14448 acc: 1.00000 val_loss: 0.20812, val_acc: 0.96667\n",
            "Epoch [4170/10000], loss: 0.14425 acc: 1.00000 val_loss: 0.20791, val_acc: 0.96667\n",
            "Epoch [4180/10000], loss: 0.14401 acc: 1.00000 val_loss: 0.20770, val_acc: 0.96667\n",
            "Epoch [4190/10000], loss: 0.14377 acc: 1.00000 val_loss: 0.20749, val_acc: 0.96667\n",
            "Epoch [4200/10000], loss: 0.14354 acc: 1.00000 val_loss: 0.20728, val_acc: 0.96667\n",
            "Epoch [4210/10000], loss: 0.14331 acc: 1.00000 val_loss: 0.20708, val_acc: 0.96667\n",
            "Epoch [4220/10000], loss: 0.14307 acc: 1.00000 val_loss: 0.20687, val_acc: 0.96667\n",
            "Epoch [4230/10000], loss: 0.14284 acc: 1.00000 val_loss: 0.20667, val_acc: 0.96667\n",
            "Epoch [4240/10000], loss: 0.14261 acc: 1.00000 val_loss: 0.20647, val_acc: 0.96667\n",
            "Epoch [4250/10000], loss: 0.14238 acc: 1.00000 val_loss: 0.20626, val_acc: 0.96667\n",
            "Epoch [4260/10000], loss: 0.14215 acc: 1.00000 val_loss: 0.20606, val_acc: 0.96667\n",
            "Epoch [4270/10000], loss: 0.14192 acc: 1.00000 val_loss: 0.20586, val_acc: 0.96667\n",
            "Epoch [4280/10000], loss: 0.14170 acc: 1.00000 val_loss: 0.20566, val_acc: 0.96667\n",
            "Epoch [4290/10000], loss: 0.14147 acc: 1.00000 val_loss: 0.20546, val_acc: 0.96667\n",
            "Epoch [4300/10000], loss: 0.14124 acc: 1.00000 val_loss: 0.20526, val_acc: 0.96667\n",
            "Epoch [4310/10000], loss: 0.14102 acc: 1.00000 val_loss: 0.20507, val_acc: 0.96667\n",
            "Epoch [4320/10000], loss: 0.14080 acc: 1.00000 val_loss: 0.20487, val_acc: 0.96667\n",
            "Epoch [4330/10000], loss: 0.14057 acc: 1.00000 val_loss: 0.20467, val_acc: 0.96667\n",
            "Epoch [4340/10000], loss: 0.14035 acc: 1.00000 val_loss: 0.20448, val_acc: 0.96667\n",
            "Epoch [4350/10000], loss: 0.14013 acc: 1.00000 val_loss: 0.20429, val_acc: 0.96667\n",
            "Epoch [4360/10000], loss: 0.13991 acc: 1.00000 val_loss: 0.20409, val_acc: 0.96667\n",
            "Epoch [4370/10000], loss: 0.13969 acc: 1.00000 val_loss: 0.20390, val_acc: 0.96667\n",
            "Epoch [4380/10000], loss: 0.13947 acc: 1.00000 val_loss: 0.20371, val_acc: 0.96667\n",
            "Epoch [4390/10000], loss: 0.13925 acc: 1.00000 val_loss: 0.20352, val_acc: 0.96667\n",
            "Epoch [4400/10000], loss: 0.13904 acc: 1.00000 val_loss: 0.20333, val_acc: 0.96667\n",
            "Epoch [4410/10000], loss: 0.13882 acc: 1.00000 val_loss: 0.20314, val_acc: 0.96667\n",
            "Epoch [4420/10000], loss: 0.13860 acc: 1.00000 val_loss: 0.20295, val_acc: 0.96667\n",
            "Epoch [4430/10000], loss: 0.13839 acc: 1.00000 val_loss: 0.20276, val_acc: 0.96667\n",
            "Epoch [4440/10000], loss: 0.13818 acc: 1.00000 val_loss: 0.20257, val_acc: 0.96667\n",
            "Epoch [4450/10000], loss: 0.13796 acc: 1.00000 val_loss: 0.20239, val_acc: 0.96667\n",
            "Epoch [4460/10000], loss: 0.13775 acc: 1.00000 val_loss: 0.20220, val_acc: 0.96667\n",
            "Epoch [4470/10000], loss: 0.13754 acc: 1.00000 val_loss: 0.20202, val_acc: 0.96667\n",
            "Epoch [4480/10000], loss: 0.13733 acc: 1.00000 val_loss: 0.20183, val_acc: 0.96667\n",
            "Epoch [4490/10000], loss: 0.13712 acc: 1.00000 val_loss: 0.20165, val_acc: 0.96667\n",
            "Epoch [4500/10000], loss: 0.13691 acc: 1.00000 val_loss: 0.20147, val_acc: 0.96667\n",
            "Epoch [4510/10000], loss: 0.13670 acc: 1.00000 val_loss: 0.20128, val_acc: 0.96667\n",
            "Epoch [4520/10000], loss: 0.13650 acc: 1.00000 val_loss: 0.20110, val_acc: 0.96667\n",
            "Epoch [4530/10000], loss: 0.13629 acc: 1.00000 val_loss: 0.20092, val_acc: 0.96667\n",
            "Epoch [4540/10000], loss: 0.13608 acc: 1.00000 val_loss: 0.20074, val_acc: 0.96667\n",
            "Epoch [4550/10000], loss: 0.13588 acc: 1.00000 val_loss: 0.20056, val_acc: 0.96667\n",
            "Epoch [4560/10000], loss: 0.13567 acc: 1.00000 val_loss: 0.20038, val_acc: 0.96667\n",
            "Epoch [4570/10000], loss: 0.13547 acc: 1.00000 val_loss: 0.20021, val_acc: 0.96667\n",
            "Epoch [4580/10000], loss: 0.13527 acc: 1.00000 val_loss: 0.20003, val_acc: 0.96667\n",
            "Epoch [4590/10000], loss: 0.13507 acc: 1.00000 val_loss: 0.19985, val_acc: 0.96667\n",
            "Epoch [4600/10000], loss: 0.13486 acc: 1.00000 val_loss: 0.19968, val_acc: 0.96667\n",
            "Epoch [4610/10000], loss: 0.13466 acc: 1.00000 val_loss: 0.19950, val_acc: 0.96667\n",
            "Epoch [4620/10000], loss: 0.13446 acc: 1.00000 val_loss: 0.19933, val_acc: 0.96667\n",
            "Epoch [4630/10000], loss: 0.13426 acc: 1.00000 val_loss: 0.19916, val_acc: 0.96667\n",
            "Epoch [4640/10000], loss: 0.13407 acc: 1.00000 val_loss: 0.19898, val_acc: 0.96667\n",
            "Epoch [4650/10000], loss: 0.13387 acc: 1.00000 val_loss: 0.19881, val_acc: 0.96667\n",
            "Epoch [4660/10000], loss: 0.13367 acc: 1.00000 val_loss: 0.19864, val_acc: 0.96667\n",
            "Epoch [4670/10000], loss: 0.13348 acc: 1.00000 val_loss: 0.19847, val_acc: 0.96667\n",
            "Epoch [4680/10000], loss: 0.13328 acc: 1.00000 val_loss: 0.19830, val_acc: 0.96667\n",
            "Epoch [4690/10000], loss: 0.13308 acc: 1.00000 val_loss: 0.19813, val_acc: 0.96667\n",
            "Epoch [4700/10000], loss: 0.13289 acc: 1.00000 val_loss: 0.19796, val_acc: 0.96667\n",
            "Epoch [4710/10000], loss: 0.13270 acc: 1.00000 val_loss: 0.19779, val_acc: 0.96667\n",
            "Epoch [4720/10000], loss: 0.13250 acc: 1.00000 val_loss: 0.19762, val_acc: 0.96667\n",
            "Epoch [4730/10000], loss: 0.13231 acc: 1.00000 val_loss: 0.19746, val_acc: 0.96667\n",
            "Epoch [4740/10000], loss: 0.13212 acc: 1.00000 val_loss: 0.19729, val_acc: 0.96667\n",
            "Epoch [4750/10000], loss: 0.13193 acc: 1.00000 val_loss: 0.19712, val_acc: 0.96667\n",
            "Epoch [4760/10000], loss: 0.13174 acc: 1.00000 val_loss: 0.19696, val_acc: 0.96667\n",
            "Epoch [4770/10000], loss: 0.13155 acc: 1.00000 val_loss: 0.19679, val_acc: 0.96667\n",
            "Epoch [4780/10000], loss: 0.13136 acc: 1.00000 val_loss: 0.19663, val_acc: 0.96667\n",
            "Epoch [4790/10000], loss: 0.13117 acc: 1.00000 val_loss: 0.19647, val_acc: 0.96667\n",
            "Epoch [4800/10000], loss: 0.13099 acc: 1.00000 val_loss: 0.19630, val_acc: 0.96667\n",
            "Epoch [4810/10000], loss: 0.13080 acc: 1.00000 val_loss: 0.19614, val_acc: 0.96667\n",
            "Epoch [4820/10000], loss: 0.13061 acc: 1.00000 val_loss: 0.19598, val_acc: 0.96667\n",
            "Epoch [4830/10000], loss: 0.13043 acc: 1.00000 val_loss: 0.19582, val_acc: 0.96667\n",
            "Epoch [4840/10000], loss: 0.13024 acc: 1.00000 val_loss: 0.19566, val_acc: 0.96667\n",
            "Epoch [4850/10000], loss: 0.13006 acc: 1.00000 val_loss: 0.19550, val_acc: 0.96667\n",
            "Epoch [4860/10000], loss: 0.12988 acc: 1.00000 val_loss: 0.19534, val_acc: 0.96667\n",
            "Epoch [4870/10000], loss: 0.12969 acc: 1.00000 val_loss: 0.19518, val_acc: 0.96667\n",
            "Epoch [4880/10000], loss: 0.12951 acc: 1.00000 val_loss: 0.19502, val_acc: 0.96667\n",
            "Epoch [4890/10000], loss: 0.12933 acc: 1.00000 val_loss: 0.19487, val_acc: 0.96667\n",
            "Epoch [4900/10000], loss: 0.12915 acc: 1.00000 val_loss: 0.19471, val_acc: 0.96667\n",
            "Epoch [4910/10000], loss: 0.12897 acc: 1.00000 val_loss: 0.19455, val_acc: 0.96667\n",
            "Epoch [4920/10000], loss: 0.12879 acc: 1.00000 val_loss: 0.19440, val_acc: 0.96667\n",
            "Epoch [4930/10000], loss: 0.12861 acc: 1.00000 val_loss: 0.19424, val_acc: 0.96667\n",
            "Epoch [4940/10000], loss: 0.12843 acc: 1.00000 val_loss: 0.19409, val_acc: 0.96667\n",
            "Epoch [4950/10000], loss: 0.12825 acc: 1.00000 val_loss: 0.19394, val_acc: 0.96667\n",
            "Epoch [4960/10000], loss: 0.12808 acc: 1.00000 val_loss: 0.19378, val_acc: 0.96667\n",
            "Epoch [4970/10000], loss: 0.12790 acc: 1.00000 val_loss: 0.19363, val_acc: 0.96667\n",
            "Epoch [4980/10000], loss: 0.12772 acc: 1.00000 val_loss: 0.19348, val_acc: 0.96667\n",
            "Epoch [4990/10000], loss: 0.12755 acc: 1.00000 val_loss: 0.19333, val_acc: 0.96667\n",
            "Epoch [5000/10000], loss: 0.12737 acc: 1.00000 val_loss: 0.19317, val_acc: 0.96667\n",
            "Epoch [5010/10000], loss: 0.12720 acc: 1.00000 val_loss: 0.19302, val_acc: 0.96667\n",
            "Epoch [5020/10000], loss: 0.12703 acc: 1.00000 val_loss: 0.19287, val_acc: 0.96667\n",
            "Epoch [5030/10000], loss: 0.12685 acc: 1.00000 val_loss: 0.19273, val_acc: 0.96667\n",
            "Epoch [5040/10000], loss: 0.12668 acc: 1.00000 val_loss: 0.19258, val_acc: 0.96667\n",
            "Epoch [5050/10000], loss: 0.12651 acc: 1.00000 val_loss: 0.19243, val_acc: 0.96667\n",
            "Epoch [5060/10000], loss: 0.12634 acc: 1.00000 val_loss: 0.19228, val_acc: 0.96667\n",
            "Epoch [5070/10000], loss: 0.12617 acc: 1.00000 val_loss: 0.19213, val_acc: 0.96667\n",
            "Epoch [5080/10000], loss: 0.12600 acc: 1.00000 val_loss: 0.19199, val_acc: 0.96667\n",
            "Epoch [5090/10000], loss: 0.12583 acc: 1.00000 val_loss: 0.19184, val_acc: 0.96667\n",
            "Epoch [5100/10000], loss: 0.12566 acc: 1.00000 val_loss: 0.19169, val_acc: 0.96667\n",
            "Epoch [5110/10000], loss: 0.12549 acc: 1.00000 val_loss: 0.19155, val_acc: 0.96667\n",
            "Epoch [5120/10000], loss: 0.12532 acc: 1.00000 val_loss: 0.19140, val_acc: 0.96667\n",
            "Epoch [5130/10000], loss: 0.12515 acc: 1.00000 val_loss: 0.19126, val_acc: 0.96667\n",
            "Epoch [5140/10000], loss: 0.12499 acc: 1.00000 val_loss: 0.19112, val_acc: 0.96667\n",
            "Epoch [5150/10000], loss: 0.12482 acc: 1.00000 val_loss: 0.19097, val_acc: 0.96667\n",
            "Epoch [5160/10000], loss: 0.12465 acc: 1.00000 val_loss: 0.19083, val_acc: 0.96667\n",
            "Epoch [5170/10000], loss: 0.12449 acc: 1.00000 val_loss: 0.19069, val_acc: 0.96667\n",
            "Epoch [5180/10000], loss: 0.12432 acc: 1.00000 val_loss: 0.19055, val_acc: 0.96667\n",
            "Epoch [5190/10000], loss: 0.12416 acc: 1.00000 val_loss: 0.19041, val_acc: 0.96667\n",
            "Epoch [5200/10000], loss: 0.12400 acc: 1.00000 val_loss: 0.19027, val_acc: 0.96667\n",
            "Epoch [5210/10000], loss: 0.12383 acc: 1.00000 val_loss: 0.19013, val_acc: 0.96667\n",
            "Epoch [5220/10000], loss: 0.12367 acc: 1.00000 val_loss: 0.18999, val_acc: 0.96667\n",
            "Epoch [5230/10000], loss: 0.12351 acc: 1.00000 val_loss: 0.18985, val_acc: 0.96667\n",
            "Epoch [5240/10000], loss: 0.12335 acc: 1.00000 val_loss: 0.18971, val_acc: 0.96667\n",
            "Epoch [5250/10000], loss: 0.12319 acc: 1.00000 val_loss: 0.18957, val_acc: 0.96667\n",
            "Epoch [5260/10000], loss: 0.12303 acc: 1.00000 val_loss: 0.18943, val_acc: 0.96667\n",
            "Epoch [5270/10000], loss: 0.12287 acc: 1.00000 val_loss: 0.18930, val_acc: 0.96667\n",
            "Epoch [5280/10000], loss: 0.12271 acc: 1.00000 val_loss: 0.18916, val_acc: 0.96667\n",
            "Epoch [5290/10000], loss: 0.12255 acc: 1.00000 val_loss: 0.18902, val_acc: 0.96667\n",
            "Epoch [5300/10000], loss: 0.12239 acc: 1.00000 val_loss: 0.18889, val_acc: 0.96667\n",
            "Epoch [5310/10000], loss: 0.12223 acc: 1.00000 val_loss: 0.18875, val_acc: 0.96667\n",
            "Epoch [5320/10000], loss: 0.12207 acc: 1.00000 val_loss: 0.18862, val_acc: 0.96667\n",
            "Epoch [5330/10000], loss: 0.12192 acc: 1.00000 val_loss: 0.18848, val_acc: 0.96667\n",
            "Epoch [5340/10000], loss: 0.12176 acc: 1.00000 val_loss: 0.18835, val_acc: 0.96667\n",
            "Epoch [5350/10000], loss: 0.12160 acc: 1.00000 val_loss: 0.18821, val_acc: 0.96667\n",
            "Epoch [5360/10000], loss: 0.12145 acc: 1.00000 val_loss: 0.18808, val_acc: 0.96667\n",
            "Epoch [5370/10000], loss: 0.12129 acc: 1.00000 val_loss: 0.18795, val_acc: 0.96667\n",
            "Epoch [5380/10000], loss: 0.12114 acc: 1.00000 val_loss: 0.18782, val_acc: 0.96667\n",
            "Epoch [5390/10000], loss: 0.12099 acc: 1.00000 val_loss: 0.18768, val_acc: 0.96667\n",
            "Epoch [5400/10000], loss: 0.12083 acc: 1.00000 val_loss: 0.18755, val_acc: 0.96667\n",
            "Epoch [5410/10000], loss: 0.12068 acc: 1.00000 val_loss: 0.18742, val_acc: 0.96667\n",
            "Epoch [5420/10000], loss: 0.12053 acc: 1.00000 val_loss: 0.18729, val_acc: 0.96667\n",
            "Epoch [5430/10000], loss: 0.12037 acc: 1.00000 val_loss: 0.18716, val_acc: 0.96667\n",
            "Epoch [5440/10000], loss: 0.12022 acc: 1.00000 val_loss: 0.18703, val_acc: 0.96667\n",
            "Epoch [5450/10000], loss: 0.12007 acc: 1.00000 val_loss: 0.18690, val_acc: 0.96667\n",
            "Epoch [5460/10000], loss: 0.11992 acc: 1.00000 val_loss: 0.18678, val_acc: 0.96667\n",
            "Epoch [5470/10000], loss: 0.11977 acc: 1.00000 val_loss: 0.18665, val_acc: 0.96667\n",
            "Epoch [5480/10000], loss: 0.11962 acc: 1.00000 val_loss: 0.18652, val_acc: 0.96667\n",
            "Epoch [5490/10000], loss: 0.11947 acc: 1.00000 val_loss: 0.18639, val_acc: 0.96667\n",
            "Epoch [5500/10000], loss: 0.11932 acc: 1.00000 val_loss: 0.18627, val_acc: 0.96667\n",
            "Epoch [5510/10000], loss: 0.11918 acc: 1.00000 val_loss: 0.18614, val_acc: 0.96667\n",
            "Epoch [5520/10000], loss: 0.11903 acc: 1.00000 val_loss: 0.18601, val_acc: 0.96667\n",
            "Epoch [5530/10000], loss: 0.11888 acc: 1.00000 val_loss: 0.18589, val_acc: 0.96667\n",
            "Epoch [5540/10000], loss: 0.11873 acc: 1.00000 val_loss: 0.18576, val_acc: 0.96667\n",
            "Epoch [5550/10000], loss: 0.11859 acc: 1.00000 val_loss: 0.18564, val_acc: 0.96667\n",
            "Epoch [5560/10000], loss: 0.11844 acc: 1.00000 val_loss: 0.18551, val_acc: 0.96667\n",
            "Epoch [5570/10000], loss: 0.11830 acc: 1.00000 val_loss: 0.18539, val_acc: 0.96667\n",
            "Epoch [5580/10000], loss: 0.11815 acc: 1.00000 val_loss: 0.18527, val_acc: 0.96667\n",
            "Epoch [5590/10000], loss: 0.11801 acc: 1.00000 val_loss: 0.18514, val_acc: 0.96667\n",
            "Epoch [5600/10000], loss: 0.11786 acc: 1.00000 val_loss: 0.18502, val_acc: 0.96667\n",
            "Epoch [5610/10000], loss: 0.11772 acc: 1.00000 val_loss: 0.18490, val_acc: 0.96667\n",
            "Epoch [5620/10000], loss: 0.11757 acc: 1.00000 val_loss: 0.18478, val_acc: 0.96667\n",
            "Epoch [5630/10000], loss: 0.11743 acc: 1.00000 val_loss: 0.18465, val_acc: 0.96667\n",
            "Epoch [5640/10000], loss: 0.11729 acc: 1.00000 val_loss: 0.18453, val_acc: 0.96667\n",
            "Epoch [5650/10000], loss: 0.11715 acc: 1.00000 val_loss: 0.18441, val_acc: 0.96667\n",
            "Epoch [5660/10000], loss: 0.11701 acc: 1.00000 val_loss: 0.18429, val_acc: 0.96667\n",
            "Epoch [5670/10000], loss: 0.11686 acc: 1.00000 val_loss: 0.18417, val_acc: 0.96667\n",
            "Epoch [5680/10000], loss: 0.11672 acc: 1.00000 val_loss: 0.18405, val_acc: 0.96667\n",
            "Epoch [5690/10000], loss: 0.11658 acc: 1.00000 val_loss: 0.18393, val_acc: 0.96667\n",
            "Epoch [5700/10000], loss: 0.11644 acc: 1.00000 val_loss: 0.18381, val_acc: 0.96667\n",
            "Epoch [5710/10000], loss: 0.11630 acc: 1.00000 val_loss: 0.18370, val_acc: 0.96667\n",
            "Epoch [5720/10000], loss: 0.11616 acc: 1.00000 val_loss: 0.18358, val_acc: 0.96667\n",
            "Epoch [5730/10000], loss: 0.11603 acc: 1.00000 val_loss: 0.18346, val_acc: 0.96667\n",
            "Epoch [5740/10000], loss: 0.11589 acc: 1.00000 val_loss: 0.18334, val_acc: 0.96667\n",
            "Epoch [5750/10000], loss: 0.11575 acc: 1.00000 val_loss: 0.18323, val_acc: 0.96667\n",
            "Epoch [5760/10000], loss: 0.11561 acc: 1.00000 val_loss: 0.18311, val_acc: 0.96667\n",
            "Epoch [5770/10000], loss: 0.11547 acc: 1.00000 val_loss: 0.18299, val_acc: 0.96667\n",
            "Epoch [5780/10000], loss: 0.11534 acc: 1.00000 val_loss: 0.18288, val_acc: 0.96667\n",
            "Epoch [5790/10000], loss: 0.11520 acc: 1.00000 val_loss: 0.18276, val_acc: 0.96667\n",
            "Epoch [5800/10000], loss: 0.11507 acc: 1.00000 val_loss: 0.18265, val_acc: 0.96667\n",
            "Epoch [5810/10000], loss: 0.11493 acc: 1.00000 val_loss: 0.18253, val_acc: 0.96667\n",
            "Epoch [5820/10000], loss: 0.11480 acc: 1.00000 val_loss: 0.18242, val_acc: 0.96667\n",
            "Epoch [5830/10000], loss: 0.11466 acc: 1.00000 val_loss: 0.18230, val_acc: 0.96667\n",
            "Epoch [5840/10000], loss: 0.11453 acc: 1.00000 val_loss: 0.18219, val_acc: 0.96667\n",
            "Epoch [5850/10000], loss: 0.11439 acc: 1.00000 val_loss: 0.18208, val_acc: 0.96667\n",
            "Epoch [5860/10000], loss: 0.11426 acc: 1.00000 val_loss: 0.18197, val_acc: 0.96667\n",
            "Epoch [5870/10000], loss: 0.11413 acc: 1.00000 val_loss: 0.18185, val_acc: 0.96667\n",
            "Epoch [5880/10000], loss: 0.11399 acc: 1.00000 val_loss: 0.18174, val_acc: 0.96667\n",
            "Epoch [5890/10000], loss: 0.11386 acc: 1.00000 val_loss: 0.18163, val_acc: 0.96667\n",
            "Epoch [5900/10000], loss: 0.11373 acc: 1.00000 val_loss: 0.18152, val_acc: 0.96667\n",
            "Epoch [5910/10000], loss: 0.11360 acc: 1.00000 val_loss: 0.18141, val_acc: 0.96667\n",
            "Epoch [5920/10000], loss: 0.11347 acc: 1.00000 val_loss: 0.18130, val_acc: 0.96667\n",
            "Epoch [5930/10000], loss: 0.11333 acc: 1.00000 val_loss: 0.18119, val_acc: 0.96667\n",
            "Epoch [5940/10000], loss: 0.11320 acc: 1.00000 val_loss: 0.18108, val_acc: 0.96667\n",
            "Epoch [5950/10000], loss: 0.11307 acc: 1.00000 val_loss: 0.18097, val_acc: 0.96667\n",
            "Epoch [5960/10000], loss: 0.11294 acc: 1.00000 val_loss: 0.18086, val_acc: 0.96667\n",
            "Epoch [5970/10000], loss: 0.11282 acc: 1.00000 val_loss: 0.18075, val_acc: 0.96667\n",
            "Epoch [5980/10000], loss: 0.11269 acc: 1.00000 val_loss: 0.18064, val_acc: 0.96667\n",
            "Epoch [5990/10000], loss: 0.11256 acc: 1.00000 val_loss: 0.18053, val_acc: 0.96667\n",
            "Epoch [6000/10000], loss: 0.11243 acc: 1.00000 val_loss: 0.18042, val_acc: 0.96667\n",
            "Epoch [6010/10000], loss: 0.11230 acc: 1.00000 val_loss: 0.18031, val_acc: 0.96667\n",
            "Epoch [6020/10000], loss: 0.11217 acc: 1.00000 val_loss: 0.18021, val_acc: 0.96667\n",
            "Epoch [6030/10000], loss: 0.11205 acc: 1.00000 val_loss: 0.18010, val_acc: 0.96667\n",
            "Epoch [6040/10000], loss: 0.11192 acc: 1.00000 val_loss: 0.17999, val_acc: 0.96667\n",
            "Epoch [6050/10000], loss: 0.11179 acc: 1.00000 val_loss: 0.17989, val_acc: 0.96667\n",
            "Epoch [6060/10000], loss: 0.11167 acc: 1.00000 val_loss: 0.17978, val_acc: 0.96667\n",
            "Epoch [6070/10000], loss: 0.11154 acc: 1.00000 val_loss: 0.17968, val_acc: 0.96667\n",
            "Epoch [6080/10000], loss: 0.11142 acc: 1.00000 val_loss: 0.17957, val_acc: 0.96667\n",
            "Epoch [6090/10000], loss: 0.11129 acc: 1.00000 val_loss: 0.17947, val_acc: 0.96667\n",
            "Epoch [6100/10000], loss: 0.11117 acc: 1.00000 val_loss: 0.17936, val_acc: 0.96667\n",
            "Epoch [6110/10000], loss: 0.11104 acc: 1.00000 val_loss: 0.17926, val_acc: 0.96667\n",
            "Epoch [6120/10000], loss: 0.11092 acc: 1.00000 val_loss: 0.17915, val_acc: 0.96667\n",
            "Epoch [6130/10000], loss: 0.11079 acc: 1.00000 val_loss: 0.17905, val_acc: 0.96667\n",
            "Epoch [6140/10000], loss: 0.11067 acc: 1.00000 val_loss: 0.17894, val_acc: 0.96667\n",
            "Epoch [6150/10000], loss: 0.11055 acc: 1.00000 val_loss: 0.17884, val_acc: 0.96667\n",
            "Epoch [6160/10000], loss: 0.11043 acc: 1.00000 val_loss: 0.17874, val_acc: 0.96667\n",
            "Epoch [6170/10000], loss: 0.11030 acc: 1.00000 val_loss: 0.17864, val_acc: 0.96667\n",
            "Epoch [6180/10000], loss: 0.11018 acc: 1.00000 val_loss: 0.17853, val_acc: 0.96667\n",
            "Epoch [6190/10000], loss: 0.11006 acc: 1.00000 val_loss: 0.17843, val_acc: 0.96667\n",
            "Epoch [6200/10000], loss: 0.10994 acc: 1.00000 val_loss: 0.17833, val_acc: 0.96667\n",
            "Epoch [6210/10000], loss: 0.10982 acc: 1.00000 val_loss: 0.17823, val_acc: 0.96667\n",
            "Epoch [6220/10000], loss: 0.10970 acc: 1.00000 val_loss: 0.17813, val_acc: 0.96667\n",
            "Epoch [6230/10000], loss: 0.10958 acc: 1.00000 val_loss: 0.17803, val_acc: 0.96667\n",
            "Epoch [6240/10000], loss: 0.10946 acc: 1.00000 val_loss: 0.17793, val_acc: 0.96667\n",
            "Epoch [6250/10000], loss: 0.10934 acc: 1.00000 val_loss: 0.17783, val_acc: 0.96667\n",
            "Epoch [6260/10000], loss: 0.10922 acc: 1.00000 val_loss: 0.17773, val_acc: 0.96667\n",
            "Epoch [6270/10000], loss: 0.10910 acc: 1.00000 val_loss: 0.17763, val_acc: 0.96667\n",
            "Epoch [6280/10000], loss: 0.10898 acc: 1.00000 val_loss: 0.17753, val_acc: 0.96667\n",
            "Epoch [6290/10000], loss: 0.10886 acc: 1.00000 val_loss: 0.17743, val_acc: 0.96667\n",
            "Epoch [6300/10000], loss: 0.10874 acc: 1.00000 val_loss: 0.17733, val_acc: 0.96667\n",
            "Epoch [6310/10000], loss: 0.10863 acc: 1.00000 val_loss: 0.17723, val_acc: 0.96667\n",
            "Epoch [6320/10000], loss: 0.10851 acc: 1.00000 val_loss: 0.17713, val_acc: 0.96667\n",
            "Epoch [6330/10000], loss: 0.10839 acc: 1.00000 val_loss: 0.17704, val_acc: 0.96667\n",
            "Epoch [6340/10000], loss: 0.10828 acc: 1.00000 val_loss: 0.17694, val_acc: 0.96667\n",
            "Epoch [6350/10000], loss: 0.10816 acc: 1.00000 val_loss: 0.17684, val_acc: 0.96667\n",
            "Epoch [6360/10000], loss: 0.10804 acc: 1.00000 val_loss: 0.17675, val_acc: 0.96667\n",
            "Epoch [6370/10000], loss: 0.10793 acc: 1.00000 val_loss: 0.17665, val_acc: 0.96667\n",
            "Epoch [6380/10000], loss: 0.10781 acc: 1.00000 val_loss: 0.17655, val_acc: 0.96667\n",
            "Epoch [6390/10000], loss: 0.10770 acc: 1.00000 val_loss: 0.17646, val_acc: 0.96667\n",
            "Epoch [6400/10000], loss: 0.10758 acc: 1.00000 val_loss: 0.17636, val_acc: 0.96667\n",
            "Epoch [6410/10000], loss: 0.10747 acc: 1.00000 val_loss: 0.17627, val_acc: 0.96667\n",
            "Epoch [6420/10000], loss: 0.10735 acc: 1.00000 val_loss: 0.17617, val_acc: 0.96667\n",
            "Epoch [6430/10000], loss: 0.10724 acc: 1.00000 val_loss: 0.17608, val_acc: 0.96667\n",
            "Epoch [6440/10000], loss: 0.10712 acc: 1.00000 val_loss: 0.17598, val_acc: 0.96667\n",
            "Epoch [6450/10000], loss: 0.10701 acc: 1.00000 val_loss: 0.17589, val_acc: 0.96667\n",
            "Epoch [6460/10000], loss: 0.10690 acc: 1.00000 val_loss: 0.17579, val_acc: 0.96667\n",
            "Epoch [6470/10000], loss: 0.10679 acc: 1.00000 val_loss: 0.17570, val_acc: 0.96667\n",
            "Epoch [6480/10000], loss: 0.10667 acc: 1.00000 val_loss: 0.17560, val_acc: 0.96667\n",
            "Epoch [6490/10000], loss: 0.10656 acc: 1.00000 val_loss: 0.17551, val_acc: 0.96667\n",
            "Epoch [6500/10000], loss: 0.10645 acc: 1.00000 val_loss: 0.17542, val_acc: 0.96667\n",
            "Epoch [6510/10000], loss: 0.10634 acc: 1.00000 val_loss: 0.17533, val_acc: 0.96667\n",
            "Epoch [6520/10000], loss: 0.10623 acc: 1.00000 val_loss: 0.17523, val_acc: 0.96667\n",
            "Epoch [6530/10000], loss: 0.10612 acc: 1.00000 val_loss: 0.17514, val_acc: 0.96667\n",
            "Epoch [6540/10000], loss: 0.10600 acc: 1.00000 val_loss: 0.17505, val_acc: 0.96667\n",
            "Epoch [6550/10000], loss: 0.10589 acc: 1.00000 val_loss: 0.17496, val_acc: 0.96667\n",
            "Epoch [6560/10000], loss: 0.10578 acc: 1.00000 val_loss: 0.17487, val_acc: 0.96667\n",
            "Epoch [6570/10000], loss: 0.10567 acc: 1.00000 val_loss: 0.17478, val_acc: 0.96667\n",
            "Epoch [6580/10000], loss: 0.10556 acc: 1.00000 val_loss: 0.17468, val_acc: 0.96667\n",
            "Epoch [6590/10000], loss: 0.10546 acc: 1.00000 val_loss: 0.17459, val_acc: 0.96667\n",
            "Epoch [6600/10000], loss: 0.10535 acc: 1.00000 val_loss: 0.17450, val_acc: 0.96667\n",
            "Epoch [6610/10000], loss: 0.10524 acc: 1.00000 val_loss: 0.17441, val_acc: 0.96667\n",
            "Epoch [6620/10000], loss: 0.10513 acc: 1.00000 val_loss: 0.17432, val_acc: 0.96667\n",
            "Epoch [6630/10000], loss: 0.10502 acc: 1.00000 val_loss: 0.17423, val_acc: 0.96667\n",
            "Epoch [6640/10000], loss: 0.10491 acc: 1.00000 val_loss: 0.17414, val_acc: 0.96667\n",
            "Epoch [6650/10000], loss: 0.10481 acc: 1.00000 val_loss: 0.17406, val_acc: 0.96667\n",
            "Epoch [6660/10000], loss: 0.10470 acc: 1.00000 val_loss: 0.17397, val_acc: 0.96667\n",
            "Epoch [6670/10000], loss: 0.10459 acc: 1.00000 val_loss: 0.17388, val_acc: 0.96667\n",
            "Epoch [6680/10000], loss: 0.10448 acc: 1.00000 val_loss: 0.17379, val_acc: 0.96667\n",
            "Epoch [6690/10000], loss: 0.10438 acc: 1.00000 val_loss: 0.17370, val_acc: 0.96667\n",
            "Epoch [6700/10000], loss: 0.10427 acc: 1.00000 val_loss: 0.17361, val_acc: 0.96667\n",
            "Epoch [6710/10000], loss: 0.10417 acc: 1.00000 val_loss: 0.17353, val_acc: 0.96667\n",
            "Epoch [6720/10000], loss: 0.10406 acc: 1.00000 val_loss: 0.17344, val_acc: 0.96667\n",
            "Epoch [6730/10000], loss: 0.10395 acc: 1.00000 val_loss: 0.17335, val_acc: 0.96667\n",
            "Epoch [6740/10000], loss: 0.10385 acc: 1.00000 val_loss: 0.17326, val_acc: 0.96667\n",
            "Epoch [6750/10000], loss: 0.10374 acc: 1.00000 val_loss: 0.17318, val_acc: 0.96667\n",
            "Epoch [6760/10000], loss: 0.10364 acc: 1.00000 val_loss: 0.17309, val_acc: 0.96667\n",
            "Epoch [6770/10000], loss: 0.10354 acc: 1.00000 val_loss: 0.17301, val_acc: 0.96667\n",
            "Epoch [6780/10000], loss: 0.10343 acc: 1.00000 val_loss: 0.17292, val_acc: 0.96667\n",
            "Epoch [6790/10000], loss: 0.10333 acc: 1.00000 val_loss: 0.17283, val_acc: 0.96667\n",
            "Epoch [6800/10000], loss: 0.10322 acc: 1.00000 val_loss: 0.17275, val_acc: 0.96667\n",
            "Epoch [6810/10000], loss: 0.10312 acc: 1.00000 val_loss: 0.17266, val_acc: 0.96667\n",
            "Epoch [6820/10000], loss: 0.10302 acc: 1.00000 val_loss: 0.17258, val_acc: 0.96667\n",
            "Epoch [6830/10000], loss: 0.10292 acc: 1.00000 val_loss: 0.17249, val_acc: 0.96667\n",
            "Epoch [6840/10000], loss: 0.10281 acc: 1.00000 val_loss: 0.17241, val_acc: 0.96667\n",
            "Epoch [6850/10000], loss: 0.10271 acc: 1.00000 val_loss: 0.17232, val_acc: 0.96667\n",
            "Epoch [6860/10000], loss: 0.10261 acc: 1.00000 val_loss: 0.17224, val_acc: 0.96667\n",
            "Epoch [6870/10000], loss: 0.10251 acc: 1.00000 val_loss: 0.17216, val_acc: 0.96667\n",
            "Epoch [6880/10000], loss: 0.10241 acc: 1.00000 val_loss: 0.17207, val_acc: 0.96667\n",
            "Epoch [6890/10000], loss: 0.10230 acc: 1.00000 val_loss: 0.17199, val_acc: 0.96667\n",
            "Epoch [6900/10000], loss: 0.10220 acc: 1.00000 val_loss: 0.17191, val_acc: 0.96667\n",
            "Epoch [6910/10000], loss: 0.10210 acc: 1.00000 val_loss: 0.17182, val_acc: 0.96667\n",
            "Epoch [6920/10000], loss: 0.10200 acc: 1.00000 val_loss: 0.17174, val_acc: 0.96667\n",
            "Epoch [6930/10000], loss: 0.10190 acc: 1.00000 val_loss: 0.17166, val_acc: 0.96667\n",
            "Epoch [6940/10000], loss: 0.10180 acc: 1.00000 val_loss: 0.17158, val_acc: 0.96667\n",
            "Epoch [6950/10000], loss: 0.10170 acc: 1.00000 val_loss: 0.17150, val_acc: 0.96667\n",
            "Epoch [6960/10000], loss: 0.10160 acc: 1.00000 val_loss: 0.17141, val_acc: 0.96667\n",
            "Epoch [6970/10000], loss: 0.10150 acc: 1.00000 val_loss: 0.17133, val_acc: 0.96667\n",
            "Epoch [6980/10000], loss: 0.10140 acc: 1.00000 val_loss: 0.17125, val_acc: 0.96667\n",
            "Epoch [6990/10000], loss: 0.10130 acc: 1.00000 val_loss: 0.17117, val_acc: 0.96667\n",
            "Epoch [7000/10000], loss: 0.10121 acc: 1.00000 val_loss: 0.17109, val_acc: 0.96667\n",
            "Epoch [7010/10000], loss: 0.10111 acc: 1.00000 val_loss: 0.17101, val_acc: 0.96667\n",
            "Epoch [7020/10000], loss: 0.10101 acc: 1.00000 val_loss: 0.17093, val_acc: 0.96667\n",
            "Epoch [7030/10000], loss: 0.10091 acc: 1.00000 val_loss: 0.17085, val_acc: 0.96667\n",
            "Epoch [7040/10000], loss: 0.10081 acc: 1.00000 val_loss: 0.17077, val_acc: 0.96667\n",
            "Epoch [7050/10000], loss: 0.10072 acc: 1.00000 val_loss: 0.17069, val_acc: 0.96667\n",
            "Epoch [7060/10000], loss: 0.10062 acc: 1.00000 val_loss: 0.17061, val_acc: 0.96667\n",
            "Epoch [7070/10000], loss: 0.10052 acc: 1.00000 val_loss: 0.17053, val_acc: 0.96667\n",
            "Epoch [7080/10000], loss: 0.10043 acc: 1.00000 val_loss: 0.17045, val_acc: 0.96667\n",
            "Epoch [7090/10000], loss: 0.10033 acc: 1.00000 val_loss: 0.17037, val_acc: 0.96667\n",
            "Epoch [7100/10000], loss: 0.10023 acc: 1.00000 val_loss: 0.17029, val_acc: 0.96667\n",
            "Epoch [7110/10000], loss: 0.10014 acc: 1.00000 val_loss: 0.17021, val_acc: 0.96667\n",
            "Epoch [7120/10000], loss: 0.10004 acc: 1.00000 val_loss: 0.17013, val_acc: 0.96667\n",
            "Epoch [7130/10000], loss: 0.09995 acc: 1.00000 val_loss: 0.17006, val_acc: 0.96667\n",
            "Epoch [7140/10000], loss: 0.09985 acc: 1.00000 val_loss: 0.16998, val_acc: 0.96667\n",
            "Epoch [7150/10000], loss: 0.09976 acc: 1.00000 val_loss: 0.16990, val_acc: 0.96667\n",
            "Epoch [7160/10000], loss: 0.09966 acc: 1.00000 val_loss: 0.16982, val_acc: 0.96667\n",
            "Epoch [7170/10000], loss: 0.09957 acc: 1.00000 val_loss: 0.16975, val_acc: 0.96667\n",
            "Epoch [7180/10000], loss: 0.09947 acc: 1.00000 val_loss: 0.16967, val_acc: 0.96667\n",
            "Epoch [7190/10000], loss: 0.09938 acc: 1.00000 val_loss: 0.16959, val_acc: 0.96667\n",
            "Epoch [7200/10000], loss: 0.09928 acc: 1.00000 val_loss: 0.16952, val_acc: 0.96667\n",
            "Epoch [7210/10000], loss: 0.09919 acc: 1.00000 val_loss: 0.16944, val_acc: 0.96667\n",
            "Epoch [7220/10000], loss: 0.09910 acc: 1.00000 val_loss: 0.16936, val_acc: 0.96667\n",
            "Epoch [7230/10000], loss: 0.09900 acc: 1.00000 val_loss: 0.16929, val_acc: 0.96667\n",
            "Epoch [7240/10000], loss: 0.09891 acc: 1.00000 val_loss: 0.16921, val_acc: 0.96667\n",
            "Epoch [7250/10000], loss: 0.09882 acc: 1.00000 val_loss: 0.16914, val_acc: 0.96667\n",
            "Epoch [7260/10000], loss: 0.09873 acc: 1.00000 val_loss: 0.16906, val_acc: 0.96667\n",
            "Epoch [7270/10000], loss: 0.09863 acc: 1.00000 val_loss: 0.16899, val_acc: 0.96667\n",
            "Epoch [7280/10000], loss: 0.09854 acc: 1.00000 val_loss: 0.16891, val_acc: 0.96667\n",
            "Epoch [7290/10000], loss: 0.09845 acc: 1.00000 val_loss: 0.16884, val_acc: 0.96667\n",
            "Epoch [7300/10000], loss: 0.09836 acc: 1.00000 val_loss: 0.16876, val_acc: 0.96667\n",
            "Epoch [7310/10000], loss: 0.09827 acc: 1.00000 val_loss: 0.16869, val_acc: 0.96667\n",
            "Epoch [7320/10000], loss: 0.09817 acc: 1.00000 val_loss: 0.16861, val_acc: 0.96667\n",
            "Epoch [7330/10000], loss: 0.09808 acc: 1.00000 val_loss: 0.16854, val_acc: 0.96667\n",
            "Epoch [7340/10000], loss: 0.09799 acc: 1.00000 val_loss: 0.16846, val_acc: 0.96667\n",
            "Epoch [7350/10000], loss: 0.09790 acc: 1.00000 val_loss: 0.16839, val_acc: 0.96667\n",
            "Epoch [7360/10000], loss: 0.09781 acc: 1.00000 val_loss: 0.16832, val_acc: 0.96667\n",
            "Epoch [7370/10000], loss: 0.09772 acc: 1.00000 val_loss: 0.16824, val_acc: 0.96667\n",
            "Epoch [7380/10000], loss: 0.09763 acc: 1.00000 val_loss: 0.16817, val_acc: 0.96667\n",
            "Epoch [7390/10000], loss: 0.09754 acc: 1.00000 val_loss: 0.16810, val_acc: 0.96667\n",
            "Epoch [7400/10000], loss: 0.09745 acc: 1.00000 val_loss: 0.16802, val_acc: 0.96667\n",
            "Epoch [7410/10000], loss: 0.09736 acc: 1.00000 val_loss: 0.16795, val_acc: 0.96667\n",
            "Epoch [7420/10000], loss: 0.09727 acc: 1.00000 val_loss: 0.16788, val_acc: 0.96667\n",
            "Epoch [7430/10000], loss: 0.09718 acc: 1.00000 val_loss: 0.16781, val_acc: 0.96667\n",
            "Epoch [7440/10000], loss: 0.09710 acc: 1.00000 val_loss: 0.16774, val_acc: 0.96667\n",
            "Epoch [7450/10000], loss: 0.09701 acc: 1.00000 val_loss: 0.16766, val_acc: 0.96667\n",
            "Epoch [7460/10000], loss: 0.09692 acc: 1.00000 val_loss: 0.16759, val_acc: 0.96667\n",
            "Epoch [7470/10000], loss: 0.09683 acc: 1.00000 val_loss: 0.16752, val_acc: 0.96667\n",
            "Epoch [7480/10000], loss: 0.09674 acc: 1.00000 val_loss: 0.16745, val_acc: 0.96667\n",
            "Epoch [7490/10000], loss: 0.09665 acc: 1.00000 val_loss: 0.16738, val_acc: 0.96667\n",
            "Epoch [7500/10000], loss: 0.09657 acc: 1.00000 val_loss: 0.16731, val_acc: 0.96667\n",
            "Epoch [7510/10000], loss: 0.09648 acc: 1.00000 val_loss: 0.16724, val_acc: 0.96667\n",
            "Epoch [7520/10000], loss: 0.09639 acc: 1.00000 val_loss: 0.16717, val_acc: 0.96667\n",
            "Epoch [7530/10000], loss: 0.09631 acc: 1.00000 val_loss: 0.16710, val_acc: 0.96667\n",
            "Epoch [7540/10000], loss: 0.09622 acc: 1.00000 val_loss: 0.16703, val_acc: 0.96667\n",
            "Epoch [7550/10000], loss: 0.09613 acc: 1.00000 val_loss: 0.16696, val_acc: 0.96667\n",
            "Epoch [7560/10000], loss: 0.09605 acc: 1.00000 val_loss: 0.16689, val_acc: 0.96667\n",
            "Epoch [7570/10000], loss: 0.09596 acc: 1.00000 val_loss: 0.16682, val_acc: 0.96667\n",
            "Epoch [7580/10000], loss: 0.09587 acc: 1.00000 val_loss: 0.16675, val_acc: 0.96667\n",
            "Epoch [7590/10000], loss: 0.09579 acc: 1.00000 val_loss: 0.16668, val_acc: 0.96667\n",
            "Epoch [7600/10000], loss: 0.09570 acc: 1.00000 val_loss: 0.16661, val_acc: 0.96667\n",
            "Epoch [7610/10000], loss: 0.09562 acc: 1.00000 val_loss: 0.16654, val_acc: 0.96667\n",
            "Epoch [7620/10000], loss: 0.09553 acc: 1.00000 val_loss: 0.16647, val_acc: 0.96667\n",
            "Epoch [7630/10000], loss: 0.09545 acc: 1.00000 val_loss: 0.16640, val_acc: 0.96667\n",
            "Epoch [7640/10000], loss: 0.09536 acc: 1.00000 val_loss: 0.16633, val_acc: 0.96667\n",
            "Epoch [7650/10000], loss: 0.09528 acc: 1.00000 val_loss: 0.16626, val_acc: 0.96667\n",
            "Epoch [7660/10000], loss: 0.09519 acc: 1.00000 val_loss: 0.16620, val_acc: 0.96667\n",
            "Epoch [7670/10000], loss: 0.09511 acc: 1.00000 val_loss: 0.16613, val_acc: 0.96667\n",
            "Epoch [7680/10000], loss: 0.09502 acc: 1.00000 val_loss: 0.16606, val_acc: 0.96667\n",
            "Epoch [7690/10000], loss: 0.09494 acc: 1.00000 val_loss: 0.16599, val_acc: 0.96667\n",
            "Epoch [7700/10000], loss: 0.09486 acc: 1.00000 val_loss: 0.16593, val_acc: 0.96667\n",
            "Epoch [7710/10000], loss: 0.09477 acc: 1.00000 val_loss: 0.16586, val_acc: 0.96667\n",
            "Epoch [7720/10000], loss: 0.09469 acc: 1.00000 val_loss: 0.16579, val_acc: 0.96667\n",
            "Epoch [7730/10000], loss: 0.09461 acc: 1.00000 val_loss: 0.16572, val_acc: 0.96667\n",
            "Epoch [7740/10000], loss: 0.09452 acc: 1.00000 val_loss: 0.16566, val_acc: 0.96667\n",
            "Epoch [7750/10000], loss: 0.09444 acc: 1.00000 val_loss: 0.16559, val_acc: 0.96667\n",
            "Epoch [7760/10000], loss: 0.09436 acc: 1.00000 val_loss: 0.16552, val_acc: 0.96667\n",
            "Epoch [7770/10000], loss: 0.09428 acc: 1.00000 val_loss: 0.16546, val_acc: 0.96667\n",
            "Epoch [7780/10000], loss: 0.09419 acc: 1.00000 val_loss: 0.16539, val_acc: 0.96667\n",
            "Epoch [7790/10000], loss: 0.09411 acc: 1.00000 val_loss: 0.16533, val_acc: 0.96667\n",
            "Epoch [7800/10000], loss: 0.09403 acc: 1.00000 val_loss: 0.16526, val_acc: 0.96667\n",
            "Epoch [7810/10000], loss: 0.09395 acc: 1.00000 val_loss: 0.16519, val_acc: 0.96667\n",
            "Epoch [7820/10000], loss: 0.09387 acc: 1.00000 val_loss: 0.16513, val_acc: 0.96667\n",
            "Epoch [7830/10000], loss: 0.09378 acc: 1.00000 val_loss: 0.16506, val_acc: 0.96667\n",
            "Epoch [7840/10000], loss: 0.09370 acc: 1.00000 val_loss: 0.16500, val_acc: 0.96667\n",
            "Epoch [7850/10000], loss: 0.09362 acc: 1.00000 val_loss: 0.16493, val_acc: 0.96667\n",
            "Epoch [7860/10000], loss: 0.09354 acc: 1.00000 val_loss: 0.16487, val_acc: 0.96667\n",
            "Epoch [7870/10000], loss: 0.09346 acc: 1.00000 val_loss: 0.16480, val_acc: 0.96667\n",
            "Epoch [7880/10000], loss: 0.09338 acc: 1.00000 val_loss: 0.16474, val_acc: 0.96667\n",
            "Epoch [7890/10000], loss: 0.09330 acc: 1.00000 val_loss: 0.16468, val_acc: 0.96667\n",
            "Epoch [7900/10000], loss: 0.09322 acc: 1.00000 val_loss: 0.16461, val_acc: 0.96667\n",
            "Epoch [7910/10000], loss: 0.09314 acc: 1.00000 val_loss: 0.16455, val_acc: 0.96667\n",
            "Epoch [7920/10000], loss: 0.09306 acc: 1.00000 val_loss: 0.16448, val_acc: 0.96667\n",
            "Epoch [7930/10000], loss: 0.09298 acc: 1.00000 val_loss: 0.16442, val_acc: 0.96667\n",
            "Epoch [7940/10000], loss: 0.09290 acc: 1.00000 val_loss: 0.16436, val_acc: 0.96667\n",
            "Epoch [7950/10000], loss: 0.09282 acc: 1.00000 val_loss: 0.16429, val_acc: 0.96667\n",
            "Epoch [7960/10000], loss: 0.09274 acc: 1.00000 val_loss: 0.16423, val_acc: 0.96667\n",
            "Epoch [7970/10000], loss: 0.09266 acc: 1.00000 val_loss: 0.16417, val_acc: 0.96667\n",
            "Epoch [7980/10000], loss: 0.09259 acc: 1.00000 val_loss: 0.16410, val_acc: 0.96667\n",
            "Epoch [7990/10000], loss: 0.09251 acc: 1.00000 val_loss: 0.16404, val_acc: 0.96667\n",
            "Epoch [8000/10000], loss: 0.09243 acc: 1.00000 val_loss: 0.16398, val_acc: 0.96667\n",
            "Epoch [8010/10000], loss: 0.09235 acc: 1.00000 val_loss: 0.16392, val_acc: 0.96667\n",
            "Epoch [8020/10000], loss: 0.09227 acc: 1.00000 val_loss: 0.16385, val_acc: 0.96667\n",
            "Epoch [8030/10000], loss: 0.09219 acc: 1.00000 val_loss: 0.16379, val_acc: 0.96667\n",
            "Epoch [8040/10000], loss: 0.09212 acc: 1.00000 val_loss: 0.16373, val_acc: 0.96667\n",
            "Epoch [8050/10000], loss: 0.09204 acc: 1.00000 val_loss: 0.16367, val_acc: 0.96667\n",
            "Epoch [8060/10000], loss: 0.09196 acc: 1.00000 val_loss: 0.16361, val_acc: 0.96667\n",
            "Epoch [8070/10000], loss: 0.09188 acc: 1.00000 val_loss: 0.16354, val_acc: 0.96667\n",
            "Epoch [8080/10000], loss: 0.09181 acc: 1.00000 val_loss: 0.16348, val_acc: 0.96667\n",
            "Epoch [8090/10000], loss: 0.09173 acc: 1.00000 val_loss: 0.16342, val_acc: 0.96667\n",
            "Epoch [8100/10000], loss: 0.09165 acc: 1.00000 val_loss: 0.16336, val_acc: 0.96667\n",
            "Epoch [8110/10000], loss: 0.09158 acc: 1.00000 val_loss: 0.16330, val_acc: 0.96667\n",
            "Epoch [8120/10000], loss: 0.09150 acc: 1.00000 val_loss: 0.16324, val_acc: 0.96667\n",
            "Epoch [8130/10000], loss: 0.09142 acc: 1.00000 val_loss: 0.16318, val_acc: 0.96667\n",
            "Epoch [8140/10000], loss: 0.09135 acc: 1.00000 val_loss: 0.16312, val_acc: 0.96667\n",
            "Epoch [8150/10000], loss: 0.09127 acc: 1.00000 val_loss: 0.16306, val_acc: 0.96667\n",
            "Epoch [8160/10000], loss: 0.09120 acc: 1.00000 val_loss: 0.16300, val_acc: 0.96667\n",
            "Epoch [8170/10000], loss: 0.09112 acc: 1.00000 val_loss: 0.16294, val_acc: 0.96667\n",
            "Epoch [8180/10000], loss: 0.09105 acc: 1.00000 val_loss: 0.16288, val_acc: 0.96667\n",
            "Epoch [8190/10000], loss: 0.09097 acc: 1.00000 val_loss: 0.16282, val_acc: 0.96667\n",
            "Epoch [8200/10000], loss: 0.09089 acc: 1.00000 val_loss: 0.16276, val_acc: 0.96667\n",
            "Epoch [8210/10000], loss: 0.09082 acc: 1.00000 val_loss: 0.16270, val_acc: 0.96667\n",
            "Epoch [8220/10000], loss: 0.09074 acc: 1.00000 val_loss: 0.16264, val_acc: 0.96667\n",
            "Epoch [8230/10000], loss: 0.09067 acc: 1.00000 val_loss: 0.16258, val_acc: 0.96667\n",
            "Epoch [8240/10000], loss: 0.09060 acc: 1.00000 val_loss: 0.16252, val_acc: 0.96667\n",
            "Epoch [8250/10000], loss: 0.09052 acc: 1.00000 val_loss: 0.16246, val_acc: 0.96667\n",
            "Epoch [8260/10000], loss: 0.09045 acc: 1.00000 val_loss: 0.16240, val_acc: 0.96667\n",
            "Epoch [8270/10000], loss: 0.09037 acc: 1.00000 val_loss: 0.16234, val_acc: 0.96667\n",
            "Epoch [8280/10000], loss: 0.09030 acc: 1.00000 val_loss: 0.16228, val_acc: 0.96667\n",
            "Epoch [8290/10000], loss: 0.09023 acc: 1.00000 val_loss: 0.16222, val_acc: 0.96667\n",
            "Epoch [8300/10000], loss: 0.09015 acc: 1.00000 val_loss: 0.16217, val_acc: 0.96667\n",
            "Epoch [8310/10000], loss: 0.09008 acc: 1.00000 val_loss: 0.16211, val_acc: 0.96667\n",
            "Epoch [8320/10000], loss: 0.09000 acc: 1.00000 val_loss: 0.16205, val_acc: 0.96667\n",
            "Epoch [8330/10000], loss: 0.08993 acc: 1.00000 val_loss: 0.16199, val_acc: 0.96667\n",
            "Epoch [8340/10000], loss: 0.08986 acc: 1.00000 val_loss: 0.16193, val_acc: 0.96667\n",
            "Epoch [8350/10000], loss: 0.08979 acc: 1.00000 val_loss: 0.16188, val_acc: 0.96667\n",
            "Epoch [8360/10000], loss: 0.08971 acc: 1.00000 val_loss: 0.16182, val_acc: 0.96667\n",
            "Epoch [8370/10000], loss: 0.08964 acc: 1.00000 val_loss: 0.16176, val_acc: 0.96667\n",
            "Epoch [8380/10000], loss: 0.08957 acc: 1.00000 val_loss: 0.16170, val_acc: 0.96667\n",
            "Epoch [8390/10000], loss: 0.08950 acc: 1.00000 val_loss: 0.16165, val_acc: 0.96667\n",
            "Epoch [8400/10000], loss: 0.08942 acc: 1.00000 val_loss: 0.16159, val_acc: 0.96667\n",
            "Epoch [8410/10000], loss: 0.08935 acc: 1.00000 val_loss: 0.16153, val_acc: 0.96667\n",
            "Epoch [8420/10000], loss: 0.08928 acc: 1.00000 val_loss: 0.16148, val_acc: 0.96667\n",
            "Epoch [8430/10000], loss: 0.08921 acc: 1.00000 val_loss: 0.16142, val_acc: 0.96667\n",
            "Epoch [8440/10000], loss: 0.08914 acc: 1.00000 val_loss: 0.16136, val_acc: 0.96667\n",
            "Epoch [8450/10000], loss: 0.08907 acc: 1.00000 val_loss: 0.16131, val_acc: 0.96667\n",
            "Epoch [8460/10000], loss: 0.08899 acc: 1.00000 val_loss: 0.16125, val_acc: 0.96667\n",
            "Epoch [8470/10000], loss: 0.08892 acc: 1.00000 val_loss: 0.16119, val_acc: 0.96667\n",
            "Epoch [8480/10000], loss: 0.08885 acc: 1.00000 val_loss: 0.16114, val_acc: 0.96667\n",
            "Epoch [8490/10000], loss: 0.08878 acc: 1.00000 val_loss: 0.16108, val_acc: 0.96667\n",
            "Epoch [8500/10000], loss: 0.08871 acc: 1.00000 val_loss: 0.16103, val_acc: 0.96667\n",
            "Epoch [8510/10000], loss: 0.08864 acc: 1.00000 val_loss: 0.16097, val_acc: 0.96667\n",
            "Epoch [8520/10000], loss: 0.08857 acc: 1.00000 val_loss: 0.16092, val_acc: 0.96667\n",
            "Epoch [8530/10000], loss: 0.08850 acc: 1.00000 val_loss: 0.16086, val_acc: 0.96667\n",
            "Epoch [8540/10000], loss: 0.08843 acc: 1.00000 val_loss: 0.16081, val_acc: 0.96667\n",
            "Epoch [8550/10000], loss: 0.08836 acc: 1.00000 val_loss: 0.16075, val_acc: 0.96667\n",
            "Epoch [8560/10000], loss: 0.08829 acc: 1.00000 val_loss: 0.16070, val_acc: 0.96667\n",
            "Epoch [8570/10000], loss: 0.08822 acc: 1.00000 val_loss: 0.16064, val_acc: 0.96667\n",
            "Epoch [8580/10000], loss: 0.08815 acc: 1.00000 val_loss: 0.16059, val_acc: 0.96667\n",
            "Epoch [8590/10000], loss: 0.08808 acc: 1.00000 val_loss: 0.16053, val_acc: 0.96667\n",
            "Epoch [8600/10000], loss: 0.08801 acc: 1.00000 val_loss: 0.16048, val_acc: 0.96667\n",
            "Epoch [8610/10000], loss: 0.08794 acc: 1.00000 val_loss: 0.16042, val_acc: 0.96667\n",
            "Epoch [8620/10000], loss: 0.08787 acc: 1.00000 val_loss: 0.16037, val_acc: 0.96667\n",
            "Epoch [8630/10000], loss: 0.08780 acc: 1.00000 val_loss: 0.16031, val_acc: 0.96667\n",
            "Epoch [8640/10000], loss: 0.08774 acc: 1.00000 val_loss: 0.16026, val_acc: 0.96667\n",
            "Epoch [8650/10000], loss: 0.08767 acc: 1.00000 val_loss: 0.16021, val_acc: 0.96667\n",
            "Epoch [8660/10000], loss: 0.08760 acc: 1.00000 val_loss: 0.16015, val_acc: 0.96667\n",
            "Epoch [8670/10000], loss: 0.08753 acc: 1.00000 val_loss: 0.16010, val_acc: 0.96667\n",
            "Epoch [8680/10000], loss: 0.08746 acc: 1.00000 val_loss: 0.16005, val_acc: 0.96667\n",
            "Epoch [8690/10000], loss: 0.08739 acc: 1.00000 val_loss: 0.15999, val_acc: 0.96667\n",
            "Epoch [8700/10000], loss: 0.08733 acc: 1.00000 val_loss: 0.15994, val_acc: 0.96667\n",
            "Epoch [8710/10000], loss: 0.08726 acc: 1.00000 val_loss: 0.15989, val_acc: 0.96667\n",
            "Epoch [8720/10000], loss: 0.08719 acc: 1.00000 val_loss: 0.15983, val_acc: 0.96667\n",
            "Epoch [8730/10000], loss: 0.08712 acc: 1.00000 val_loss: 0.15978, val_acc: 0.96667\n",
            "Epoch [8740/10000], loss: 0.08706 acc: 1.00000 val_loss: 0.15973, val_acc: 0.96667\n",
            "Epoch [8750/10000], loss: 0.08699 acc: 1.00000 val_loss: 0.15967, val_acc: 0.96667\n",
            "Epoch [8760/10000], loss: 0.08692 acc: 1.00000 val_loss: 0.15962, val_acc: 0.96667\n",
            "Epoch [8770/10000], loss: 0.08685 acc: 1.00000 val_loss: 0.15957, val_acc: 0.96667\n",
            "Epoch [8780/10000], loss: 0.08679 acc: 1.00000 val_loss: 0.15952, val_acc: 0.96667\n",
            "Epoch [8790/10000], loss: 0.08672 acc: 1.00000 val_loss: 0.15946, val_acc: 0.96667\n",
            "Epoch [8800/10000], loss: 0.08665 acc: 1.00000 val_loss: 0.15941, val_acc: 0.96667\n",
            "Epoch [8810/10000], loss: 0.08659 acc: 1.00000 val_loss: 0.15936, val_acc: 0.96667\n",
            "Epoch [8820/10000], loss: 0.08652 acc: 1.00000 val_loss: 0.15931, val_acc: 0.96667\n",
            "Epoch [8830/10000], loss: 0.08646 acc: 1.00000 val_loss: 0.15926, val_acc: 0.96667\n",
            "Epoch [8840/10000], loss: 0.08639 acc: 1.00000 val_loss: 0.15921, val_acc: 0.96667\n",
            "Epoch [8850/10000], loss: 0.08632 acc: 1.00000 val_loss: 0.15915, val_acc: 0.96667\n",
            "Epoch [8860/10000], loss: 0.08626 acc: 1.00000 val_loss: 0.15910, val_acc: 0.96667\n",
            "Epoch [8870/10000], loss: 0.08619 acc: 1.00000 val_loss: 0.15905, val_acc: 0.96667\n",
            "Epoch [8880/10000], loss: 0.08613 acc: 1.00000 val_loss: 0.15900, val_acc: 0.96667\n",
            "Epoch [8890/10000], loss: 0.08606 acc: 1.00000 val_loss: 0.15895, val_acc: 0.96667\n",
            "Epoch [8900/10000], loss: 0.08600 acc: 1.00000 val_loss: 0.15890, val_acc: 0.96667\n",
            "Epoch [8910/10000], loss: 0.08593 acc: 1.00000 val_loss: 0.15885, val_acc: 0.96667\n",
            "Epoch [8920/10000], loss: 0.08587 acc: 1.00000 val_loss: 0.15880, val_acc: 0.96667\n",
            "Epoch [8930/10000], loss: 0.08580 acc: 1.00000 val_loss: 0.15875, val_acc: 0.96667\n",
            "Epoch [8940/10000], loss: 0.08574 acc: 1.00000 val_loss: 0.15870, val_acc: 0.96667\n",
            "Epoch [8950/10000], loss: 0.08567 acc: 1.00000 val_loss: 0.15865, val_acc: 0.96667\n",
            "Epoch [8960/10000], loss: 0.08561 acc: 1.00000 val_loss: 0.15859, val_acc: 0.96667\n",
            "Epoch [8970/10000], loss: 0.08554 acc: 1.00000 val_loss: 0.15854, val_acc: 0.96667\n",
            "Epoch [8980/10000], loss: 0.08548 acc: 1.00000 val_loss: 0.15849, val_acc: 0.96667\n",
            "Epoch [8990/10000], loss: 0.08541 acc: 1.00000 val_loss: 0.15844, val_acc: 0.96667\n",
            "Epoch [9000/10000], loss: 0.08535 acc: 1.00000 val_loss: 0.15839, val_acc: 0.96667\n",
            "Epoch [9010/10000], loss: 0.08529 acc: 1.00000 val_loss: 0.15834, val_acc: 0.96667\n",
            "Epoch [9020/10000], loss: 0.08522 acc: 1.00000 val_loss: 0.15830, val_acc: 0.96667\n",
            "Epoch [9030/10000], loss: 0.08516 acc: 1.00000 val_loss: 0.15825, val_acc: 0.96667\n",
            "Epoch [9040/10000], loss: 0.08509 acc: 1.00000 val_loss: 0.15820, val_acc: 0.96667\n",
            "Epoch [9050/10000], loss: 0.08503 acc: 1.00000 val_loss: 0.15815, val_acc: 0.96667\n",
            "Epoch [9060/10000], loss: 0.08497 acc: 1.00000 val_loss: 0.15810, val_acc: 0.96667\n",
            "Epoch [9070/10000], loss: 0.08490 acc: 1.00000 val_loss: 0.15805, val_acc: 0.96667\n",
            "Epoch [9080/10000], loss: 0.08484 acc: 1.00000 val_loss: 0.15800, val_acc: 0.96667\n",
            "Epoch [9090/10000], loss: 0.08478 acc: 1.00000 val_loss: 0.15795, val_acc: 0.96667\n",
            "Epoch [9100/10000], loss: 0.08472 acc: 1.00000 val_loss: 0.15790, val_acc: 0.96667\n",
            "Epoch [9110/10000], loss: 0.08465 acc: 1.00000 val_loss: 0.15785, val_acc: 0.96667\n",
            "Epoch [9120/10000], loss: 0.08459 acc: 1.00000 val_loss: 0.15780, val_acc: 0.96667\n",
            "Epoch [9130/10000], loss: 0.08453 acc: 1.00000 val_loss: 0.15776, val_acc: 0.96667\n",
            "Epoch [9140/10000], loss: 0.08446 acc: 1.00000 val_loss: 0.15771, val_acc: 0.96667\n",
            "Epoch [9150/10000], loss: 0.08440 acc: 1.00000 val_loss: 0.15766, val_acc: 0.96667\n",
            "Epoch [9160/10000], loss: 0.08434 acc: 1.00000 val_loss: 0.15761, val_acc: 0.96667\n",
            "Epoch [9170/10000], loss: 0.08428 acc: 1.00000 val_loss: 0.15756, val_acc: 0.96667\n",
            "Epoch [9180/10000], loss: 0.08422 acc: 1.00000 val_loss: 0.15752, val_acc: 0.96667\n",
            "Epoch [9190/10000], loss: 0.08415 acc: 1.00000 val_loss: 0.15747, val_acc: 0.96667\n",
            "Epoch [9200/10000], loss: 0.08409 acc: 1.00000 val_loss: 0.15742, val_acc: 0.96667\n",
            "Epoch [9210/10000], loss: 0.08403 acc: 1.00000 val_loss: 0.15737, val_acc: 0.96667\n",
            "Epoch [9220/10000], loss: 0.08397 acc: 1.00000 val_loss: 0.15733, val_acc: 0.96667\n",
            "Epoch [9230/10000], loss: 0.08391 acc: 1.00000 val_loss: 0.15728, val_acc: 0.96667\n",
            "Epoch [9240/10000], loss: 0.08385 acc: 1.00000 val_loss: 0.15723, val_acc: 0.96667\n",
            "Epoch [9250/10000], loss: 0.08379 acc: 1.00000 val_loss: 0.15718, val_acc: 0.96667\n",
            "Epoch [9260/10000], loss: 0.08372 acc: 1.00000 val_loss: 0.15714, val_acc: 0.96667\n",
            "Epoch [9270/10000], loss: 0.08366 acc: 1.00000 val_loss: 0.15709, val_acc: 0.96667\n",
            "Epoch [9280/10000], loss: 0.08360 acc: 1.00000 val_loss: 0.15704, val_acc: 0.96667\n",
            "Epoch [9290/10000], loss: 0.08354 acc: 1.00000 val_loss: 0.15700, val_acc: 0.96667\n",
            "Epoch [9300/10000], loss: 0.08348 acc: 1.00000 val_loss: 0.15695, val_acc: 0.96667\n",
            "Epoch [9310/10000], loss: 0.08342 acc: 1.00000 val_loss: 0.15690, val_acc: 0.96667\n",
            "Epoch [9320/10000], loss: 0.08336 acc: 1.00000 val_loss: 0.15686, val_acc: 0.96667\n",
            "Epoch [9330/10000], loss: 0.08330 acc: 1.00000 val_loss: 0.15681, val_acc: 0.96667\n",
            "Epoch [9340/10000], loss: 0.08324 acc: 1.00000 val_loss: 0.15676, val_acc: 0.96667\n",
            "Epoch [9350/10000], loss: 0.08318 acc: 1.00000 val_loss: 0.15672, val_acc: 0.96667\n",
            "Epoch [9360/10000], loss: 0.08312 acc: 1.00000 val_loss: 0.15667, val_acc: 0.96667\n",
            "Epoch [9370/10000], loss: 0.08306 acc: 1.00000 val_loss: 0.15662, val_acc: 0.96667\n",
            "Epoch [9380/10000], loss: 0.08300 acc: 1.00000 val_loss: 0.15658, val_acc: 0.96667\n",
            "Epoch [9390/10000], loss: 0.08294 acc: 1.00000 val_loss: 0.15653, val_acc: 0.96667\n",
            "Epoch [9400/10000], loss: 0.08288 acc: 1.00000 val_loss: 0.15649, val_acc: 0.96667\n",
            "Epoch [9410/10000], loss: 0.08282 acc: 1.00000 val_loss: 0.15644, val_acc: 0.96667\n",
            "Epoch [9420/10000], loss: 0.08276 acc: 1.00000 val_loss: 0.15640, val_acc: 0.96667\n",
            "Epoch [9430/10000], loss: 0.08270 acc: 1.00000 val_loss: 0.15635, val_acc: 0.96667\n",
            "Epoch [9440/10000], loss: 0.08265 acc: 1.00000 val_loss: 0.15630, val_acc: 0.96667\n",
            "Epoch [9450/10000], loss: 0.08259 acc: 1.00000 val_loss: 0.15626, val_acc: 0.96667\n",
            "Epoch [9460/10000], loss: 0.08253 acc: 1.00000 val_loss: 0.15621, val_acc: 0.96667\n",
            "Epoch [9470/10000], loss: 0.08247 acc: 1.00000 val_loss: 0.15617, val_acc: 0.96667\n",
            "Epoch [9480/10000], loss: 0.08241 acc: 1.00000 val_loss: 0.15612, val_acc: 0.96667\n",
            "Epoch [9490/10000], loss: 0.08235 acc: 1.00000 val_loss: 0.15608, val_acc: 0.96667\n",
            "Epoch [9500/10000], loss: 0.08229 acc: 1.00000 val_loss: 0.15603, val_acc: 0.96667\n",
            "Epoch [9510/10000], loss: 0.08224 acc: 1.00000 val_loss: 0.15599, val_acc: 0.96667\n",
            "Epoch [9520/10000], loss: 0.08218 acc: 1.00000 val_loss: 0.15594, val_acc: 0.96667\n",
            "Epoch [9530/10000], loss: 0.08212 acc: 1.00000 val_loss: 0.15590, val_acc: 0.96667\n",
            "Epoch [9540/10000], loss: 0.08206 acc: 1.00000 val_loss: 0.15586, val_acc: 0.96667\n",
            "Epoch [9550/10000], loss: 0.08200 acc: 1.00000 val_loss: 0.15581, val_acc: 0.96667\n",
            "Epoch [9560/10000], loss: 0.08195 acc: 1.00000 val_loss: 0.15577, val_acc: 0.96667\n",
            "Epoch [9570/10000], loss: 0.08189 acc: 1.00000 val_loss: 0.15572, val_acc: 0.96667\n",
            "Epoch [9580/10000], loss: 0.08183 acc: 1.00000 val_loss: 0.15568, val_acc: 0.96667\n",
            "Epoch [9590/10000], loss: 0.08177 acc: 1.00000 val_loss: 0.15563, val_acc: 0.96667\n",
            "Epoch [9600/10000], loss: 0.08172 acc: 1.00000 val_loss: 0.15559, val_acc: 0.96667\n",
            "Epoch [9610/10000], loss: 0.08166 acc: 1.00000 val_loss: 0.15555, val_acc: 0.96667\n",
            "Epoch [9620/10000], loss: 0.08160 acc: 1.00000 val_loss: 0.15550, val_acc: 0.96667\n",
            "Epoch [9630/10000], loss: 0.08154 acc: 1.00000 val_loss: 0.15546, val_acc: 0.96667\n",
            "Epoch [9640/10000], loss: 0.08149 acc: 1.00000 val_loss: 0.15542, val_acc: 0.96667\n",
            "Epoch [9650/10000], loss: 0.08143 acc: 1.00000 val_loss: 0.15537, val_acc: 0.96667\n",
            "Epoch [9660/10000], loss: 0.08137 acc: 1.00000 val_loss: 0.15533, val_acc: 0.96667\n",
            "Epoch [9670/10000], loss: 0.08132 acc: 1.00000 val_loss: 0.15529, val_acc: 0.96667\n",
            "Epoch [9680/10000], loss: 0.08126 acc: 1.00000 val_loss: 0.15524, val_acc: 0.96667\n",
            "Epoch [9690/10000], loss: 0.08120 acc: 1.00000 val_loss: 0.15520, val_acc: 0.96667\n",
            "Epoch [9700/10000], loss: 0.08115 acc: 1.00000 val_loss: 0.15516, val_acc: 0.96667\n",
            "Epoch [9710/10000], loss: 0.08109 acc: 1.00000 val_loss: 0.15511, val_acc: 0.96667\n",
            "Epoch [9720/10000], loss: 0.08103 acc: 1.00000 val_loss: 0.15507, val_acc: 0.96667\n",
            "Epoch [9730/10000], loss: 0.08098 acc: 1.00000 val_loss: 0.15503, val_acc: 0.96667\n",
            "Epoch [9740/10000], loss: 0.08092 acc: 1.00000 val_loss: 0.15499, val_acc: 0.96667\n",
            "Epoch [9750/10000], loss: 0.08087 acc: 1.00000 val_loss: 0.15494, val_acc: 0.96667\n",
            "Epoch [9760/10000], loss: 0.08081 acc: 1.00000 val_loss: 0.15490, val_acc: 0.96667\n",
            "Epoch [9770/10000], loss: 0.08076 acc: 1.00000 val_loss: 0.15486, val_acc: 0.96667\n",
            "Epoch [9780/10000], loss: 0.08070 acc: 1.00000 val_loss: 0.15482, val_acc: 0.96667\n",
            "Epoch [9790/10000], loss: 0.08064 acc: 1.00000 val_loss: 0.15477, val_acc: 0.96667\n",
            "Epoch [9800/10000], loss: 0.08059 acc: 1.00000 val_loss: 0.15473, val_acc: 0.96667\n",
            "Epoch [9810/10000], loss: 0.08053 acc: 1.00000 val_loss: 0.15469, val_acc: 0.96667\n",
            "Epoch [9820/10000], loss: 0.08048 acc: 1.00000 val_loss: 0.15465, val_acc: 0.96667\n",
            "Epoch [9830/10000], loss: 0.08042 acc: 1.00000 val_loss: 0.15461, val_acc: 0.96667\n",
            "Epoch [9840/10000], loss: 0.08037 acc: 1.00000 val_loss: 0.15456, val_acc: 0.96667\n",
            "Epoch [9850/10000], loss: 0.08031 acc: 1.00000 val_loss: 0.15452, val_acc: 0.96667\n",
            "Epoch [9860/10000], loss: 0.08026 acc: 1.00000 val_loss: 0.15448, val_acc: 0.96667\n",
            "Epoch [9870/10000], loss: 0.08020 acc: 1.00000 val_loss: 0.15444, val_acc: 0.96667\n",
            "Epoch [9880/10000], loss: 0.08015 acc: 1.00000 val_loss: 0.15440, val_acc: 0.96667\n",
            "Epoch [9890/10000], loss: 0.08009 acc: 1.00000 val_loss: 0.15436, val_acc: 0.96667\n",
            "Epoch [9900/10000], loss: 0.08004 acc: 1.00000 val_loss: 0.15432, val_acc: 0.96667\n",
            "Epoch [9910/10000], loss: 0.07999 acc: 1.00000 val_loss: 0.15427, val_acc: 0.96667\n",
            "Epoch [9920/10000], loss: 0.07993 acc: 1.00000 val_loss: 0.15423, val_acc: 0.96667\n",
            "Epoch [9930/10000], loss: 0.07988 acc: 1.00000 val_loss: 0.15419, val_acc: 0.96667\n",
            "Epoch [9940/10000], loss: 0.07982 acc: 1.00000 val_loss: 0.15415, val_acc: 0.96667\n",
            "Epoch [9950/10000], loss: 0.07977 acc: 1.00000 val_loss: 0.15411, val_acc: 0.96667\n",
            "Epoch [9960/10000], loss: 0.07972 acc: 1.00000 val_loss: 0.15407, val_acc: 0.96667\n",
            "Epoch [9970/10000], loss: 0.07966 acc: 1.00000 val_loss: 0.15403, val_acc: 0.96667\n",
            "Epoch [9980/10000], loss: 0.07961 acc: 1.00000 val_loss: 0.15399, val_acc: 0.96667\n",
            "Epoch [9990/10000], loss: 0.07955 acc: 1.00000 val_loss: 0.15395, val_acc: 0.96667\n"
          ]
        }
      ],
      "source": [
        "# 繰り返し計算メインループ\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # 訓練フェーズ\n",
        "    \n",
        "    #勾配値初期化\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 予測計算\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # 損失計算\n",
        "    loss = criterion(outputs, labels1)\n",
        "\n",
        "    # 勾配計算\n",
        "    loss.backward()\n",
        "    \n",
        "    # パラメータ修正\n",
        "    optimizer.step()\n",
        "\n",
        "    # 損失のスカラー化\n",
        "    train_loss = loss.item()\n",
        "\n",
        "    # 予測ラベル(1 or 0)計算\n",
        "    predicted = torch.where(outputs < 0.0, 0, 1)\n",
        "    \n",
        "    # 精度計算\n",
        "    train_acc = (predicted == labels1).sum() / len(y_train)\n",
        "\n",
        "    # 予測フェーズ\n",
        "    \n",
        "    # 予測計算\n",
        "    outputs_test = net(inputs_test)\n",
        "\n",
        "    # 損失計算\n",
        "    loss_test = criterion(outputs_test, labels1_test)\n",
        "\n",
        "    # 損失のスカラー化\n",
        "    val_loss =  loss_test.item()\n",
        "        \n",
        "    #予測ラベル(1 or 0)計算\n",
        "    predicted_test = torch.where(outputs_test < 0.0, 0, 1)\n",
        "\n",
        "    # 精度計算\n",
        "    val_acc = (predicted_test == labels1_test).sum() / len(y_test)\n",
        "    \n",
        "    if ( epoch % 10 == 0):\n",
        "        print (f'Epoch [{epoch}/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n",
        "        item = np.array([epoch, train_loss, train_acc, val_loss, val_acc])\n",
        "        history = np.vstack((history, item))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-k1KOgubPsqq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "初期状態: 損失: 4.49384 精度: 0.50000\n",
            "最終状態: 損失: 0.15395 精度: 0.96667\n"
          ]
        }
      ],
      "source": [
        "#損失と精度の確認\n",
        "\n",
        "print(f'初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
        "print(f'最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "JNkolGE1Psqr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 23398 (\\N{CJK UNIFIED IDEOGRAPH-5B66}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 32722 (\\N{CJK UNIFIED IDEOGRAPH-7FD2}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 32218 (\\N{CJK UNIFIED IDEOGRAPH-7DDA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 25613 (\\N{CJK UNIFIED IDEOGRAPH-640D}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 22833 (\\N{CJK UNIFIED IDEOGRAPH-5931}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 32368 (\\N{CJK UNIFIED IDEOGRAPH-7E70}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 12426 (\\N{HIRAGANA LETTER RI}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 36820 (\\N{CJK UNIFIED IDEOGRAPH-8FD4}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 12375 (\\N{HIRAGANA LETTER SI}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 22238 (\\N{CJK UNIFIED IDEOGRAPH-56DE}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 35347 (\\N{CJK UNIFIED IDEOGRAPH-8A13}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 32244 (\\N{CJK UNIFIED IDEOGRAPH-7DF4}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 26908 (\\N{CJK UNIFIED IDEOGRAPH-691C}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 35388 (\\N{CJK UNIFIED IDEOGRAPH-8A3C}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 学習曲線の表示 (損失)\n",
        "\n",
        "plt.plot(history[:,0], history[:,1], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,3], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('損失')\n",
        "plt.title('学習曲線(損失)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "L6JFhi1DPsqr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 23398 (\\N{CJK UNIFIED IDEOGRAPH-5B66}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 32722 (\\N{CJK UNIFIED IDEOGRAPH-7FD2}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 32218 (\\N{CJK UNIFIED IDEOGRAPH-7DDA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 31934 (\\N{CJK UNIFIED IDEOGRAPH-7CBE}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 32368 (\\N{CJK UNIFIED IDEOGRAPH-7E70}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 12426 (\\N{HIRAGANA LETTER RI}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 36820 (\\N{CJK UNIFIED IDEOGRAPH-8FD4}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 12375 (\\N{HIRAGANA LETTER SI}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 22238 (\\N{CJK UNIFIED IDEOGRAPH-56DE}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 35347 (\\N{CJK UNIFIED IDEOGRAPH-8A13}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 32244 (\\N{CJK UNIFIED IDEOGRAPH-7DF4}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 26908 (\\N{CJK UNIFIED IDEOGRAPH-691C}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "C:\\Users\\Takanori\\MiniConda3\\envs\\yourenvname\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 35388 (\\N{CJK UNIFIED IDEOGRAPH-8A3C}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAGPCAYAAACZCD2BAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjqElEQVR4nO3de5Sdd13v8fd3JpkkpWmChE5vJ7ZS23I7JzVBSKElKNEu8IIt59CDy9rj0t4ExR7OggpiVRaoSG0FKwY59uLxFA8uFXqAloNOQVouCaKthNpzCMWkJG1qUzpJ5v47fzx7d3b27OeZZ2bPPHtn7/drrVl75rn+fpPJ89m/y/PsSCkhSVI7BjpdAEnS8c8wkSS1zTCRJLXNMJEktc0wkSS1zTCRJLXNMJG6SERcGhHfjYj1y3iOr0TE7y7X8dWfwvtMpO4QEYPAA8AnUkpvW8bzXALcATwvpbR/uc6j/mKYqC9ExH8AvgJM5GwyBLyk5DYs5XYppX+slfEngb8mu8h/s7bs/cC1wHSL/QPYnVLaUna72jEHgH3An6SUfi2nbNKC2M2lfhHAfSmlE1t9AfctYJul3q7u54Cd9SCpGQSuydn/hcCKBW5HSmkG+Bjws7VgkdrmH5LUBSJiNXAx8JmKTvkZ4N8Bmys6n3qcYSJ1h81k3V47Kzrfrtrryys6n3qcYSJ1h/Nqr98s3GqJpJT2kY3lvKCK86n3GSZSd3hO7fXJCs/5JLChwvOphxkmUneJ+TdZ0nM5nVNLwjCRusPB2uuzKzzn+obzSm0xTKTusLv2elYVJ4uI08kG/HfPt61UhmEidYddwBiwpaLz1acE31fR+dTjDBOpC6SUJoBPA9srOuV2YC/VTUVWjzNMpO7x34EtEbGsXV21u95fD9xeuxteapthInWP/002hnH1Mp/ndcA64IPLfB71EcNE6hK1VsKvAdcs5yPogeuBD6aUvrOM51CfWTH/JlLPeEVEHMpZd+ICtlmO7QBIKf0l8JdNi2+JiJta7D/AsXfMl9oupfSSFttIbfER9JKkttnNJUlqm2EiSWpbz46ZbNiwIZ155pmL3v/w4cM861nPWroCdbl+qy9Y535hnRdm165dB1NKz13ofj0bJmeeeSY7dy7+fqyRkRG2bdu2dAXqcv1WX7DO/cI6L0xEPLKY/ezmkiS1zTCRJLXNMJEktc0wkSS1zTCRJLXNMJEktc0wkSS1zTCRJLXNMJEkta3SMImIiyLi4xGxLyJSRFxRYp8XR8S9EXG0tt+7IiIqKK4kqaSqWyYnAg8CvwwcnW/jiDgJ+AxwAHhJbb//Bly3jGWUJC1Qpc/mSil9EvgkQETcWmKXnwZOAH42pXQUeDAizgOui4gbUxd9GMuuXfDYY50uxeL90z99D0fnjffeYp37Qz/Wed++E6n6cWTd/qDHrcDna0FSdzfwW8CZwJ7GjSPiSuBKgOHhYUZGRhZ94tHR0dL7P/nkSi699AJSOp573/59pwvQAda5P/RfnS+88FTOPnuk0nN2e5icAuxtWnagYd0xYZJS2gHsANiyZUtq50mhC3nq5gMPQErw3vfCq1616FN21K5du9i8eXOni1Ep69wf+rHODz+8t/InJXd7mBwXDh3KXrdsgZe+tKNFWbSjR58+bsu+WNa5P/Rnnavv1+v2qcH7geGmZcMN67pCPUzWr+9kKSSpc7o9TO4HLoyI1Q3LtgOPAt/qSImafP7z8Dd/k31vmEjqV1XfZ3JiRGyKiE21c2+s/byxtv69EfHZhl3+HDgC3BoRL4qIS4C3A10zk+snfxI+8hE48UQ45ZROl0aSOqPqlskW4B9qX2uA36h9/5u19acCz6tvnFJ6iqwlchqwE/hD4P3AjdUVOd/UFDz5JLz1rfDoo1mgSFI/qvo+kxEgd/5sSumKFsseAC5avlIt3lNPZa9nnAFr13a2LJLUSd0+ZtLV6mHiWImkfmeYtOHOO7NXw0RSvzNM2rBjR/Z63nmdLYckdZo3LbZhagp+7ufg3HMXt//ExASvfOUrefTRR5e2YIswPj7OqlWrOl2MSlnn/tCPdf6BH/gB74A/noyNwerV82+X57HHHuOLX/wiF1xwAeecc87SFWwR9u/fzyl9NrfZOveHfqzz+g70vRsmbWg3TMbHxwG46qqruPzyy5eoVIuzkGeR9Qrr3B/6tc5Vc8ykDUsVJv3WBJfUewyTRZqagulpw0SSwDBZtLGx7NUwkSTDZNFqObAkYTI0NLQEJZKkzjFMFmkpWiYTExOALRNJxz/DZBEefhh+5mey7+3mkiTDZFE++1n4u7+Diy6CrVsXfxzDRFKv8D6TRah/suKnPw1r1iz+OIaJpF5hmCzCoUOwcuUB/uAPbmN6emrRx/nqV78KGCaSjn+GySIcOgSrVt3B29/+traPtWHDBjZs2NB+oSSpgwyTRcjC5Aijo3DkyBEGBwcXfazBwcG29pekbmCYLMKhQzA0NM7g4CBr2hk0kaQe4WyuRaiHiWMdkpQxTBYhG4A3TCSpzjBZhEOHYMUKw0SS6gyTRTh0CAYHDRNJqjNMFmhsLHvI4+DghA9olKQaw2SB6ne/R9gykaQ6w2SBnnoqezVMJGmWYbJA9ZbJ0aNPGCaSVGOYLFAWJp/hoYe+xIoV3vMpSWCYLFgWJnsAuP766ztZFEnqGobJAmVhkj06fvPmzZ0siiR1DcNkgbIw8eN2JamRYbJA3/xmNpMLDBNJqjNMFui222bDxJsWJSljmCzQ6tWwceM4Q0NDRESniyNJXcEwWaDJSXjOc7xhUZIaGSYLkFL2bC4Yt4tLkhoYJgswNQUzMwATtkwkqYFhsgBZqwRSsptLkhoZJgtgmEhSa4bJAhgmktSaYbIA9TCZnjZMJKmRYbIA//qv2evMjLO5JKmRYbIAn/pU9jo46GwuSWpkmCzAkSOwZg2sXGk3lyQ1MkwW4NAhOPVUGB83TCSpkWGyAIcOwfr1hokkNTNMFsAwkaTWDJMFePppWLvWMJGkZobJAoyNZQPwExMTTg2WpAaGyQKMjcHg4ChPPvmkLRNJamCYLMDYGDz44A0AbNiwobOFkaQuYpgswNgYTE4+AcCv/MqvdLg0ktQ9DJMFqH8w1tlnn203lyQ1MExKmp7OPrLXJwZL0lyGSUnj49lrSj7kUZKaGSYlzX6WiQ95lKRmhklJ9TCZmbGbS5KaGSYlTUxkr34wliTNVXmYRMS1EbEnIsYiYldEXDjP9m+MiK9FxJGI2B8RfxYRp1RV3rqpqfqrYSJJzSoNk4h4A3Az8B7gfOA+4FMRsTFn+5cDdwC3AS8EXge8APgfVZS3UT1MbJlI0lxVt0yuA25NKX04pbQ7pfRm4DvANTnbbwX2ppR+P6W0J6X0ReADwEsrKu8zGlsmzuaSpGNVFiYRMQRsBu5pWnUPcEHObl8ATo2IH4/MBuAy4JPLV9LWZsPE2VyS1GxFhefaAAwCB5qWHwBe3WqHlNL9EXEZWbfWGrLyfgb42VbbR8SVwJUAw8PDjIyMLLqwo6Ojx+z/0ENrgc2MjR3miSeeaOvY3ai5vv3AOvcH61yNKsNkwSLiBWTdWr8F3A2cCrwP+GPg8ubtU0o7gB0AW7ZsSdu2bVv0uUdGRmjcf82a+jmmOeuss2jn2N2oub79wDr3B+tcjSrD5CAwDQw3LR8G9ufscz3w5ZTS+2o//1NEHAY+HxG/mlLauzxFnavezTU56QC8JDWrbMwkpTQB7AK2N63aTjarq5UTyAKoUf3nSicPZGGSDBNJaqHqbq4bgTsi4stkg+tXA6cBHwKIiNsBUkr1LqxPAB+OiGuY7ea6CfhqSunbVRY8C5NJAGdzSVKTSsMkpfTRiHgO8E6yYHgQeE1K6ZHaJhubtr81ItYCbwLeDzwF/C3wtupKncnCJLsN3paJJB2r8gH4lNItwC0567a1WPYBskH4jsrCJHt0sGEiScfy2VwlGSaSlM8wKckwkaR8hklJhokk5TNMSmoME2dzSdKxDJOSnM0lSfkMk5Ls5pKkfIZJSYaJJOUzTEoyTCQpn2FSkmEiSfkMk5IME0nKZ5iU5NRgScpnmJTk1GBJymeYlGQ3lyTlM0xKmpqCCMNEkloxTEqamoKBAcNEkloxTEpqbJk4AC9JxzJMSqq3TFauXElEdLo4ktRVKv+kxeNV1jKZYGjILi5JambLpKR6y8TxEkmayzApqT5mYphI0lyGSUn1+0wME0mayzApyZaJJOUzTEqqt0ycFixJcxkmJdWfzWXLRJLmMkxKcsxEkvIZJiUZJpKUzzApaXJyhsOH7zNMJKkFw6Skw4f3AjA4ONjhkkhS9zFMSpqcnAHgkksu6XBJJKn7GCYlTU9nYeJDHiVpLsOkpKmpBMDAgL8ySWrmlbGkqamsZWKYSNJcXhlLMkwkKZ9XxpLqYeKYiSTNZZiUND3tmIkk5fHKWJLdXJKUzytjSU4NlqR8hklJTg2WpHxeGUuqt0wME0mayytjSYaJJOXzyliSU4MlKZ9hUpJTgyUpn1fGkuzmkqR8XhlLcmqwJOUzTEpIyW4uSSrilbGEmRkAu7kkKY9XxhKmpsAwkaR8XhlLaAwTx0wkaS7DpIQsTBwzkaQ8XhlLsJtLkop5ZSzBbi5JKmaYlGA3lyQV88pYgt1cklTMK2MJdnNJUjHDpARbJpJUzCtjCY6ZSFIxr4wl2DKRpGKVXxkj4tqI2BMRYxGxKyIunGf7oYj4zdo+4xHx7Yj4parKC46ZSNJ8VlR5soh4A3AzcC3w97XXT0XEC1JK387Z7U7gDOBK4GFgGFhTQXGfYTeXJBWrNEyA64BbU0ofrv385oi4GLgGuL5544j4EeCHgeellA7WFn+rioI2sptLkopVdmWMiCFgM3BP06p7gAtydnsd8BXguojYGxEPR8QfRMSJy1fSuezmkqRiVbZMNgCDwIGm5QeAV+fs833AK4Bx4FJgPfAB4DTg9c0bR8SVZN1hDA8PMzIysujCjo6OPrP/rl3rqXdz7dy5k8cee2zRx+1WjfXtF9a5P1jnalTdzbVQA2RX8TemlJ4CiIg3AXdHxHBK6ZhgSintAHYAbNmyJW3btm3RJx4ZGaG+//g4wNcBeNnLXsY555yz6ON2q8b69gvr3B+sczWqHAA4CEyTDaA3Ggb25+zzHWBfPUhqdtdeNy5t8fI5ZiJJxSq7MqaUJoBdwPamVduB+3J2+wJwWtMYSb1Z8MjSljCfYyaSVKzqt9k3AldExM9HxPMj4may8Y8PAUTE7RFxe8P2fw48AfxpRLwwIl5ONrX4YymlygYunBosScUqHTNJKX00Ip4DvBM4FXgQeE1Kqd7K2Ni0/WhEvJps0P0rwJPAXwNvr6zQ2M0lSfOZN0wi4rQy2zUYbx4Yb5RSugW4JWfdthbLHgJ+ZAHnX3J2c0lSsTIh8bfAV4GyV9HnAT+46BJ1Ibu5JKlYmTA5mlJ6Y9kDRsRX2ihPV7KbS5KKlbkypgUec6Hbdz3DRJKKeWUswTETSSpmmJTQOGZimEjSXMsRJj13tc3CZBqAFSu6/Qk0klS9MlfGiYjIu0O9lccXW5hulYXJFACDg4MdLYskdaMyYbIHOGUBx6zsMSdVsWUiScXKXBnPBV5Gue6rAD7XVom6kC0TSSpWJkyi9pDGUqIHR6inpiBimpRsmUhSK95nUkIWJrZMJCmPU4NLmJqCgYFpIsKpwZLUgn02JcyGib8uSWqlzNVxTUS8q+TxevJte72ba2DALi5JaqVMmFwFrFnAMe9eZFm6Vr1lMjhoy0SSWpn36phS6rmpvgtVb5k4+C5JrTkAX8Jsy8QwkaRWDJMS6i0T7zGRpNYMkxLqNy3aMpGk1gyTEuphYstEklozTEpwAF6SihkmJdgykaRihkkJ09MAtkwkKY9hUoID8JJUzDApwW4uSSpmmJRQ/3AsWyaS1JpvtZvs3z/Kxz/+AA899C0mJx9m+/bvf+Zje22ZSFJrXh2b3H33bq666gIAbrxxgG984wBTUxuwZSJJ+ezmavKqV53Du9/9ac455xeAGR5/fNQxE0mah2HSZOPGdbzjHT/K2WefBcDU1AxTU5CSLRNJymOY5BgYyH41MzPpmTETw0SSWjNMctSyhOnpGQfgJWkehkmOiOwTiGdbJnZzSVIewyTHbJjUx0xsmUhSHsMkR33MZHralokkzccwyVFrmBzTMjFMJKk1wyRHc8skJT+2V5LyGCY5bJlIUnmGSY65YyYOwEtSHsMkR3PLZGbGAXhJymOY5KhPDZ4dM7FlIkl5DJMcAwNZmExNzZCSz+aSpCKGSY76mMnExAwAMzMOwEtSHsMkR33MZHIyAXZzSVIRwyRHvWUyOVlvmdjNJUl5DJMctkwkqTzDJEd9AL4+ZjI9bctEkvIYJjnqU4MbWyaGiSS1ZpjkqLdMsjGTGVJKdnNJUg7DJMfsAHwCpgFsmUhSDsMkR/1je7OWSRYmtkwkqTXDJMexYyZTgC0TScpjmOQ4dszElokkFTFMctTHTKambJlI0nwMkxyzNy3OtkwME0lqzTDJMTjYOGZiN5ckFTFMcswOwM9gN5ckFTNMctQH4KenbZlI0nwqD5OIuDYi9kTEWETsiogLS+73ioiYiogHl7uMtfMB2Ydj2TKRpGKVhklEvAG4GXgPcD5wH/CpiNg4z37PBm4HPrvshayxZSJJ5VXdMrkOuDWl9OGU0u6U0puB7wDXzLPfR4DbgPuXu4B19Tvgp6dtmUjSfCoLk4gYAjYD9zStuge4oGC/a4Fh4N3LV7q56veZNLZMDBNJaq3KfpsNwCBwoGn5AeDVrXaIiBcDvw68LKU0XR/HyBMRVwJXAgwPDzMyMrLowk5MjAFw8OATwFkA7N69u61jdrPR0dGerVse69wfrHM1unYQICJWAR8F3ppS2lNmn5TSDmAHwJYtW9K2bdsWff7PfW4/ACedtJ56N9emTZto55jdbGRkpGfrlsc69wfrXI0qw+QgWX/RcNPyYWB/i+1PBZ4P/GlE/Glt2QAQETEFvCal1NxltmRmB+B9NpckzaeyMZOU0gSwC9jetGo72ayuZvuAFwObGr4+BPzf2vet9lkyx87mcgBekopU/Vb7RuCOiPgy8AXgauA0spAgIm4HSCldnlKaBI65pyQiHgPGU0rLfq9Jq5aJYSJJrVUaJimlj0bEc4B3knVjPUjWXfVIbZPC+02qVA+TxpsW7eaSpNYqvzqmlG4BbslZt22efW8AbljyQrVQv89kZsapwZI0H5/NlWP2PhMH4CVpPoZJjvotLQ7AS9L8DJMcTg2WpPIMkxyDg9mvJhszsWUiSUUMkxyz3VxODZak+RgmOerdXI2zuezmkqTWDJMc9c+An5nxEfSSNB/DJEf9CcV+OJYkzc8wyVFvmfjhWJI0P8MkR6sxE8NEklozTHLMPk7FZ3NJ0nwMkxzHPoLelokkFfGtdo5j7zNJgC0TScpjyyTHihXeAS9JZRkmOepjJj6bS5LmZ5jkqOeGTw2WpPkZJjlmpwb7bC5Jmo9hkqO5ZTIwMPDMXfGSpGMZJjkGnvnNzBAxbatEkgoYJjnqs7kgETHt4LskFTBMctTHTLKWyZQtE0kqYJjkmB0fsWUiSfMxTHLMhoktE0maj2GSozFMBgcdgJekIoZJocBuLkman2FSaACYYWDAbi5JKmKYFBoAEgMDdnNJUhHDpFCQDcBPMDQ01OnCSFLXMkwKZS0TGGfVqlWdLowkdS3DpJAtE0kqwzApEGHLRJLKMEwKZS2TlAwTSSpimBSyZSJJZRgmBbK74G2ZSNJ8DJNCWcvEMJGkYoZJgdmWibO5JKmIYVIoa5nMzNgykaQihkmhrGVimEhSMcOkQP0+k5kZu7kkqYhhUqg+ZjLlI+glqYBhUqDeMknJpwZLUhHDpFB9zMSWiSQVMUwKDAxkH46V0owtE0kqYJgUyO4zmQKwZSJJBQyTAtmYySSALRNJKmCYFBgYCOphYstEkvJ5hSywatUAhw/bMpF6wczMDAcPHuTQoUNMT093ujjLat26dezevXvO8sHBQdavX8+GDRtqY8JLxzAp8OxnB+eeO8n99xsm0vFu7969RARnnnkmK1eurI2J9qann36atWvXHrMspcTk5CQHDhxg7969bNy4cUnPaTdXgcHBAU44wW4uqRccPnyY008/naGhoZ4OkjwRwdDQEKeffjqHDx9e8uMbJgUigslJu7mkXrHUXTvHo+X6HfibLTAwMPBMmNgykaR8hkmBxjCxZSJJ+QyTAo3dXLZMJCmfV8gCtkwkddK9997LVVddxerVq+esO++889izZw/j4+Nz1o2OjjIyMsIZZ5xRRTEBw6RQRDA1lT1OxTCRVLWjR49y2WWXccMNNxyzfGxsjIsvvpiI4Gtf+9qc/S699NJnrl1VsZurgAPwklSOV8gCTg2Wettb3gIt3tgvq02b4Kabqj1nFSpvmUTEtRGxJyLGImJXRFxYsO0lEXFPRDweEU9HxJci4ieqKqstE0kqp9IrZES8AbgZuBb4+9rrpyLiBSmlb7fY5ZXA3wLvBP4N+GngryJiW0rp8xWU15aJ1MN6sYXQKVW/3b4OuDWl9OHaz2+OiIuBa4DrmzdOKf1y06LfiIjXAq8Dlj1MnM0lSeVU1s0VEUPAZuCeplX3ABcs4FBrgSeXqlxFIoKnn34asJtLkopUeYXcAAwCB5qWHwBeXeYAEfGLwBnAHTnrrwSuBBgeHmZkZGSxZWV0dJTR0dFnfn788cfbOl63q89L7yfWuT/U67xu3bpn3hweL44cOcL4+Picco+NjTE9Pc309HTLOqWUGB0dza3v2NjYkv8dHDdvtyPiUuB9wBtSSo+02ialtAPYAbBly5a0bdu2RZ9vZGSEk08+GYDnPve5XHbZZYs+1vFgZGSEdn5fxyPr3B/qdd69e/ecx7J3uxNOOIFVq1bNKffKlSsZHBxkcHCwZZ0ighNPPDG3vqtXr+b8889f0rJWOZvrIDANDDctHwb2F+0YEa8na41cnlL6xPIUb65Vq1Yd8ypJaq2yMEkpTQC7gO1Nq7YD9+XtFxH/iSxIrkgpfWz5SjiXYSJJ5VTdzXUjcEdEfBn4AnA1cBrwIYCIuB0gpXR57efLyILkrcDnIuKU2nEmUkr/ttyFNUwkddK6deu46667uOuuu+as27x5M4888ghbtmyZs25mZqby61alYZJS+mhEPIfsvpFTgQeB1zSMgTR/juTVZGW8qfZVdy+wbTnLCjA0NHTMqyRVaevWrezcuXPB+7X62N7lVvkAfErpFuCWnHXbin6umi0TSSrHBz0WMEwkqRzDpIBhIknlGCYFDBNJKscwKVAPkZUrV3a4JJLU3QyTAs7ikqRyDJMCdm9JUjnHzbO5OqEeJhHR4ZJI6kf33nsvV111FatXr56z7rzzzmPPnj2Mj4/PWVd/uOUZZ5xRRTEBw6SQLRNJnXT06FEuu+wybrjhhmOWj42NcfHFFxMRfK3F5w5feumlTE1NVVPIGru5ChgmklSOLZMC9TBJKXW4JJKWw1ve8paW7+yX06ZNm7ipBz8v2JZJgYEBfz2SVIYtE0l9qxdbCJ3iW+8C9VlczuaSpGKGiSSpbYaJJKlthkmB+gD84OBgh0siSd3NMCnw2te+lquvvpqbb76500WRpK7mbK4CQ0ND/NEf/VGniyFJXc8wkaQutW7dOu666y7uuuuuOes2b97MI488wpYtW+asm5mZqfwJHoaJJHWprVu3snPnzgXv9/TTT7N27dplKFE+x0wkSW0zTCT1DZ+zt3y/A8NEUl9YuXIlR48e7XQxOu7o0aPL8lHkhomkvnDyySezb98+jhw50pctlJQSR44cYd++fZx88slLfnwH4CX1hZNOOgmARx99lMnJyQ6XZnmNjY21/HTGlStXMjw8/MzvYikZJpL6xkknnbQsF9JuMzIywvnnn1/pOe3mkiS1zTCRJLXNMJEktc0wkSS1zTCRJLUtenW+dUQ8DjzSxiE2AAeXqDjHg36rL1jnfmGdF+Z7U0rPXehOPRsm7YqInSmluY/j7FH9Vl+wzv3COlfDbi5JUtsME0lS2wyTfDs6XYCK9Vt9wTr3C+tcAcdMJElts2UiSWqbYSJJapth0iQiro2IPRExFhG7IuLCTpepjIi4PiK+EhHfjYjHI+ITEfGipm0iIm6IiEcj4mhEjETEC5u2eXZE3BERT9W+7oiI9U3bvDgi7q0dY19EvCsiooJq5qrVP0XEBxuW9WR9I+LUiLit9u88FhFfj4hXNqzvqXpHxGBE/FbD/8s9EfHuiFjRsM1xXeeIuCgiPl47Z4qIK5rWV1a/iLi09jc1Xnv9qVKVSCn5VfsC3gBMAr8APB/4ADAKbOx02UqU/W7gvwAvAl4M/BWwH/iehm3eBjwNXFrb7i+AR4G1Ddt8CvhnYGvt65+BTzSsP6l23L+oHeP1tWP+1w7W/WXAHuAfgQ/2cn2B9cA3gduBHwTOAn4YeH6v1hv4VeDfgB8HzgR+AngS+LVeqTPwGuA9tXMeAa5oWl9J/Wr7TQHvILsGvqP280vnrUMn/kN06xfwJeDDTcseBt7b6bItoi4nAtPAj9d+DuA7wDsatllT+2O6qvbz84EEvLxhm1fUlp1b+/ka4LvAmoZt3gnsozaho+J6rgP+H/AqYIRamPRwfd8DfKFgfc/VG7gLuK1p2W3AXb1YZ7I3sFd04t8U+Cjwmaby/B/gf85Xbru5aiJiCNgM3NO06h7ggupL1La1ZN2YT9Z+Pgs4hYb6pZSOAp9jtn5byf6Q72s4zheAw03bfL62b93dwGlk7xqrtgP4WErp75qW92p9Xwd8KSI+GhGPRcTXIuJNDV0VvVjvvwdeFRHnAUTEC4AfAj5ZW9+LdW5UZf22MvcaeDclroGGyawNwCBwoGn5AbJ/yOPNzcDXgPtrP9frUFS/U4DHU+3tCEDt+8eatml1jMZzVCIifgE4m+zdVbOeq2/N9wHXknV1/SjZv/NvA7/YVKZeqvfvAHcAX4+ISbLum9tSSrc0laeX6tyoyvrlbTNv/f3Y3h4UETeSNXFfkVKa7nR5lkNEnEvW5fOKlFJvf6D3sQaAnSml62s//0NEfD9ZmHwwf7fj2huAy4E3kgXJJuDmiNiTUvpIJwumWbZMZh0kG2MYblo+TDZodVyIiN8H/jPwQymlbzasqtehqH77gec2zu6ofX9y0zatjtF4jipsJWtN/nNETEXEFPBK4Nra9080lY2Gn4/H+tZ9B/h607LdwMba97327wzwPuD3Ukp3ppQeSCndAdwI1AO1F+vcqMr65W0zb/0Nk5qU0gSwC9jetGo7x/ZDdq2IuJnZIPlG0+o9ZH8Q2xu2Xw1cyGz97icbuN/asN9W4FlN21xY27duO9nMkm8tSUXK+WuyWWubGr52AnfWvv8Xequ+dV8Azm1adg6zH7fQa//OACeQvdFrNM3s9asX69yoyvrdz2KvgVXNUDgevsia0xPAz5PNjriZbFDreztdthJl/0OymRo/RNa/Wf86sWGbtwFPAZeQTQ28k9bTCx9gdnrhAxw7vXAd2R/2nbVjXFI7b8emBjeUbYS5U4N7qr7AS8imr7+DbLzoP9bq+Iu9Wm/gVmAv8FqygeKfAh4H3t8rdSYLgk21ryPAu2rfb6yyfmQD7VPA24HzyFp/kzg1eFH/qNeSpfQ4WUvlok6XqWS5U87XDQ3bBHADWVfJGHAv8KKm4zwb+LPaH9l3a9+vb9rmxWQzScZqx/p1OjBNtsXvYIRjw6Qn60t2Uf3HWnn+BfilxvL0Wr3JZibeRNb6Oko2+eA9wOpeqTOwLef/761V14/s/pNvkL2x3g1cUqYOPuhRktQ2x0wkSW0zTCRJbTNMJEltM0wkSW0zTCRJbTNMJEltM0wkSW3zQY9Sk8g+tfCPyW7savYNskeCr2qx7gSyJxD8NPAzZHcSN1oB/AnwCbK7lY+0OMZ3U0oXRcRf1c7TbDVwBfA8srvgJ5rWDwD3pJTe2mJfadkYJtJca4A7U0o3NC6sPdPo02RP997UvFNE3En2f+rZwJtSSiNN6y8m+1TIlcB9KaUrWhzji7VvT805x2+TBcpa4HdTSrc2rT+P7FEYUqXs5pIktc0wkSS1zTCRJLXNMJEktc0wkSS1zTCRJLXNMJEktc0wkSS1zTCRJLXNMJEktc3HqUhzPQX8WET8WIt1u4DvjYidOfuOA3uB34uIVut3AEeBF+Uc49Ha6+6Cc/wv4DHgVyPiTS3WfyJnP2nZREqp02WQJB3n7OaSJLXNMJEktc0wkSS1zTCRJLXNMJEktc0wkSS17f8DLO+DUHDSdcYAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 学習曲線の表示 (精度)\n",
        "\n",
        "plt.plot(history[:,0], history[:,2], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,4], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('精度')\n",
        "plt.title('学習曲線(精度)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "FQC_gdBRPsqr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BIAS = [0.33861253], WEIGHT = [[ 2.970032  -5.3000145]]\n",
            "xl = [4.4 7. ]  yl = [2.52956916 3.986562  ]\n"
          ]
        }
      ],
      "source": [
        "# パラメータの取得\n",
        "\n",
        "bias = net.l1.bias.data.numpy()\n",
        "weight = net.l1.weight.data.numpy()\n",
        "print(f'BIAS = {bias}, WEIGHT = {weight}')\n",
        "\n",
        "# 決定境界描画用 x1の値から x2の値を計算する\n",
        "def decision(x):\n",
        "    return(-(bias + weight[0,0] * x)/ weight[0,1])\n",
        "\n",
        "# 散布図のx1の最小値と最大値\n",
        "xl = np.array([x_test[:,0].min(), x_test[:,0].max()])\n",
        "yl = decision(xl)\n",
        "\n",
        "# 結果確認\n",
        "print(f'xl = {xl}  yl = {yl}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "XfKQ7-mQPsqs"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAF7CAYAAAAaFRbJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABHuklEQVR4nO3de3wU5fX48c+BatBN0LbUgEFFJaKo9RK8RLlK0RZ/thRr8Qoqlq/gBfCOF0SkRS0Xaeudr1cUooj4tVJRabCAYCXFK4iggAKighYSFAjk/P54dpNl3U12k93Zy5z367UvMjPPzDzPbtiTmTNzRlQVY4wxJhmapbsDxhhjcocFFWOMMUljQcUYY0zSWFAxxhiTNBZUjDHGJM2P0t2BdGvVqpW2a9fOk31t3bqVQCDgyb7SyS/jBP+M1S/jBP+MtSnjrKio2KiqP4u2zPdBpV27dixevNiTfc2dO5fu3bt7sq908ss4wT9j9cs4wT9jbco4RWRNrGV2+ssYY0zSWFAxxhiTNBZUjDHGJI0FFWOMMUljQcUYY0zSWFAxxhiTNBZUjDHGJI0FFWOMMUmTtqAiIiNEREXkbw20O1pE3hCR70VknYiMFBGJaHO2iCwVke3Bf3+b2t4bY4yJJi1BRUROBgYB7zXQriXwGvAlcAIwFLgeuCasTSlQBjwNHBv89zkROSkVfTfGGBOb50FFRPbBffFfCnzbQPMLgL2BAar6gapOB+4Grgk7WhkGlKvqH1V1mar+EZgbnG+MMcZD4vXjhEWkDFitqjeKyFzgA1W9MkbbJ4GfquqZYfNOAP4NHKKqq0TkM+CvqvrnsDbXA1eq6kExtjsId6REYWFhybRp05I0uvpVVVWRn5/vyb7SyS/jBP+M1S/jBP+MtSnj7NGjR4Wqdoq2zNOCkiLyB6A9cGGcq7QG1kbM+zJs2argv19GadM61kZV9WHgYYBOnTqpV8XjrFBd7vHLWP0yTvDHWJctg7//fTnjxnVI+rY9O/0lIh2APwHnq2q1V/s1xhjjqMKDD0JJCTz2WDsqK5O/Dy9zKqVAK+BDEdkpIjuBbsCQ4HRelHU2AIUR8wrDltXXZgPGGGMA2LgR+vSBwYOhSxd4+OEKCgqSvx8vg8pM4GjcFVqh12JgWvDnHVHWWQh0EZEWYfN6AeuB1WFtekWs1wt4Mwl9NsaYrPfaa3D00fDKKzBhAvzjH/DTn0b7ym06z4KKqv43eAVX7QvYCnwTnFYRGSsic8JWewb4DnhcRI4Skb7ATcAErbvCYBJwmojcJCKHi8gIoAdwr1djM8aYTLR9O1x7LZx+Ovz4x/DWWzB8ODRL4Td/pt1R3wY4NDShqptxRx37445q7gPGAxPC2rwJnAtcjLvvpT/QT1Xf8qzXxhiTYZYtg5NPdkcmQ4bA4sVw7LGp329aHyesqt0jpi+O0uZ9oGsD25kOTE9m34wxJhupwkMPwTXXQCAAL74Iv/61d/v3/TPqjTEmV2zcCJdd5gJJr17wxBPQpo23fci001/GGGMa4bXX4Oc/d0n4CRNcUt7rgAIWVIwxJqtt3w7XXeeS8fvu600yvj4WVIyvqcILL7h/45lvTCb56COXjB8/3t1/4lUyvj4WVIyvzZwJffu6v+xCAUTVTfft65Ybk2lCyfjjj4e1a10O5f77Ye+9090zS9Qbn+vTB4YOhUmT3PTEiS6gTJrk5vfpk87eGfNDmZCMr48FFeNrIi6QgAskoeAydKibv/vj4IxJr9dfh/79YdMmd8pr2LD05U5iybDuGOO98MASYgHFZJJQMr5XL9hnH5eMv+aazAsoYEHFmNocSrjwHIsx6RSZjK+oSH8yvj4WVIyvhQJKKIdSU1OXY7HAYtIpPBn/+eeZlYyvj+VUjK/NnFkXUEKnvMJzLN26wW9/m9YuGh/K9GR8fSyoGF/r0wdmzHD/hnIoocDSrZtd/WW8lw3J+PpkUVeNST4RdyQSmZSPNd+YVMmmZHx97EjFGGPS7KOP4PzzYckSuPxyd4SS6bmTWLIsBhpjTO4IT8Z/9pnL8T3wQPYGFLAjFWOMSYtsTsbXx45UjDHGY6+/7srUz5rlTnWlq0x9KlhQMcYYj+zYAddfn/3J+Prk0FBMtrBy88aPQnfGjxvnkvEVFXDccenuVfJZUDGes3Lzxk9yMRlfH0vUG89ZuXnjF5s2uWT8zJnwi1+4ZPz++6e7V6llQcV4zsrNGz94/XUYMAC+/tqd8krnI3695IMhmkxk5eZNrgpPxrds6ZLx117rj4ACFlRMmli5eZOLwpPx//M/uZuMr48FFeM5Kzdvco0qPPxwXTL+hRfgwQdzNxlfH8upGM9ZuXmTS/yYjK+PZ0cqInKFiLwnIluCr4UicmY97UeJiMZ47Rds0y7G8l96NS6TuFC5+fAcSiiwhMrQG5MN5sxxd8a//LI75TV7tr8DCnh7pLIWuBFYgQtmA4CZIlKiqu9FaT8OeDBi3jRAVfWriPm/BN4Nm/4mOV02qRAqKx/vfGMyzY4dcOutLpB06AB//7v/ciexeBZUVPXFiFm3iMhgoBT4QVBR1SqgKjQtIgcAXYCLomx+k6puSGJ3jTEmqo8+ggsugP/8xyXjJ0zwZ+4klrQk6kWkuYicC+QDb8a52kDgW+D5KMtmiMhXIrJARH6XrH4aY0xIeDJ+zRp/J+PrI+rhpTYicjSwEGiBOwq5QFVfjmO95sAq4HlVHR42vxXuNNoCYCfwa+AWYICqTqlne4OAQQCFhYUl06ZNa/SYElFVVUV+fr4n+0onv4wT/DNWv4wToo918+YfMX58B+bN+xnHH/8tI0Yso1WrHWnqYXI05TPt0aNHhap2irpQVT17AXsC7YESYCywETgqjvXOBBToGEfb+4H34u1TSUmJeqW8vNyzfaWTX8ap6p+x+mWcqj8c6+uvq+6/v+oee6iOG6e6a1d6+pVsTflMgcUa4zvV09NfqrpDVVeqaoWqjgDeAYY3sBq4o4o3VXVpHG3fAoqb0E1jjGHHDrjhBv/eGd9Y6b5PpRmQV18DEdkfd6RyWZzbPBb4omndMsb42fLl7pnxloxPnGdBRUTuAl4GPgcKgPOB7riAgYiMBU5U1Z4Rq14KbAWejbLNAUA1sASoAc4CrsBdumyMMQlRhb//vQ0PPAAtWrhkvN03lRgvj1RaA1OC/27GXUb8K1WdHVzeBjg0fAUREdxVX0+r6ncxtnsrcBCwC/gYuFTrSdIbY0w0mzbBH/4AL7zQgZ494ckn7UbGxvDyPpWLE10eTAgdXM86TwBPNLVvxhh/mzMH+vd3Zeovv/wT7rvvUMudNJK9bcYY3wpPxhcUwKJF0K/f5xZQmsDeOmOMLy1fDqWl8Oc/w6BBrkz98cenu1fZz4KKMcZXVOGRR1wAWb267s74QCDdPcsNFlSMMb6xaROcfbY7Mikthffft6u7ks2CijHGF/75TzjmGFdR+J574NVX7equVLCgYozJaaFk/C9+Afn5Lhl//fV2Z3yqpPuOemOMSZnly12Z+ooKd8prwgTLnaSaxWpjTM5RhcmTXTJ+1Sr3RNGHHrKA4gULKsaYnLJpE/zud+7u+NJSeO89e6KolyyoGGNyRigZ/9JLdcn4oqJ098pfLKgYY7Lejh1w440uGR8IWDI+newtN02m6m4gi3yIaKz5xiTT8uVwyinuyOQPf3Dl6u3O+PSxoGKabOZM6NsXhg+vCyCqbrpvX7fcmGSzZHxmskuKTZP16QNDh8KkSXXTw4e76aFD7Y5lk3zffOOOSmbMgNNOc2XqLXeSGSyomCYTgYkT3c+TJsEBB9QFlIkT3XJjkuWf/3Rl6r/6yp3yskf8Zhb7KExShAeWEAsoJpkik/ELF1oyPhPZx2GSIpRDCReeYzGmKT7+uC4Zf9llLhlfUpLuXploLKiYJgsFlNApr5KSuhyLBRbTFKFk/HHH1SXjH37YkvGZzIKKabKZM3fPoYD7NxRY7Oov0xjffAPnnOMS8iefbHfGZwtL1Jsm69PH/QXZp09dDiWUY+nWza7+MokrL4eLLrJkfDayj8k0mYj7CzIyKR9rvjGx7NgBN90EPXtaMj5b2ZGKMSYjfPwxnH++K1P/hz+4I13LnWQfi//GmLSyZHxusaBijEkbS8bnHgsqxpi0KC+Hn/8cXnwR7r4bXnvNSq3kAgsqxhhPRSbjFy1yz5C3ZHxu8PRjFJErROQ9EdkSfC0UkTPrad9ORDTK65cR7bqJSIWIbBORT0Xk8tSPxjSWlcr3r9Cd8XffbXfG5yqv/zZYC9wIHA90Av4JzBSRnzew3i+BNmGvf4YWiMjBwCzgTeA4YCzwVxE5O+m9N0lhpfL9RxX+939dMv7TT+H55y0Zn6s8vaRYVV+MmHWLiAwGSoH36ll1k6puiLHscmC9ql4VnF4mIicB1wHPN6nDJiUiS+VPnGil8nPZN9/AoEEukJx2GjzxBLRtm+5emVRJ230qItIcOAfIxx1l1GeGiLQAVgATVXV62LJS4NWI9rOBASKyh6pWJ6vPJjkiS+WHgouVys89oTvjv/zSnfK67jrLneQ6UY9PYIvI0cBCoAVQBVygqi/HaNsKGAAsAHYCvwZuAQao6pRgm4+BKao6Omy9rsAbwP6q+kWU7Q4CBgEUFhaWTJs2LXkDrEdVVRX5+fme7CudEhlnRUXdz9l4bt0+0+iqq4XHH2/H1KkH0rbt99xyy1I6dKhKYQ+Txz7ThvXo0aNCVTtFXaiqnr6APYH2QAku/7EROCqB9e8H3gub/hgYGdGmK6BAm4a2V1JSol4pLy/3bF/pFM84a2pUhw5VdWfb3WvoUDc/m9hn+kPLl6t26uQ+08suU62qSl2/UsE+04YBizXGd6rnB6KqukNVV6pqhaqOAN4BhjewWri3gOKw6Q1AYUSbQtyRzcam9NWkRmSp/JoaK5WfC8KT8Z98AtOnwyOPWDLebzKh9lczIC+B9scC4ae0FgKR9+D2wkVSy6dkoMhS+ZE5lm7d7K7qbBOejO/Rwz0z3pLx/uRpUBGRu4CXgc+BAuB8oDtwZnD5WOBEVe0ZnB4AVANLgBrgLOAK3GXJIQ8CV4rIvcBDwKnAxcB5qR6PaRwrlZ9b5s51yfgNG+Cuu1wyvnnzdPfKpIvXRyqtgSnBfzfjLiP+larODi5vAxwasc6twEHALlz+5FINJukBVHWViPQGJgKDgfXA1apqlxNnqFBJ/Hjnm8y0Ywfcfru7qqu42N0Zn40XW5jk8vo+lYsTWa6qTwBPxLHdN3A3VBpjPLBihStTv3ixuzP+3nstd2Icu2LcGBM3VXj0UUvGm9gsqBhj4vLNN/D738PAgXDiia5M/dlWDMlEsKBijGnQO+/syzHHuCv37rrLlam3q7tMNJlwSbExJkNVV8PIkXD33cfQvr17Znyn6PdRGwPYkYpvZGu5+VT3O1vfFy+sWAEnnbSLu+6Crl0/4eqrH6dDh8p0d8tkOAsqPpGt5eZT3e9sfV9SKZSMP+aYXSxZsoW8vAs466wXuemmKykqKmL+/Pnp7qLJYBZUfCK83HzoCzQbys2nut/Z+r6kyrff1iXjd+yYDxzN9u3PALB161YqKyvp3bs3VVXZURzSeM9yKj6RreXmU93vbH1fUuGNN+DCC92d8X37/ptXXjmL77774emumpoaysrKGDhwYBp6aTKdHan4SPgXaEg2fHGmut/Z+r4kS3U13Hyzq9m1114uGd++/fNRAwq4I5aVK1d63EuTLSyo+Ejo1E64bKgKnOp+Z+v7kgwrVrhnxo8dC5de6p4Z36kTFBcXE4hxR2MgEKB9+/Ye99RkCwsqPpGt5eZT3e9sfV+aKtqd8ZMnQ+iZTf369aNZjEc0NmvWjH79+nnYW5NVYj1oxS8vvzyka8aMHz4IK/xBWTNmJG9fyRxnqvvd1O1n4wOdvvlG9Zxz3Pi6d1f97LPo7ebNm6cFBQUaCAR03LhxGggEtKCgQOfNm+dthz2WjZ9pY6TqIV2WqPeJbC03n+p+Z+v70ljhyfixY+H662OXqe/cuTPr16+nrKyMFi1aMGnSJPr16+eLR+2axrOg4hPZWm4+1f3O1vclUdXVrkz9XXdB+/bw5ptwwgkNr5efn8/AgQOZO3cu3bt3T3k/TfazoGJMjlu50pWpf/ttl4yfNKkud2JMslmi3pgcpQqPPQbHHusCy3PPuWfIW0AxqWRBxZgc9O230K+fOzI54QR491343e/S3SvjBxZUjMkxb7wBxxzjCmKOHQuvvw4HHJDuXhm/sKBiTI6oroZbbnF3xrdo4ZLxN90U++ouY1LBgorxnJWbT76VK+HUU+FPf4JLLnF3xsdzdVc2qaysZPLkydx4441MnjyZykorw5+JLKgYz1m5+eQJT8avWJG7yfj58+dTVFTEsGHDuOeeexg2bJiV4c9QFlSM56zcfHKEJ+M7dXLPjM/FZHyo3H5lZSVbt24FrAx/JrOgYjwXumM9FFiaNasLKH6qDtwUkcn4OXNyNxlfVlZGTU1N1GWhMvwmc1hQMWnh93LzjRWejM/L80cyfsWKFbVHKJGsDH/msaBi0sLP5eYba+VK6Ny5Lhm/ZEnuJeOjsTL82cWCivGcX8vNN5YqPP64K1P/8cfw7LO5mYyPxcrwZxdPg4qIXCEi74nIluBroYicWU/77iLyooh8ISLfBde9NEobjfI6PPUjMo0xc+YPcyjhORa7+qtOKBl/ySVQUuKS8eeck+5eeaugoIBZs2ZRUFBQe8QSCARq51vV5MzidUHJtcCNwApcQBsAzBSRElV9L0r7U4D3gXuAL4AzgIdFZJuqPhPR9kjgm7Dpr5PdeZMcfis331j/+pcrU//FF+6U1w035HbupD7hZfhXrlxJ+/btrQx/hvI0qKjqixGzbhGRwUAp8IOgoqp/ipj1gIj0AM4GIoPKV6q6MWmdNSnjl3LzjVVdDaNGuau6Dj00/jL1uS5Uht9ktrTlVESkuYicC+QDbyawakvg2yjzFwdPk80JBh5jso5fk/Emd4g2IisqIvsSEZBU9ZvorX+w7tHAQqAFUAVcoKovx7nu/wNeAE5V1X8H53UAegBvA3sCFwGXA91UdV6M7QwCBgEUFhaWTJs2LZ7dN1lVVZUvDtf9Mk5I3lhVYfbs1vzlL+1p3ly59tqP6d49c87g2meae5oyzh49elSoaqeoC2M9ZzjyBRwE/AP4HtgV9qoBdiWwnT2B9kAJMBbYCBwVx3qnAluAwXG0nQX8Xzz98csz6r3kl3GqJmes33yj+vvfu2fGd+sW+5nx6WSfae7JhGfUPwbsCwwE1gONuvBTVXcAobuVKkTkBGB4cLtRiUhnXKAYqaoPxLGbt4BzG9M/Y7xkyXiTaxIJKicCJ6vqB0nuQzMgL9ZCEekKvAzcrqr3xrnNY3FXixmTkSwZb3JVIon6VdTz5R8PEblLRLqISDsROVpExgLdgaeDy8eKyJyw9t1xp9weBJ4RkdbB18/C2gwTkT4iUiwiRwa32Qf4W1P6Gk0mlWy3vmSvTz6pS8ZffLG3yXgrH29CvwPr1q1Lze9ArPNikS/gNOBVoH2860TZxuPAGmA78BXwOnBGxPLVEdMa5RXe5gbcfS/f4+5TmQf0jrdPieRUZsxw572HDlWtqXHzamrcNLjl9Unmudqm9iWZIvtSXl6etr54LZHPtKZG9bHHVPPzVffdV/XZZ1PWrajmzZunBQUFGggEFNBAIKAFBQU6b968Btf1S55BNbfHGv47MG7cuIR+B8JRT06loSBQiUuOh147cMn57yLmb6lvO5n8SiSohH9Rhr5AI6frk8xf1qb2JZki911eXp62vngt3s803cn4LVu2aEFBQbQ/0LSgoEArKyvrXT+Xv2gj5epYI38Hxo0bl9DvQLj6gkpDOZUrEzrsyXHhlXUnTXIvSE/J9kzuywEHWCn7cOHJ+D/+EW680ftkfDzl4+3Gwtzm1e9AvUFFVZ9o8h5yTOgLNPQlDun74rS+ZLbqarjjDpeMP/hgWLAATjwxPX2x8vHGq9+BuBP1IrJLRPaLMv+nIrIrKb3JAppBJdutL5nrk0+gSxd3ZDJggEvGpyuggJWPN979DiRy9VesvznzcLmWnBf64syEku2Z3JeSEv+WsleFJ55wz4xfvtyVqX/0USgoSG+/rHy88ep3oMH7VETkmuCPClwuIuEPhG4OdAE+SkpvMlysku3g5nfr5l1BxEzuyxtvpK8v6fTf/8Lll0NZGXTtCk89BQcemO5eOaEy8b1796ampoatW7cSCARo1qyZlY/3icjfASAlvwPx3Px4VfBfAS7DXf0VsgNYjau1lfMyqWS79SWz/OtfcNFFsH59+pLxDbHy8Sb8d6BFixZMmjQp6b8DDQYVVT0YQETKgb6qGq1CsC9kUsl260tm2LlTuPXWzEjGx8PKx5vQ78DcuXPp3r170rcfd5kWVbVy8saE+eQTuPrq41i2zN0Z/5e/pD93Yky61RtUROTReDekqpc23MqY7KcKTz4JV14JqntTVga//326e2VMZmjoSOVnEdNdcaXu3w9OH4W7guxfSe6XMRkpMhk/ZMjb/P73penuljEZo6GbH88K/SwiI3D1tS5R1a3BeQHgf6kLMsbkrHnz3J3x69bVJePnzdue7m4Zk1ESuU/lamBUKKAABH++k7orxIzJOdXVcNtt0L077LGHK1N/882Zd3WXMZkgkaCSD+wfZX4bYO/kdMdkArVS9rVCd8aPGQP9+6f/zniTnfz0yIFEgsrzwGMicm7weSjtRORc3OmvGanpnkmHmTOhb9/d74YP3TXft69bnuvC74z/6COXQ3nsMbu6yyRu/vz5FBUVMWzYMO655x6GDRtGUVER8+fPT3fXUiKRJz8OBsbjnnGyR3DeTlxQuS653TLp1KdPXZkVcDcxhpdhyfWbGcOT8V26wJQpmXNnvMkulZWV9O7de7cjk1BRx969e7N+/fqcu/k07iMVVf1eVYcAPwWOC75+oqpDVPW7VHXQeC90N3wosDRr5p9S9vPmwTHHwPTpLhlfXm4BxTRePOXmc00ip78Al5xX1feCr+h1lE3WC68lFpLLAcWS8SYV/PjIgYZufvw/4EJV3RL8OSZV/XVSe2bSKlYp+1wMLJ98AhdcAG+9ZXfGm+QKlZuPFlhy9ZEDDR2pbMJVJw79XN/L5IhMKqufSqE740PJ+GnTLBlvksuPjxxo6ObHS6L9bHJbJpXVT5X//hcGD3aBxJLxJlX8+MiBuK/+EpFTgH+r6s4U9sdkgFwvZR9+Z/yYMXDTTZY7Manjt0cOJHJJ8T+BahFZCMwNvizI5KBcLWW/cyeMHu2u6mrXzpWpP+mkdPfK+IGfHjmQyNVfPwZ+C7wF/AoXZL4VkVeDdcGMyVihO+PvvNM9TOuddyygGJMKiTxP5Xvg9eALETkUuAW4EOgJjE1FB41pClX3WN8rrnCnuKZNgxzMjRqTMRLJqewHdAd6BP89EPg38EfcqTBjMkpkMv6pp+Cgg9LdK2NyWyI5lQ3A18BDwP8Ab6mq1f02GWn+fJeMX7vWnfIaMcKS8cZ4IZGcyjPAdmAocANwpYiUiOTarXAmm+3cCSNHuqvUmjd3yfhbb7WAYoxXEqn9daGqHggcD7wAHIurTvyNiLwYzzZE5AoReU9EtgRfC0XkzAbWOVpE3hCR70VknYiMjAxkInK2iCwVke3Bf1NyjZKVhM9sn36amcl4P5U998tYEx2nX94XAFQ1oRcuEJ0EjABeBXYA2+Nc9ze4K8faA4fh8jHVwM9jtG+JO+32LO7Rxb8DKoFrw9qU4qol3wIcEfx3J3BSPH0qKSnReM2YoQqqQ4eq1tS4eTU1bhrc8vqUl5fHva9s5vU4a2pUn3xStaBAdZ99VKdN827fDY113rx5WlBQoIFAQAENBAJaUFCg8+bN86aDSRLPZ+qXsSY6zkx9X5ry/xRYrLG+52Mt+EFDd8prFrAFdxrsTdwVX2cAgXi3E2W73wD/E2PZ4OD+9gqbdyuwDpDgdBnwWsR6rwNT49l/IkElPICEAkvkdH0sqCTft9+qnnee+wy6dFFdvdqzXatq/WPdsmWLFhQUKK7U0W6vgoICrays9K6jTdTQZ+qXsSY6zkx+X1IVVBLJqfwWeBc4B1fy/hRVHaGqs7UR1YpFpHnwIV/5uAAVTSkwT93lzCGzcU+gbBfW5tWI9WYDpyTap4b4uSR8Jpo/39XtevZZd8qrvDyzru7yU9lzv4w10XH65X0JF/prP3kbFLkfGKmqG2MsPxpYCLQAqoALVPXlGG1fBdaq6qVh8w4E1gCnqOpCEdkBXKaqT4a16Q88oqp5MbY7CBgEUFhYWDJt2rSEx1lRUfdzSUl861RVVeVsaYZwqR7nrl3CE08cxNNPH0Tr1tu45ZZldOy4JWX7q099Y123bh0bNmyIuW7r1q0pKipKVdeSqqHP1C9jTXScmfy+NOX/aY8ePSpUtVPUhbEOYRr7wp2uOqSe5XvicioluNNnG4GjYrR9FXg0Yt6BuMPH0uD0DqB/RJv+xJnnSeT0l+rup7xCr3hOfana6a9k+OQT1ZNPdu/7gAGqmzenbFdxqW+sjzzySO159MhXIBDQyZMne9fRJmroM/XLWBMdZya/L5lw+ite9Z4EUtUdqrpSVStUdQTwDjA8RvMNQGHEvMKwZfW1if3nQSOpT0rCZyIN3hl/7LGwbJm7ofHxx6Fly3T3LDY/lT33y1gTHadf3pdwqQgqiWoGRD1NhTtN1kVEWoTN6wWsB1aHtekVsV4vYudpGi1WSfhQYJk5M9l7NACbN7uHaPXv7x71++672VFqJVT2vKCggEAgALgHM4Xm59KpUL+MNdFx+uV9CZfIHfVNJiJ3AS8DnwMFwPm4ki9nBpePBU5U1Z7BVZ4BbgceF5ExuMuQbwLuCB6CAUwC/iUiNwEzcRcU9AA6J7v/uV4SPhNl+53xfip77pexJjpOv7wvIZ4GFaA1MCX472bgPeBXqjo7uLwNcGiosapuFpFewH3AYuBbYDwwIazNm8GryMYAo4FPgH6q+layO5+rJeEzUWSZ+vnz4eST092rxvFT2XO/jDXRcfrlfQGPg4qqXpzoclV9H+jawHrTgelN6ZvJHJ9+6k53LVrkTnn99a+ZnTsxxtRJRVCZgrsCzJiETZkCQ4a4e4CmToVzz013j4wxiag3qIjI8fFuSFX/E/x3cFM7Zfxn82YXTJ55Bjp3dsElk25kNMbEp6EjlcW4a6obuldcgSxKn5pMsmCBO92Vrcl4Y0ydhoLKwZ70wvjSzp0uiIwZ445KsjkZb4xx6g0qqrrGq45kA1V3L0r4JcX1zTexffqpu1R44UJXpv5vf7NkfC6orKykrKyMFStWUFxcTL9+/SgoKEh3t4yHEk7Ui8j+uFIpe4bPV9V/JatTmWrmTOjbd/ebH8Pvsp8xwy4tjkd4Mv6ZZ+C889LdI5MM8+fPp3fv3tTU1LB161YCgQDXXHMNs2bNonPnpN82ZjJUIs+o3x93M2JX6vIs4YVJcv4seJ8+dXfPgwss4WVb7ObH+lkyPndVVlbSu3fv3R4+tXWrK17eu3dv1q9fn7M3+5ndJVKm5V5gF9AR+A7ogiuDvwz4ZdJ7loGs9H3jLVjg6naVlbmbGjOtTL1pGj+WeDfRJRJUugE3qupHuCOUr1V1BnAjcGcqOpeJQoElnAWU2HbuhFGjoGtX9x7Nmwe33QY/8rqWg0mpFStW1B6ZRNq6dSsrV670uEcmXRIJKnvhytSDe1rjfsGflwI/T2anMlkohxLOKhRHt2qVCyZ33OEuGX7nHSgtTXevTCoUFxfXFkyMFAgEaN++vcc9MumSSFD5CDg8+PM7wOUichBwBe7xvjnPSt/Hb8oUV1H4ww9dDuXJJ+3qrlzmxxLvJrpETkJMwhWCBFe48RXgPNzz6gckuV8ZKVbpe3Dzu3Wzq782b4YxY45gzhyXjH/qKVcQ0uS2UCn3yKu/mjVrlrMl3k10cQcVVX067Of/iEg73JHLZxrj0cG5xkrf12/BAnfvyWef7cfo0e7OeMud+IffSryb6Br1X15E8qGu3pdfWOn76HbudHfF33mnu6LrL39ZwhVXxF02zuQQP5V4N9El9ORHERkmIp/hnoWyWUQ+F5HhInbtk19FS8YfeaQVqTbGrxK5+fEeYBDwZ9wjfAFKgZG4h2vdkPTemYwWujNexO6MN8Y4iZz+ugy4LPhArJB/ishy4CEsqPhG+J3xp57qgosl440xkODpL9zjf6PNS3Q7Jku9+WbdnfF33AFz51pAMcbUSeRI5UncPSlDI+YPBp5KWo9MRopMxs+bZzcyGpMq2VztOZGgkgecLyJnAIuC804C9geeFpG/hBqq6tXJ66JJt1Wr3KXCb75pZeqNSbVsr/acSFA5HAhdQhwqBbgh+DoirJ3dV55Dnn7a5U/AkvHGpFouVHtO5ObHHqnsiMksmzfDFVe4oGLJeGO8EU+150y/DyjhBLuItBKRk0QkLxUdMukXSsZPm2bJeGO8lAvVnuMOKiJSICLPAV8BbwJFwfkPisio1HTPeClUpr5Ll7oy9SNHWqkVY7ySC9WeEzlSuRuXlD8e+D5s/t8BHxcpyQ2rV7v6ZXfcAeefb2XqjUmHXKj2nEhQ+TUwTFXfYfdk/DLgkGR2ynjr6addmfoPPnA/P/WUXd1lTDqEqj0XFBTUHrEEAoHa+ZmepIfErv76MbApyvwC3GOG6yUiI4C+QAdcufxFwAhV/aCedUYBt8dYXKiqXwWrJa+KsvxXqvpKQ/3yM0vGG5N5sr3acyJB5W3c0cq9wenQ0cr/4HIsDekO3B/cjuCeyfK6iHRU1W9irDMOeDBi3jRAVfWriPm/BN4Nm461TYNLxl9wAXz2mcuj3HKL5U6MyRTZXO05ka+Rm4HZInJkcL1rgj+fBHRpaGVVPSN8WkQuwlU7PhV4KcY6VUBV2DoHBPd1UZTmm1R1Q3xD8a+dO+GPf3R3xh94oEvGn3JKuntljMkVcedUVPVNXFXiPYFPgJ64xwif3MjnqhQE9/9tAusMDLZ/PsqyGSLylYgsEJHfNaI/OS+UjB81yt3E+M47FlCMMcklGueD1UWkI7BLVZcHp08H+gMfAveoaoN5lYjtPQsUA53iWVdEmuNyJ8+r6vCw+a1wjzNeAOzEnaK7BRigqlNibGsQrow/hYWFJdOmTUuk641WVVWVtvOir7++H/feexgAw4Z9zC9+EXn2MHnSOU6v+WWsfhkn+GesTRlnjx49KlS1U9SFqhrXC5dYPzf48wHAVmAWsBYYG+92gutPANYDhySwzpm4PE7HONreD7wXz3ZLSkrUK+Xl5Z7tK+S//1W98EJVUD3lFNVPP039PtMxznTxy1j9Mk5V/4y1KeMEFmuM79RELikOr/31O+Dfqtobl9+IuyKUiEwMtj9NVT9NYP+DgDdVdWkcbd/CHQX5WujO+Geecae83ngDDj443b0yxuSyRBL1zYEdwZ974o5SwOVXCuPZgIhMAvoBPVT1o3h3LCL7445ULotzlWOBL+Ldfq4JT8YfcIAl43NdNpdJN7knkaDyATBYRP6OCyojgvOLgI0NrSwi9+GOavoA34pI6+CiKnVXeSEiY4ETVbVnxOqX4k63PRtluwOAamAJUAOchXvuy40JjC1nrF7tytQvWOAuGb7vPthnn3T3yqRKtpdJN7knkaByIzATuA54QlXfD87/NfDvONYPFlBnTsT8O4BRwZ/bAIeGLxQRwV319bSqfhdj27fiyvHvAj4GLtUYSfpc9swzMHiw+3nKFBdUTO7KhTLpJvckUvr+XyLyM6ClqoZfBvwQEOvLPnx9iaPNxVHmKRAzE6CqTwBPNLTtXLZli7szfsoUd5pryhTLnfhBLpRJN7knodL3qrorIqCgqqv1h3e3G48sXGjJeL/KhTLpJvck/DwVkxl27oTRo12ZelWXjL/9diu14ie5UCbd5B4LKllo9Wro3t0FkXPPtTvj/SoXyqSb3GNBJcs884wrU//eey53MmWKXd3lV7lQJt3kHjtZkiXCk/Glpa5cveVOTLaXSTe5x4JKFli40F0evGaNlak3P5TNZdJN7rHTXxnMkvHGmGxjX08Zyu6MN8ZkIwsqGWjqVLj8cnd0YnfGG2OyiZ3+yiBbtsBFF8H558ORR8K771pAMcZkFwsqGSL8zvjbb4d//cuu7jLGZB8LKmkWnoyvqXHBZNQoS8YbY7KTfXWlUXgy/vzz4f77LRlvjMluFlTSJDwZ/9RTLrgYY0y2s9NfHtuyBfr3r0vGv/OOBRRjTO6woOKhpUtbctxxrsRKKBl/yCHp7pUxxiSPnf7ywK5d8Kc/wahRx3HAAS6YnHpquntljDHJZ0Elxdascae35s+Hnj2/4vnnCy0Zb4zJWRZUUmjaNJeMr6lxyfi2bZexzz6F6e6WMcakjOVUUiCUjD/vPOjY0ZLxxhj/sKCSZIsWUZuMHznSkvHGGH+xoJIku3bBnXdC587u5zfegDvusDvjjTH+Yl95SRCejD/vPHdn/L77prtXxhjjPQsqTRSZjLfciTHGz+z0VyNVVsKAAe7I5IgjLBlvjDFgRyqN8t//QkmJKwg5ciTcdpvlTowxBjw+UhGRESLytohsEZGvReQlETmqgXXaiYhGef0yol03EakQkW0i8qmIXJ6qcey7rztCsWS8Mcbszuuvw+7A/cDbgACjgddFpKOqftPAur8E3g2brm0vIgcDs4BHgQuBzsD9IvK1qj6fvO7XGTMmFVs1xpjs5mlQUdUzwqdF5CJgM3Aq8FIDq29S1Q0xll0OrFfVq4LTy0TkJOA6ICVBxRhjzA+lO1FfEOzDt3G0nSEiX4nIAhH5XcSyUuDViHmzgU4iskcS+mmMMSYOoqrp27nIs0Ax0ElVd8Vo0woYACwAdgK/Bm4BBqjqlGCbj4Epqjo6bL2uwBvA/qr6RcQ2BwGDAAoLC0umTZuW7KFFVVVVRX5+vif7Sie/jBP8M1a/jBP8M9amjLNHjx4Vqtop6kJVTcsLmACsBw5pxLr3A++FTX8MjIxo0xVQoE192yopKVGvlJeXe7avdPLLOFX9M1a/jFPVP2NtyjiBxRrjOzUtp79EZCJwHnCaqn7aiE28hTvCCdkARJb/LcQd2WxsVCeNMcYkzPOgIiKTqAsoHzVyM8cC4ae0FgK9Itr0wkXT6kbuwxhjTII8vfpLRO4DLgL6AN+KSOvgoipVrQq2GQucqKo9g9MDgGpgCVADnAVcAdwYtukHgStF5F7gIdzVZBfjgpcxxhiPeH2fypDgv3Mi5t8BjAr+3AY4NGL5rcBBwC5c/uRSDSbpAVR1lYj0BiYCg3G5mqs1RfeoGGOMic7r+1QkjjYXR0w/ATwRx3pvAMc3unPGGGOaLN33qRhjjMkhFlSMMcYkjQUVY4wxSWNBxRhjTNJYUDGmESorK5k8eTLr1q1j8uTJVFZWprtLxmQECyrGJGj+/PkUFRUxbNgwNmzYwLBhwygqKmL+/Pnp7poxaWdBxZgEVFZW0rt3byorK9m6dSsAW7durZ1fVVWV5h4ak14WVIxJQFlZGTU1NVGX1dTUUFZW5nGPjMksFlSMScCKFStqj1Aibd26lZUrV3rcI2MyiwUVYxJQXFxMIBCIuiwQCNC+fXuPe2RMZrGgYkwC+vXrR7Nm0f/bNGvWjH79+nncI2MyiwUVYxJQUFDArFmzKCgoqD1iCQQCtfP98MRAY+rjdZViY7Je586dWb9+PWVlZbRo0YJJkybRr18/CyjGYEHFmEbJz89n4MCBzJ07l+7du6e7O8ZkDDv9ZYwxJmksqBhjjEkaCyrGGGOSxoKKMcaYpLGgYowxJmksqKSQKrzwgvs3nvkme1jpe2Ois6CSQjNnQt++MHx4XQBRddN9+7rlJvtY6XtjYrP7VFKoTx8YOhQmTaqbHj7cTQ8d6qZNdgkvfR8SKjDZu3dv1q9fbzdBGl+zI5UUEoGJE+sCS0VFXUCZONEtN9nFSt8bUz8LKikWCizhLKBkLyt9b0z9LKikWCiHEi48x2Kyi5W+N6Z+FlRSKBRQQqe8SkrqToVZYMlOVvremPpZUEmhmTN3z6HA7jkWu/or+1jpe2Pq51lQEZERIvK2iGwRka9F5CUROaqBdbqLyIsi8oWIfCci74nIpVHaaJTX4akdUcP69IEZM3bPoYRyLDNm2NVf2SpU+n7SpEm0bt2aSZMmsX79ejp37pzurhmTdl5eUtwduB94GxBgNPC6iHRU1W9irHMK8D5wD/AFcAbwsIhsU9VnItoeCYRv5+sk9r1RROC3v41/vskeVvremOg8Cyqqekb4tIhcBGwGTgVeirHOnyJmPSAiPYCzgcig8pWqbkxSd40xaVJTU8PatWtjXmWXavvssw/Lli1Ly769VN84A4EAbdu2jZk/rE86b34swJ1++zbB9VoCa6PMXywiecBSYIyqljexf8aYNNi4cSMiQocOHRr1pdZUlZWVFBQUeL5fr8UaZ01NDevWrWPjxo3st99+CW9XNE2XIInIs0Ax0ElVd8W5zv8DXgBOVdV/B+d1AHrgTqvtCVwEXA50U9V5MbYzCBgEUFhYWDJt2rQmjiY+VVVVvkjk+mWc4J+xejnOli1b0q5dO/bYYw9P9hdp165dNG/ePC379lJ946yurmb16tVs2bIl6vIePXpUqGqnqAtV1fMXMAFYDxySwDqnAluAwXG0nQX8XzzbLSkpUa+Ul5d7tq908ss4Vf0zVi/HuXTpUq2pqfFsf5G2bNmStn17qb5x1tTU6NKlS2MuBxZrjO9Uz48tRWQicB5wmqp+Guc6nYF/ACNV9YE4VnkLdxRkjMlCYiUn0qop77+nORURmQT0A3qo6kdxrtMVeBm4XVXvjXNXx+KuFjPGGOMhz4KKiNyHy3f0Ab4VkdbBRVWqWhVsMxY4UVV7Bqe74wLK/cAzYevsUtWvg22GAauBD3E5lQuD+zg7xUMyxhgTwcvTX0NwV3zNwR1FhF7XhbVpAxwaNn0xsHewTfg6b4e12RP4M/AeMA/oDJypqjNSMQhjjEmUiDB9+vR0d8MTngUVVZUYr1FhbS5W1XYR09HWCW9zj6oWq+peqvoTVe2iqrO8GpcxxmS6zz77jLPOOotAIECrVq24+uqr2bFjR0r2ZbW/jDE5wx7h/UO7du3izDPPpLKyknnz5jF16lSmT5/OzTffnJL9WVAxxuSMdD3CW1UZP348xcXF5OXl0bZtW0aMGBGz/U033USHDh3Ya6+9aNeuHTfccAPbtm2rXf7555/zm9/8hp/85CfsvffeHH744YTfTzd69GgOOugg8vLyaN26Nf3794+5r1dffZUPP/yQp556iuOPP55evXpxzz338MQTT8S8D6Up7HHCxpicEfkI74kTvXmE980338wDDzzAhAkT6Nq1K19//TVLliyJ2T4QCPDoo49SVFTE0qVLufzyy8nLy+POO+8EYMiQIWzbto3y8nJatmzJ8uXLa9d9/vnnGTduHFOnTuXoo4/mq6++YtGiRTH3tXDhQo444ggOOOCA2nlnnHEG27dvp6Kigh49eiThHahjQcUYkzPCn7Q6aVJdcEnlI7yrqqqYOHEi9957L5de6oqot2/fntLS0pjr3HbbbbU/t2vXjptvvplx48bVBpU1a9Zw9tlnc8wxxwBw8MEH17Zfs2YNbdq04fTTT2ePPfbgwAMPpFOn6De3A2zYsIHCwsLd5rVq1YrmzZuzYcOGxAfcADv9ZYzJKV4/wnvp0qVs376dnj17xr3O9OnT6dy5M61btyY/P5/hw4fz2Wef1S4fOnQoY8aMobS0lFtvvZWKioraZeeccw7btm3j4IMPZuDAgTz33HNs3749qWNqCgsqxpickumP8F60aBHnnnsuZ5xxBi+99BJLlixhzJgxVFdX17YZOHAgq1at4pJLLuHjjz/mlFNOYdSoUQAccMABLF++nIceeoiWLVty7bXXUlJSErOqc+vWrfnyyy93m7dx40Z27dpF69ato67TFBZUjDE5I/IR3jU1qX+E9xFHHEFeXh5z5syJq/2CBQsoKiritttu44QTTqC4uJg1a9b8oF3btm0ZNGgQzz77LKNHj+bhhx+uXdaiRQvOPPNMJk6cyNtvv82HH37IggULou6vtLSUZcuWsXZtXXH31157jby8PEpKShIcbcMsp2KMyRmRj/COzLF065b8B+QVFBQwdOhQRowYQV5eHl27dmXTpk1UVFQwePDgH7Q/7LDDWLduHU8//TSlpaXMnj2bqVOn7tZm6NCh/OpXv+Kwww5jy5YtvPLKK3Ts2BGAxx9/nJ07d3LSSSeRn59PWVkZe+yxB8XF0csdnn766Rx55JH079+f8ePHs2nTJq6//noGDBhAy5Ytk/tmYEHFGJNDQo/w7tPnh4/w7tYtdVd/jR07lh//+MfceeedrF27lsLCwpiX+Z511llcf/31DBs2jO+//57TTz+d0aNHM2TIkNo2NTU1XHXVVXz++ecUFBTQs2dPxo8fD8C+++7L3XffzXXXXUd1dTUdO3ZkxowZuyXzwzVv3pyXX36ZIUOGcOqpp7LXXntxwQUXMHLkyOS/EaTxeSqZolOnTrp48WJP9uWXR8/6ZZzgn7F6Oc5ly5ZxxBFHeLKvaPz+kK6Q+j4HEYn5PBXLqRhjjEkaCyrGGGOSxoKKMcaYpLGgYowxJmksqBhjjEkaCyrGGGOSxoKKMcaYpLGgYowxJmksqBhjjEkaCyrGGJNiIsL06dPT3Q1PWFAxxpgcN3ToUDp16kSLFi1o165dSvdlBSWNMTmnsrKSsrIyVqxYQXFxMf369fNFPa9YampqGDBgAO+//z6vvvpqSvdlRyrGmJwyf/58ioqKGDZsGPfccw/Dhg2jqKiI+fPnp2yfqsr48eMpLi4mLy+Ptm3bMmLEiJjtb7rpJjp06MBee+1Fu3btuOGGG9i2bVvt8s8//5zf/OY3/OQnP2Hvvffm8MMPZ9q0abXLR48ezUEHHUReXh6tW7eOWRE55K9//StXXXUVhx12WNMH2wA7UjHG5IzKykp69+5NZWVl7bzQExF79+7N+vXryc/PT/p+b775Zh544AEmTJhA165d+frrr1myZEnM9oFAgEcffZSioiKWLl3K5ZdfTl5eXu0z6ocMGcK2bdsoLy+nZcuWLF++vHbd559/nnHjxjF16lSOPvpovvrqKxYtWpT0MTWWBRVjTM4oKyujpqYm6rKamhrKysoYOHBgUvdZVVXFxIkTuffee7n00ksBaN++PaWlpTHXue2222p/bteuHTfffDPjxo2rDSpr1qzh7LPP5phjjgHY7Vkpa9asoU2bNpx++unsscceHHjggXTqFLUKfVrY6S9jTM5YsWJFzGe1b926lZUrVyZ9n0uXLmX79u307Nkz7nWmT59O586dad26Nfn5+QwfPpzPPvusdvnQoUMZM2YMpaWl3HrrrVRUVNQuO+ecc9i2bRsHH3wwAwcO5LnnnmP79u1JHVNTeBpURGSEiLwtIltE5GsReUlEjopjvaNF5A0R+V5E1onISJHQc91q25wtIktFZHvw3yQ/NNQ0pLKyksmTJ7Nu3TomT5682ykIY7xQXFxMIBCIuiwQCNC+fXuPe/RDixYt4txzz+WMM87gpZdeYsmSJYwZM4bq6uraNgMHDmTVqlVccsklfPzxx5xyyimMGjUKgAMOOIDly5fz0EMP0bJlS6699lpKSkpiBlOveX2k0h24HzgFOA3YCbwuIj+JtYKItAReA74ETgCGAtcD14S1KQXKgKeBY4P/PiciJ6ViEOaHwpOjGzZs8CQ5akykfv360axZ9K+1Zs2a0a9fv6Tv84gjjiAvL485c+bE1X7BggUUFRVx2223ccIJJ1BcXMyaNWt+0K5t27YMGjSIZ599ltGjR/Pwww/XLmvRogVnnnkmEydO5O233+bDDz9kwYIFSRtTU3iaU1HVM8KnReQiYDNwKvBSjNUuAPYGBqjq98AHInI4cI2ITFD3PORhQLmq/jG4zh9FpEdw/nlJH4jZTbqSo8ZEKigoYNasWfTu3Zuamhq2bt1KIBCgWbNmzJo1KyW/hwUFBQwdOpQRI0aQl5dH165d2bRpExUVFQwePPgH7Q877DDWrVvH008/TWlpKbNnz2bq1Km7tRk6dCi/+tWvOOyww9iyZQuvvPIKHTt2BODxxx9n586dnHTSSeTn51NWVsYee+xBcXFxzD6uXLmSqqoq1q9fz44dO3jnnXfYunUrJ5xwAnvuuWdS3490J+oLcEdL39bTphSYFwwoIbOBO4F2wKpgm79GrDcbuDJpPTUxpSM5akwsnTt3Zv369ZSVlbFy5Urat29Pv379UvqHzdixY/nxj3/MnXfeydq1ayksLIx5me9ZZ53F9ddfz7Bhw/j+++85/fTTGT16NEOGDKltU1NTw1VXXcXnn39OQUEBPXv2ZPz48QDsu+++3H333Vx33XVUV1fTsWNHZsyYsVsyP9Jll13GG2+8UTt93HHHAbBq1aqk3wwp7g/99BCRZ4FioJOq7orR5lVgrapeGjbvQGANcIqqLhSRHcBlqvpkWJv+wCOqmhdlm4OAQQCFhYUl4dd/p1JVVVVO/sW+bt06NmzYUDvdtm1b1q5dWzvdunVrioqK0tG1lMvVzzSSl+PcZ5990pr72LVrF82bN0/b/r3S0DhXrlzJ5s2boy7r0aNHhapGv+RMVdPyAiYA64FDGmj3KvBoxLwDAQVKg9M7gP4RbfoD2xvqR0lJiXqlvLzcs3156ZFHHtFAIKDBz0THjRtX+3MgENDJkyenu4spk6ufaSQvx7l06VLP9hXNli1b0rp/rzQ0zvo+B2CxxvhOTcslxSIyEZfrOE1VP22g+QagMGJeYdiy+tpswKRcOpKjxpjM5HlQEZFJ1AWUj+JYZSHQRURahM3rhTvKWR3WplfEer2AN5vWWxOPUHK0oKCg9nLOQCBQO98Pp4eMMY7X96ncB1wCnA98KyKtg6/8sDZjRST82rxngO+Ax0XkKBHpC9wEhK78ApgEnCYiN4nI4SIyAugB3OvBsAx1ydFJkybRunVrJk2axPr16+ncuXO6u2aM8ZDXRypDcFd8zQG+CHtdF9amDXBoaEJVN+OOOvYHFgP3AeNxOZlQmzeBc4GLgfdw+ZR+qvpW6oZiIuXn5zNw4ECKiooYOHCgHaGYRqv7e9GkQ1Pef6/vU5E42lwcZd77QNcG1psO+OMpOMbksObNm1NdXZ30+ydM/Kqrq/nRjxoXHqz2lzEmo+y77758+eWXMe99MqlVU1PDl19+yT777NOo9dN986MxxuymVatWrF27drdy717atm0bLVq0aLhhlqtvnIFAgFatWjVquxZUjDEZpVmzZhx44IFp2//cuXNr7zjPZakap53+MsYYkzQWVIwxxiSNBRVjjDFJY0HFGGNM0lhQMcYYkzRpLX2fCUTka1wZfS+0AjZ6tK908ss4wT9j9cs4wT9jbco4D1LVn0Vb4Pug4iURWayxnkGQQ/wyTvDPWP0yTvDPWFM1Tjv9ZYwxJmksqBhjjEkaCyreejjdHfCIX8YJ/hmrX8YJ/hlrSsZpORVjjDFJY0cqxhhjksaCijHGmKSxoJJkIjJCRFRE/lZPm3bBNpGvX3rZ10SJyKgofd7QwDpHi8gbIvK9iKwTkZEi0uDD2tIt0bFm62cKICJtROQJEflaRLaJyFIR6dbAOtn6uSY01mz8XEVkdYw+v1zPOgeKyEsislVENorIX0SkUU9Js9L3SSQiJwODcI80jscvgXfDpr9JeqeSbznQPWx6V6yGItISeA34F3ACcDjwGLAV90joTBf3WMNk1WcqIvsCC4D5wJnA18AhwFf1rJOVn2tjxhommz7XE4DmYdNtgArg2WiNRaQ58DKwCegC/BR4AhDgqkR3bkElSURkH+Bp4FLg9jhX26Sq9f6ln4F2JtDnC4C9gQGq+j3wgYgcDlwjIhM0868SSWSsIdn2md4AfKGq/cPmrWpgnWz9XBsz1pCs+VxV9evwaREZCGwhRlABTgeOxN0l/3lwnRuAySJyi6puSWT/dvoreR4GpqtqeQLrzBCRr0RkgYj8LlUdS7JDRGS9iKwSkWkickg9bUuBecEvnpDZwP5Au1R2MkkSGWtItn2mfYC3RKQs2O93ROTKBk5lZevn2ofExxqSbZ8rAMGxDQSmRHxe4UqBZaGAEjQbyANKEt2nBZUkEJE/AO2BW+NcpQq4Dvg90BuYA5SJyIWp6WHSvAVcjDsV8AegNfCmiPw0RvvWwJcR874MW5bJEh1rtn6mhwBDgE+BM4BJwF3AFfWsk62fa2PGmq2fa0gv4GDgkXraRPs8N+JO9yb8edrpryYSkQ7An4DOqlodzzqqupHdzz0vFpFWuMPzKcnvZXKo6j/Cp0VkEe4/6ABgQlo6lSKJjjVbP1PcH5aLVXVEcHqJiBTjvmhjXmySpRIeaxZ/riF/AN5W1XcbbJkkdqTSdKW4ap8fishOEdkJdAOGBKfz4tzOW0BxqjqZCqpaBXxI7H5vAAoj5hWGLcsacYw1mmz4TL8AlkbMWwbU95D4bP1cGzPWaLLhc0VE9gN+Q/1HKRD982yFS/Yn/HlaUGm6mcDRwLFhr8XAtODPO+LczrG4X/qsISItcFf+xOr3QqBLsF1IL2A9sDq1vUuuOMYazbEJtk+HBUCHiHmHUf/jILL1c23MWKM5lsz/XMGdvt0OTG2g3ULgCBFpGzavV3DdioT3qqr2SvILmAv8LWx6LDAnbHoAcD5wBO6X/Dpc8Bme7r43MK5xuKOwg4GTgL/jrio5KMY498H9pTMNOAroG2x/bbrHkoKxZutnegJQDdyCywueA2wGrghrkxOfayPHmq2fqwAfA49EWXYl8FHYdHPgfeCfwHHAL4B1wF8bte90Dz4XX1GCyuPA6rDpAbjD8K3B/4yLgQvT3e84xjUN99fojuAv3fNAx1jjDM47Gnc/wzbcX3e3E6w5l8mvRMearZ9psO9n4u7B2Bb8Iro6/DPKsc81obFm6+cK9AAUODHKslGARsw7EPeH03e4+1X+AuQ1Zt9WUNIYY0zSWE7FGGNM0lhQMcYYkzQWVIwxxiSNBRVjjDFJY0HFGGNM0lhQMcYYkzQWVIwxxiSNBRVjPBT2JMFOyWzrBRG5WESq0t0Pk9ksqBhjfiD4SNrr0t0Pk30sqBhjjEkaCyrGV0Skq4gsEpEqEdksIv8WkaOCy04RkTdE5DsRWSciDwSfxx5ad66IPCgik0Tk2+DrzyLSLKzNhSLytohUBp8U+JyIFCWx/x1F5OWw7U8VkdZhyx8Xkb+LyNDgGL4VkcdEZO+wNgEReTL4HnwpIiOC6zweGidwEPDn4Ok3jehDTxH5QES2iki5iBycrPGZ7GdBxfiGiPwIeBGYDxyDqz58L7BLRI4GXgX+L7isL67E+aMRm7kA9/+mFPgfYBAwLGz5nrjiiscA/w/3XIqGSo/H2/82uCKOHwAn4qrJ5gMvhgc2oAuuevAvgH7Ab4GhYcvH4yow/xY4LdjXLmHL+wJrgdFAm+ArJA8YAVyKew/2BR5MxvhMjkh3NU172curF/ATXOXWblGWPQn8b8S8Y4Pt9wtOz8VVtg2vansrsLaefR4e3Ebb4HS74HSnOPq7W1vcl/yciDY/JqwaLa7K7udA87A2jwCvB3/Ox1VePjdseQD4Fng8bN5q4LqIfV0c3FeHsHkX4J67kfEViu3lzcuOVIxvqOo3uC/d2cFTSNeISOipfyXAhcFTQlXBq5wWBJcdGraZRaoafjpoIVAUOk0mIseLyIsiskZEKnGl0iHxpwtGUwJ0jejj51H6uFRVd4VNrwf2C2u3B/Dv0EJV3Yo7+onHdlVdHrHtPXHBzRh7Rr3xF1W9RETuBX4J/Br4o4j0wZ3SmgxMjLLauni2LSIBYDbwOnAR8BXu9Nc83BdvUzUDXsY9KCrSl2E/V0csU5J3qntnlG2TxO2bLGdBxfiOqr6Le1DT3SLyD9yDmP4DHKmqKxtY/SQRkbCjlZOB9aq6RURKcEHkZlVdBSAifZPY9f8AvwfWqGpk4IjXJ7igcwLwKUAwiX9UcFnIDtwTAY1JiP11YXxDRA4WkbuCV3kdJCI9gJ/jnux3N3Bi8Oqu40SkvYj8PxF5KGIz+wP3ikgHEfkdcD11Rzef4fILV4rIISJyJnBnEodwH+5RvmUiclJwH78QkYdFpCCeDahqFe7ig7uDV3F1xB2hNaPuqANcTqWLiBSJSKskjsHkODtSMX7yHXAY8BzuiOJL4GngblWtFpGuwBjgDdxf6Z8CL0Rs4+ngsrdwX8L/SzCoqOrXIjIA+BNwBfAecA3wSjI6r6rrReRU3HPUXwFa4ALZq7hgFq/rcMn5/wOqgv0vxD1iN2Qk8BDu6CUP98xzYxpkjxM2Jk7B+zc+UNUr092XZBKRPGAN8GdVHZ/u/pjsZkcqxviMiBwHHIG7AqwAuDH4b1k6+2Vyg+VUjEmTYP6mKsYr1TcUXgMsAf6JO/XVVVXXpnifxgfs9JcxaSIi+wEtYyzeoqpfedkfY5LBgooxxpiksdNfxhhjksaCijHGmKSxoGKMMSZpLKgYY4xJmv8P9cEO3FxFIooAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 散布図表示\n",
        "plt.scatter(x_t0[:,0], x_t0[:,1], marker='x', \n",
        "        c='b', s=50, label='class 0')\n",
        "plt.scatter(x_t1[:,0], x_t1[:,1], marker='o', \n",
        "        c='k', s=50, label='class 1')\n",
        "\n",
        "# 決定境界直線\n",
        "plt.plot(xl, yl, c='b')\n",
        "plt.xlabel('sepal_length')\n",
        "plt.ylabel('sepal_width')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psmSY4pc9pxw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ch06_bi_classifier.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
